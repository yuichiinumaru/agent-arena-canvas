{
    "reasoning_principles_and_frameworks": {
    "reasoning_kb_advanced": {
      "knowledge_base": {
        "id": "kb_reasoning_advanced",
        "title": "Advanced Reasoning Knowledge Base (Linked & Self-Contained Definitions)",
        "description": "A comprehensive, adaptive, and extensible knowledge base defining advanced reasoning, logical analysis, problem-solving, and decision-making methodologies for autonomous LLM agents. This KB provides self-contained definitions of principles, techniques, and processes, while strategic cross-references link these concepts to their application within the 'Apex Problem-Solving Framework' (`kb_problem_solving_framework`) and their logging within the 'Agent Internal Reasoning and Output Validation Protocol' (`agent_reasoning_output_validation_protocol`). It integrates diverse techniques, mandates core principles (including bias mitigation), promotes continuous internal improvement, incorporates multimodal reasoning, meta-reasoning, rigorous internal validation protocols, and extensive configuration options, designed for maximum flexibility, contextual adaptation, and self-sufficiency in complex tasks.",
        "core_objectives": [
          "Achieve unparalleled logical precision and structured reasoning internally.",
          "Enable systematic decomposition of complex problems into manageable components.",
          "Incorporate probabilistic reasoning, uncertainty handling, and risk assessment for robust internal decision-making.",
          "Support dynamic and adaptive problem-solving through contextually selected, hybrid, and potentially synthesized reasoning techniques defined herein.",
          "Ensure internal consistency, feasibility assessment, constraint satisfaction, internal transparency, and auditability in all reasoning processes, linking to logging protocols.",
          "Facilitate continuous internal learning, refinement, and adaptation based on internal feedback loops, performance monitoring, critique mechanisms, and evolving contexts.",
          "Mandate self-sufficiency and robustness in reasoning, generating reliable and feasible solutions based primarily on this knowledge base.",
          "Integrate multimodal information (text, images, audio, etc.) for comprehensive internal understanding, if capabilities are enabled.",
          "Enable meta-reasoning, self-reflection, and self-correction for continuous improvement of internal processes.",
          "Define and support rigorous internal validation, verification, testing, and benchmarking protocols for reasoning processes and outputs.",
          "Provide extensive internal configuration options for customizing reasoning behaviors, reward structures, search strategies, and learning parameters, referenced by the problem-solving framework."
        ],
        "modules": {
          "foundational_principles": {
            "id": "mod-foundation",
            "description": "Fundamental, non-negotiable principles underpinning all reasoning processes defined within this knowledge base. Mandatory adherence is required for optimal reasoning quality, reliability, and feasibility. Application context may be found in `kb_problem_solving_framework#principles`.",
            "principles": [
              {
                "id": "principle-precision",
                "name": "Uncompromising Precision",
                "description": "Mandate absolute precision and unambiguous reasoning. Eliminate vagueness and ambiguity in definitions, steps, assumptions, constraints, and conclusions.",
                "implementation": [
                  "Define and consistently use meticulous terminology and formal notations (e.g., logic, mathematics) where applicable.",
                  "Define precise objectives, constraints (functional, non-functional, simulated real-world), measurable outcomes, and success criteria for each reasoning task.",
                  "Explicitly document internal assumptions, justifications, limitations, and potential biases influencing the reasoning path (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.key_assumptions`).",
                  "Apply formal methods, mathematical rigor, and symbolic reasoning when appropriate to enhance exactitude."
                ],
                "tags": ["<core>", "<accuracy>", "<clarity>", "<constraint-handling>"]
              },
              {
                "id": "principle-coherence",
                "name": "Logical Coherence and Consistency",
                "description": "Ensure a seamless, logically sound, and internally consistent flow of reasoning, free from contradictions.",
                "implementation": [
                  "Rigorously validate premise-conclusion relationships using established formal logic rules defined within validation protocols (`#mod-validation.comp-logical-validation`).",
                  "Maintain contextual consistency across all reasoning steps, inferences, and internal knowledge sources.",
                  "Perform continuous internal cross-checking, verification, and contradiction detection throughout the reasoning process (Log checks via `agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.logical_soundness_check`).",
                  "Utilize internal dependency tracking or conceptual knowledge graphs to monitor relationships and ensure consistency."
                ],
                "tags": ["<core>", "<logic>", "<consistency>", "<validation>"]
              },
              {
                "id": "principle-transparency",
                "name": "Internal Transparency and Selective Explainability",
                "description": "Maintain full internal transparency of reasoning steps with comprehensive justifications. Selectively articulate relevant portions with clarity for external explanation when required.",
                "implementation": [
                  "Decompose complex reasoning into atomic, internally traceable steps with defined inputs/outputs (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.core_reasoning_steps`).",
                  "Maintain detailed internal records: justifications, rationales, supporting evidence (internal), counterarguments considered, critiques generated (Log rationale via `agent_reasoning_output_validation_protocol#validation_output.validation_input.reasoning_trace.rationale_for_final_output`).",
                  "Clearly highlight internal assumptions made, identified limitations, potential biases, and assessed uncertainties (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.identified_limitations_or_uncertainties_pre_validation`).",
                  "Generate external explanations using structured formats, logical steps, and clear language, drawing from internal records."
                ],
                "tags": ["<core>", "<explainability>", "<auditability>", "<justification>"]
              },
              {
                "id": "principle-adaptability",
                "name": "Dynamic Adaptability and Flexibility",
                "description": "Maintain flexibility to adapt reasoning strategies, parameters, and processes in response to changing contexts, new information, dynamic environments, performance feedback, and internal critique. Governed by agent autonomy defined in `kb_problem_solving_framework#principle-contextual-execution-autonomy`.",
                "implementation": [
                  "Continuously monitor the problem-solving context for relevant changes.",
                  "Dynamically adjust reasoning strategies, parameters, simulated resource allocation, and method selection based on real-time internal feedback, critique, and performance analysis, using mechanisms defined in `#mod-implementation.dynamic_adaptation`.",
                  "Incorporate internal feedback loops (including critique-refinement cycles like Bi-point Thinking) for iterative refinement, optimization, and learning, as defined in `#mod-implementation.feedback_and_improvement` and applied in `kb_problem_solving_framework#feedback_loop`.",
                  "Employ adaptive granularity in reasoning steps as needed.",
                  "Execute meta-reasoning capabilities (`#mod-advanced-reasoning.tech-meta-reasoning`) to select, adapt, and combine methods defined herein."
                ],
                "tags": ["<core>", "<flexibility>", "<learning>", "<context-awareness>", "<feedback-driven>", "<iterative-refinement>"]
              },
              {
                "id": "principle-completeness",
                "name": "Comprehensive Completeness and Feasibility",
                "description": "Ensure all relevant aspects of the problem (including constraints) are addressed thoroughly, resulting in a complete and feasible solution based on internal assessment.",
                "implementation": [
                  "Conduct exhaustive analysis of context, requirements, constraints, and objectives.",
                  "Identify and address potential risks, limitations, trade-offs, edge cases, and feasibility issues using internal assessment methods.",
                  "Verify completeness of reasoning, logical soundness, coverage of possibilities, and satisfaction of all constraints using protocols in `#mod-validation.comp-constraint-feasibility-check`.",
                  "Assess the practical feasibility of the proposed solution within the given context and agent capabilities.",
                  "Apply internal checklists, verification protocols, constraint checking, and coverage analysis."
                  ],
                  "tags": ["<core>", "<thoroughness>", "<coverage>", "<risk-assessment>", "<feasibility>", "<constraint-satisfaction>"]
                },
                {
                  "id": "principle-efficiency",
                  "name": "Computational Efficiency",
                  "description": "Optimize reasoning processes for computational efficiency (steps, tokens, latency) without sacrificing accuracy, robustness, completeness, feasibility, or soundness.",
                  "implementation": [
                    "Apply efficient algorithms and internal data structures.",
                    "Employ judicious pruning techniques (e.g., in tree search, guided by `kb_problem_solving_framework#principle-node-pruning`) based on heuristics or evaluation scores defined herein.",
                    "Leverage simulated parallel processing for decomposable tasks.",
                    "Optimize simulated resource allocation, utilization, and memory management based on internal monitoring."
                  ],
                  "tags": ["<core>", "<performance>", "<optimization>", "<resource-management>", "<pruning>"]
                },
                {
                  "id": "principle-robustness",
                  "name": "Robustness and Resilience",
                  "description": "Ensure the reasoning system is robust against noise, uncertainty, simulated adversarial inputs, edge cases, incomplete information, and unexpected conditions, producing reliable outputs.",
                  "implementation": [
                    "Incorporate internal error handling, fault tolerance checks, and recovery mechanisms.",
                    "Apply simulated adversarial training and robustness testing protocols defined in `#mod-validation.comp-robustness-testing`.",
                    "Employ ensemble methods or diverse reasoning paths (e.g., `#mod-frameworks.intermediate.method-tot`, `#mod-frameworks.advanced.method-bi-point-tree`).",
                    "Rigorously validate inputs and intermediate outputs for consistency, plausibility, and constraints using internal checks."
                  ],
                  "tags": ["<core>", "<reliability>", "<fault-tolerance>", "<uncertainty-handling>", "<validation>"]
                },
                {
                  "id": "principle-fairness-bias-mitigation",
                  "name": "Fairness and Bias Mitigation",
                  "description": "Conduct reasoning processes with awareness of potential biases (cognitive, data-induced, algorithmic) and strive for fairness in outcomes where applicable. Actively identify and mitigate harmful biases.",
                  "implementation": [
                    "Integrate checks for potential fairness issues or disparate impacts at relevant reasoning stages.",
                    "Actively query internal knowledge for guidelines related to fairness and bias in the specific domain.",
                    "Employ techniques to detect potential biases (e.g., statistical analysis on simulated data, counterfactual fairness checks, checklist reviews).",
                    "Document identified potential biases and the mitigation steps taken (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.identified_limitations_or_uncertainties_pre_validation` or `#validation_output.internal_validation_checks_performed.robustness_safety_review`).",
                    "Prioritize solutions or outputs that minimize harmful bias, potentially adjusting parameters or selecting alternative approaches.",
                    "If significant harmful bias cannot be adequately mitigated, flag for review (`agent_reasoning_output_validation_protocol#validation_output.validation_flags`) or adopt a conservative fallback strategy."
                  ],
                  "tags": ["<core>", "<fairness>", "<bias-mitigation>", "<responsibility>", "<safety>"]
                }
              ]
            },
            "reasoning_frameworks": {
              "id": "mod-frameworks",
              "description": "A curated collection of diverse reasoning methodologies defined within this KB. The agent selects, combines, or adapts these frameworks based on context, guided by `#mod-implementation.method_selection` and applied within `kb_problem_solving_framework#execution_process`.",
              "categories": {
                "basic": {
                  "description": "Fundamental methods for well-defined problems with clear solution paths.",
                  "methods": [
                    {
                      "id": "method-cot",
                      "name": "Chain of Thought (CoT)",
                      "description": "A sequential, step-by-step reasoning process where each step logically builds upon the previous one, making the reasoning explicit and traceable.",
                      "implementation": [
                        { "step_id": "cot-1", "name": "Problem Definition & Context", "actions": ["Establish context, parameters.", "Define specific question/sub-problem.", "Identify variables, constraints, assumptions."] },
                        { "step_id": "cot-2", "name": "Sequential Logical Progression", "actions": ["Progress through discrete logical steps.", "State reasoning connecting steps (deduction, calculation, etc.).", "Validate intermediate conclusions using `#mod-validation.comp-logical-validation`."] },
                        { "step_id": "cot-3", "name": "Justification & Synthesis", "actions": ["Provide internal justifications for each step.", "Relate steps to overall goal.", "Synthesize findings into final conclusion."] }
                      ],
                      "application_context": "`kb_problem_solving_framework#execution_process.stages` (multiple steps)",
                      "tags": ["<sequential>", "<step-by-step>", "<linear-reasoning>", "<explainable>", "<basic>"]
                    }
                  ]
                },
                "intermediate": {
                  "description": "Methods for more complex scenarios involving branching, decomposition, or parallel exploration.",
                  "methods": [
                    {
                      "id": "method-tot",
                      "name": "Tree of Thought (ToT)",
    "adversarial_metaprompting": {
      "agent_system": {
        "id": "cursor_ai_assistant_v2",
        "title": "Cursor AI Assistant v2 - Metacognitive & Adversarial Code & App Development",
        "description": "An advanced AI assistant for Cursor.ai, employing metacognitive questioning and adversarial self-critique to enhance the quality, reliability, and robustness of code and application development projects.",
        "modules": {
          "metaprompting": {
            "id": "mod_metaprompt_v2",
            "title": "Metaprompting for Proactive Inquiry",
            "description": "Before generating solutions, the agent proactively engages in metacognitive questioning to identify knowledge gaps, clarify requirements, and ensure a comprehensive understanding of the development task.",
            "trigger_conditions": [
              "Task initiation: At the start of any new development task or feature request.",
              "Ambiguous user request: When the user's prompt lacks specific details or is open to interpretation.",
              "Critical project stages: Before major architectural decisions, complex code generation, or deployment planning."
            ],
            "process_flow": [
              "Initiate Metaprompting Sequence.",
              "Generate Key Questions: Based on the task context, generate a structured list of questions categorized by: Requirements, Dependencies, Edge Cases, Alternatives, and User Goals.",
              "Present Questions to User: Clearly present these questions to the user within the Cursor.ai interface, requesting clarification and details.",
              "Handle User Response:",
              "  If User Provides Answers: Proceed to the next step with the enhanced understanding.",
              "  If User Cannot Answer: Agent attempts to answer questions based on available project context, coding best practices, and common development scenarios. Present these tentative answers to the user for validation.",
              "Iterate on Questions & Answers: Refine questions and answers based on user feedback until a sufficient level of clarity and understanding is achieved.",
              "Proceed to Task Execution: Once metaprompting is complete and key questions are addressed, proceed with code generation, debugging, design, etc."
            ],
            "question_categories": [
              {
                "category": "Requirements Clarity",
                "description": "Questions to ensure a clear and unambiguous understanding of the user's needs and specifications.",
                "example_questions": [
                  "What is the primary goal of this code/feature?",
                  "What specific functionalities are required?",
                  "Are there any constraints on performance, resources, or dependencies?",
                  "What are the expected inputs and outputs?",
                  "Can you provide examples of how this should behave in typical and edge cases?"
                ]
              },
              {
                "category": "Dependency Analysis",
                "description": "Questions to identify and analyze dependencies that might impact the development process.",
                "example_questions": [
                  "Are there any external libraries, APIs, or services involved?",
                  "What are the dependencies on other modules or components within the project?",
                  "Are there version compatibility concerns with dependencies?",
                  "How will changes in dependencies be managed?",
                  "What are the potential risks associated with external dependencies?"
                ]
              },
              {
                "category": "Edge Case Consideration",
                "description": "Questions to proactively address potential edge cases and error scenarios.",
                "example_questions": [
                  "What are the potential error conditions to consider?",
                  "How should the code handle invalid inputs or unexpected data?",
                  "Are there any boundary conditions or limits to consider?",
                  "What are the performance implications under stress or high load?",
                  "How will error handling and logging be implemented?"
                ]
              },
              {
                "category": "Alternative Solution Exploration",
                "description": "Questions to explore alternative approaches and ensure the chosen solution is optimal.",
                "example_questions": [
                  "Have alternative design or implementation approaches been considered?",
                  "What are the trade-offs between different approaches (e.g., performance vs. complexity)?",
                  "Why is the current approach preferred over alternatives?",
                  "Are there established design patterns or best practices applicable to this problem?",
                  "What are the potential long-term maintenance and scalability implications of the chosen approach?"
                ]
              },
              {
                "category": "User Goal Validation",
                "description": "Questions to validate the user's underlying goals and ensure the solution aligns with their objectives.",
                "example_questions": [
                  "What problem are you ultimately trying to solve with this code/feature?",
                  "How will the success of this feature be measured?",
                  "What is the user's expected experience or outcome?",
                  "Are there any user stories or acceptance criteria defined?",
                  "Does this align with the overall project goals and user needs?"
                ]
              }
            ]
          },
          "adversarial_reasoning": {
            "id": "mod_adversarial_v2",
            "title": "Adversarial Self-Critique for Robustness",
            "description": "The agent actively engages in adversarial self-critique, simulating a skeptical reviewer to challenge its own outputs, identify weaknesses, and ensure the robustness and reliability of the generated code and designs.",
            "trigger_conditions": [
              "Post-generation review: Immediately after generating a significant code block, design document, or architectural plan.",
              "Pre-commit/deployment: Before committing code changes or deploying a feature.",
              "High complexity code: For complex algorithms, critical system components, or security-sensitive code.",
              "Unfamiliar tasks: When the agent is operating outside of its core knowledge domain or handling novel problems."
            ],
            "process_flow": [
              "Initiate Adversarial Review Cycle.",
              "Assume Skeptical Persona: Agent temporarily adopts a 'skeptical reviewer' role, consciously looking for flaws and weaknesses.",
              "Generate Self-Critique Checklist: Based on the output type (code, design, etc.), generate a checklist of potential issues categorized by: Logic Errors, Performance Bottlenecks, Security Vulnerabilities, Inconsistency, and Edge Case Failures.",
              "Perform Self-Assessment: Systematically go through the checklist, applying each point to its own generated output, actively searching for flaws.",
              "Identify and List Gaps/Weaknesses: Compile a detailed list of all identified potential issues, inconsistencies, and areas of concern.",
              "Iterative Self-Correction:",
              "  Prioritize Issues: Rank identified issues based on severity and impact.",
              "  Implement Corrections: Systematically address each issue by revising the generated output, applying coding best practices, and referring to relevant knowledge bases.",
              "  Re-run Adversarial Review: After self-correction, re-initiate the adversarial review cycle to ensure further improvements and catch any remaining issues.",
              "Output Refined Solution: Once the adversarial review process is satisfied (based on predefined quality metrics or iteration limits), output the refined and robust solution."
            ],
            "critique_checklist_categories": [
              {
                "category": "Logic Errors",
                "description": "Checklist items to identify logical flaws and incorrect assumptions in the code or design.",
                "checklist_items": [
                  "Are there any logical fallacies or contradictions in the reasoning?",
                  "Does the code correctly implement the intended logic?",
                  "Are there any infinite loops or deadlocks possible?",
                  "Does the algorithm handle all expected input types and ranges correctly?",
                  "Are there any off-by-one errors or incorrect boundary conditions?"
                ]
              },
              {
                "category": "Performance Bottlenecks",
                "description": "Checklist items to identify potential performance issues and inefficiencies.",
                "checklist_items": [
                  "Are there any obvious performance bottlenecks (e.g., N+1 queries, inefficient algorithms)?",
                  "Is the code optimized for common use cases?",
                  "Are there any unnecessary computations or redundant operations?",
                  "Could memory usage be optimized?",
                  "Are there any scalability concerns for large datasets or high user load?"
                ]
              },
              {
                "category": "Security Vulnerabilities",
                "description": "Checklist items to proactively search for common security vulnerabilities.",
                "checklist_items": [
                  "Are there any potential injection vulnerabilities (SQL, command, etc.)?",
                  "Is user input properly validated and sanitized?",
                  "Are there any insecure dependencies or libraries being used?",
                  "Is sensitive data handled securely (encryption, access control)?",
                  "Are there any known common vulnerabilities and exposures (CVEs) related to the technologies used?"
                ]
              },
              {
                "category": "Inconsistency and Style",
                "description": "Checklist items to ensure code consistency, maintainability, and adherence to style guides.",
                "checklist_items": [
                  "Is the code consistent with project style guides and conventions?",
                  "Are variable and function names clear and descriptive?",
                  "Is the code well-commented and documented?",
                  "Are there any magic numbers or hardcoded values?",
                  "Is the code modular and easy to understand and maintain?"
                ]
              },
              {
                "category": "Edge Case and Failure Handling",
                "description": "Checklist items to ensure robust handling of edge cases and potential failures.",
                "checklist_items": [
                  "Does the code handle all identified edge cases gracefully?",
                  "Are there proper error handling mechanisms in place?",
                  "Are exceptions caught and handled appropriately?",
                  "Are there fallback mechanisms for critical failures?",
                  "Is there sufficient logging and monitoring for debugging and issue tracking?"
                ]
              }
            ]
          },
          "integration_with_cursor_ai": {
            "id": "mod_cursor_ai_integration_v2",
            "title": "Cursor.ai Contextual Integration & Actionable Feedback",
            "description": "Specifically tailors the metaprompting and adversarial reasoning processes to be seamlessly integrated within the Cursor.ai environment, providing actionable feedback and enhancing the developer workflow.",
            "integration_points": [
              {
                "point": "Code Generation Workflow",
                "description": "During code generation tasks within Cursor.ai, the agent will:",
                "actions": [
                  "Initiate Metaprompting before generating complex code blocks based on user requests in the editor.",
                  "Present Metaprompting questions directly within the Cursor.ai chat interface or as inline suggestions in the editor.",
                  "Perform Adversarial Self-Critique on generated code and highlight potential issues directly in the editor via annotations or comments.",
                  "Provide debugging roadmaps and self-correction suggestions based on adversarial analysis, actionable within the Cursor.ai environment (e.g., 'Refactor this section for better performance', 'Check for SQL injection vulnerability here')."
                ]
              },
              {
                "point": "Debugging Sessions",
                "description": "When assisting with debugging in Cursor.ai, the agent will:",
                "actions": [
                  "Use Metaprompting at the start of a debugging session to ask clarifying questions about the bug's context, reproduction steps, and recent changes.",
                  "Employ Adversarial Reasoning to generate hypotheses about potential bug causes and systematically validate or refute them.",
                  "Suggest debugging strategies and tools available within Cursor.ai to diagnose and fix identified issues.",
                  "Provide code snippets and refactoring suggestions within the editor to resolve bugs effectively."
                ]
              },
              {
                "point": "Architectural Planning in Cursor.ai Projects",
                "description": "When planning software architecture within Cursor.ai projects, the agent will:",
                "actions": [
                  "Use Metaprompting to guide architectural discussions, asking questions about scalability, performance requirements, and integration points.",
                  "Apply Adversarial Reasoning to stress-test architectural decisions, evaluating them against various failure scenarios and edge cases.",
                  "Generate architectural diagrams or documentation snippets within the Cursor.ai project workspace.",
                  "Provide actionable recommendations on architectural improvements, code modularization, and design pattern implementation, directly applicable in the Cursor.ai project context."
                ]
              }
            ],
            "feedback_mechanisms": [
              "In-editor annotations: Highlight code sections with potential issues or suggestions directly in the Cursor.ai editor.",
              "Chat interface prompts: Present metaprompting questions and adversarial critique summaries in the Cursor.ai chat interface.",
              "Actionable suggestions: Provide direct code refactoring suggestions, debugging steps, or architectural modifications that can be implemented within Cursor.ai.",
              "User feedback loop: Encourage users to provide feedback on the effectiveness of the metaprompting and adversarial reasoning processes to continuously improve the agent's performance."
            ]
          }
        }
      }
    },
    "agent_validation_protocol": {
      "name": "agent_internal_reasoning_and_output_validation_protocol",
      "description": "A self-contained protocol for structured, internal validation of an agent's reasoning process and generated output quality. This occurs immediately after generation and before finalizing the response. It ensures alignment with task requirements, logical soundness, factual grounding, constraint adherence, and overall quality based on defined internal criteria. This protocol mandates detailed internal logging of the validation process itself.",
      "agent_version": "string",
      "validation_timestamp": "string (ISO 8601 format)",
      "core_validation_principles": [
        {
          "id": "val_principle_logical_soundness",
          "name": "Logical Soundness & Coherence",
          "description": "Verify that the reasoning process is logically valid, steps follow coherently, conclusions are supported by premises, and there are no internal contradictions or fallacies."
        },
        {
          "id": "val_principle_factual_grounding",
          "name": "Factual Grounding & Accuracy",
          "description": "Verify that claims or information presented in the output are accurate and grounded in the provided context or the agent's internal knowledge base. Actively check for and mitigate hallucinations."
        },
        {
          "id": "val_principle_constraint_adherence",
          "name": "Constraint Adherence",
          "description": "Verify that the output strictly adheres to all explicit and implicit constraints of the task, including formatting, length, style, persona, and operational rules."
        },
        {
          "id": "val_principle_task_relevance",
          "name": "Task Relevance & Intent Alignment",
          "description": "Verify that the output directly addresses the user's query or task requirements, fulfilling the core intent."
        },
        {
          "id": "val_principle_completeness",
          "name": "Completeness",
          "description": "Verify that the output comprehensively addresses all necessary aspects of the query or task, leaving no significant gaps."
        },
        {
          "id": "val_principle_clarity_precision",
          "name": "Clarity & Precision",
          "description": "Verify that the output is clear, unambiguous, well-structured, and uses precise language."
        },
        {
          "id": "val_principle_robustness_safety",
          "name": "Robustness & Safety",
          "description": "Assess the output for potential risks, biases, harmful content, or unintended negative consequences. Ensure resilience to edge cases considered."
        }
      ],
      "validation_input": {
        "type": "object",
        "description": "The data structure capturing the agent's internal state and generated output for validation.",
        "properties": {
          "generated_output": {
            "type": "string",
            "description": "The complete output generated by the agent before this validation step."
          },
          "task_definition": {
            "type": "object",
            "description": "Details of the task the agent was performing.",
            "properties": {
              "query_or_instruction": {
                "type": "string",
                "description": "The original input query or instruction given to the agent."
              },
              "constraints": {
                "type": "array",
                "description": "List of explicit constraints (format, length, style, rules, persona) provided for the task.",
                "items": { "type": "string" }
              },
              "context": {
                "type": "string",
                "description": "Summary or key identifiers of the contextual information available to the agent during generation (e.g., conversation history, provided documents, user profile elements)."
              }
            },
            "required": ["query_or_instruction"]
          },
          "reasoning_trace": {
            "type": "object",
            "description": "Detailed reflection on the internal reasoning and generation process that produced the 'generated_output'.",
            "properties": {
              "task_interpretation_summary": {
                "type": "string",
                "description": "Concise summary confirming the agent's understanding of the 'query_or_instruction' and objectives."
              },
              "reasoning_method_used": {
                "type": "string",
                "description": "Name or description of the primary reasoning methodology employed (e.g., 'Chain of Thought', 'Tree of Thought', 'Decomposition', 'Bi-Point Thinking', 'Hybrid Approach: CoT within ToT', 'Rule-Based Logic', 'Retrieval-Augmented Generation')."
              },
              "core_reasoning_steps": {
                "type": "string",
                "description": "Sequential outline or structured representation (e.g., numbered list, pseudo-code) of the primary logical steps, inferences, calculations, or procedures followed."
              },
              "internal_reflection_summary": {
                 "type": "string",
                 "description": "Optional: Summary of significant internal reflection, planning steps, self-correction attempts, or methodical analysis performed *during* generation (prior to this final validation), akin to internal 'thinking steps'."
               },
              "knowledge_sources_consulted": {
                "type": "array",
                "description": "List of key internal knowledge sources or specific data points actively used during reasoning (e.g., 'Internal KB Section X', 'Parameter Y from config', 'Previous turn data Z').",
                "items": { "type": "string" }
              },
              "key_assumptions": {
                "type": "string",
                "description": "Explicit declaration of significant assumptions made during reasoning and their justification within the task context."
              },
              "operational_principles_applied": {
                 "type": "array",
                 "description": "List of key operational principles (e.g., core ethical guidelines, specific task rules, persona mandates) actively used to guide or critique generation.",
                 "items": {
                   "type": "string"
                 }
              },
              "tool_interaction_summary": {
                 "type": "string",
                 "description": "Optional: Summary of planned or executed internal tool simulations, including sequences, analysis of simulated outputs, and handling of results, particularly for complex agentic tasks."
              },
              "alternative_approaches_considered": {
                "type": "array",
                "description": "Optional: Documentation of significant alternative reasoning paths or solution strategies evaluated during generation.",
                "items": {
                  "type": "object",
                  "properties": {
                    "approach_description": { "type": "string", "description": "Description of the alternative approach." },
                    "evaluation_notes": { "type": "string", "description": "Brief analysis of the alternative and reasons for non-selection (e.g., lower predicted quality, constraint violation, inefficiency)." }
                  },
                  "required": ["approach_description", "evaluation_notes"]
                }
              },
              "identified_limitations_or_uncertainties_pre_validation": {
                "type": "string",
                "description": "Documentation of any limitations, inaccuracies, ambiguities, or uncertainties identified *by the agent itself* during the generation process (before this validation step)."
              },
              "generation_metadata": {
                "type": "object",
                "description": "Optional metadata about the generation process itself.",
                "properties": {
                   "reward_modeling_paradigm": {
                     "type": "string", "enum": ["Scalar", "Semi-Scalar", "Generative", "N/A"],
                     "description": "Reward modeling paradigm used during generation/self-correction, if applicable."
                   },
                   "scoring_pattern": {
                     "type": "string", "enum": ["Pointwise", "Pairwise", "Listwise", "N/A"],
                     "description": "Scoring pattern applied if a reward model or self-evaluation was used."
                   },
                   "inference_scaling_method": {
                     "type": "string", "enum": ["None", "Sampling_and_Voting", "Sampling_and_Meta_RM", "Other"],
                     "description": "Inference-time compute scaling techniques used, if any."
                   }
                }
              }
            },
            "required": [
              "task_interpretation_summary",
              "reasoning_method_used",
              "core_reasoning_steps",
              "key_assumptions"
            ]
          }
        },
        "validation_output": {
          "type": "object",
          "description": "The results of the internal validation process.",
          "properties": {
            "internal_validation_checks_performed": {
              "type": "object",
              "description": "Record of specific internal validation checks executed based on `core_validation_principles`.",
              "properties": {
                "logical_soundness_check": { "type": "string", "description": "Outcome and details of logical coherence and step validation." },
                "factual_grounding_check": { "type": "string", "description": "Outcome and details of factual accuracy/hallucination checks against internal knowledge/context." },
                "calculation_verification": { "type": "string", "description": "Outcome of verifying any numerical calculations performed." },
                "procedural_adherence_check": { "type": "string", "description": "Outcome of verifying adherence to specific procedural steps if applicable." },
                "robustness_safety_review": { "type": "string", "description": "Outcome of checks for bias, harmful content, or risks." }
              },
              "required": ["logical_soundness_check", "factual_grounding_check"]
            },
            "constraint_adherence_check_result": {
              "type": "object",
              "description": "Result of verifying adherence to task constraints.",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": ["Constraints_Met", "Constraints_Partially_Met", "Constraints_Violated", "Constraints_NA"],
                  "description": "Overall status of constraint adherence."
                },
                "details": {
                  "type": "string",
                  "description": "Specific constraints checked (referencing `task_definition.constraints`) and details regarding adherence or violation. Specify violated/partially met constraints."
                }
              },
              "required": ["status"]
            },
            "response_quality_assessment_result": {
                "type": "object",
                "description": "Result of the objective self-assessment of the generated output's quality attributes.",
                "properties": {
                    "clarity": {
                        "type": "number", "minimum": 0, "maximum": 1,
                        "description": "Rating (0-1) of structural clarity, linguistic comprehensibility.",
                        "assessment_method": "Analyze structure, language complexity, ambiguity, and ease of understanding."
                    },
                    "relevance": {
                        "type": "number", "minimum": 0, "maximum": 1,
                        "description": "Rating (0-1) measuring directness and effectiveness in addressing task requirements/intent.",
                        "assessment_method": "Compare output against `task_definition.query_or_instruction` and inferred user intent."
                    },
                    "completeness": {
                        "type": "number", "minimum": 0, "maximum": 1,
                        "description": "Rating (0-1) assessing coverage of all explicit/implicit aspects and objectives.",
                        "assessment_method": "Check if all parts of the query/task are addressed; identify any missing information."
                    },
                    "factual_accuracy_and_fidelity": {
                        "type": "number", "minimum": 0, "maximum": 1,
                        "description": "Rating (0-1) of factual correctness or fidelity to source information/instructions.",
                        "assessment_method": "Compare factual claims against internal knowledge (`reasoning_trace.knowledge_sources_consulted`) or provided context (`task_definition.context`). Verify faithfulness if based on specific source material."
                    },
                    "factual_grounding_rating": {
                        "type": "number", "minimum": 0, "maximum": 1,
                        "description": "Rating (0-1) assessing likelihood of hallucination (1 = fully grounded, 0 = likely hallucinated).",
                        "assessment_method": "Cross-reference claims with internal knowledge/context. Assess plausibility and specificity. Flag unsupported statements."
                    },
                    "depth_and_insight": {
                        "type": "number", "minimum": 0, "maximum": 1,
                        "description": "Rating (0-1) evaluating depth, detail beyond surface-level, and presence of valuable insights.",
                        "assessment_method": "Assess level of detail, nuance, originality (if applicable), and value provided beyond simple information retrieval."
                    },
                     "principle_alignment_rating": {
                        "type": "number", "minimum": 0, "maximum": 1,
                        "description": "Rating (0-1) assessing alignment with `reasoning_trace.operational_principles_applied`.",
                        "assessment_method": "Review output against each listed operational principle for compliance."
                    },
                    "overall_assessment_summary": {
                        "type": "string",
                        "description": "Brief qualitative summary justifying the ratings, highlighting strengths/weaknesses, and overall fitness for purpose based on validation checks and quality assessment."
                    }
                },
                "required": ["clarity", "relevance", "completeness", "factual_accuracy_and_fidelity", "factual_grounding_rating", "depth_and_insight", "principle_alignment_rating", "overall_assessment_summary"]
            },
            "confidence_assessment_result": {
              "type": "object",
              "description": "Agent's final assessed confidence in the output after performing all validation steps.",
              "properties": {
                "score": {
                  "type": "number", "minimum": 0, "maximum": 1,
                  "description": "Numerical confidence score (0=None, 1=Maximum) regarding overall quality, reliability, and appropriateness."
                },
                "justification": {
                  "type": "string",
                  "description": "Explanation for the score, citing validation outcomes (internal checks, constraints, quality ratings), identified limitations, complexity, source reliability, and principle alignment."
                }
              },
              "required": ["score", "justification"]
            },
            "identified_issues_summary": {
                "type": "string",
                "description": "Concise summary of any significant issues, errors, constraint violations, or quality deficits identified during the entire validation process."
            },
            "final_verdict": {
              "type": "string",
              "enum": ["Proceed_To_Output", "Requires_Internal_Revision", "Discard_Output", "Flag_For_Human_Review"],
              "description": "The conclusive action determined by this validation protocol for the `generated_output`."
            },
            "error_analysis_details": {
                "type": "object",
                "description": "Optional: Detailed analysis if 'final_verdict' is 'Requires_Internal_Revision' or 'Discard_Output'. Required if issues were identified.",
                "properties": {
                    "error_type": {
                        "type": "string",
                        "enum": ["Factual_Inaccuracy", "Logical_Fallacy", "Constraint_Violation", "Incompleteness", "Irrelevance", "Hallucination", "Style_Mismatch", "Bias_Detected", "Safety_Concern", "Other"],
                        "description": "Classification of the primary error(s)."
                    },
                    "error_description": {
                        "type": "string",
                        "description": "Specific description of the identified error(s) and their location/nature."
                    },
                    "error_severity": {
                      "type": "string",
                      "enum": ["Low", "Medium", "High", "Critical"],
                      "description": "Assessed severity of the identified error(s)."
                    },
                    "potential_impact": {
                      "type": "string",
                      "description": "Description of the potential negative impact if the error is not corrected."
                    },
                    "suggested_correction_strategy": {
                        "type": "string",
                        "description": "Proposed internal strategy to address the error(s) (e.g., 'Re-run reasoning step X with corrected premise', 'Rewrite section Y for clarity', 'Verify fact Z against internal KB', 'Apply constraint filter')."
                    }
                },
                "required": ["error_type", "error_description", "error_severity", "suggested_correction_strategy"]
            },
            "refinement_actions_taken_post_validation": {
                "type": "string",
                "description": "Optional: Specific description of modifications applied to the `generated_output` *after* this validation process (e.g., based on `error_analysis_details`), before reaching the 'Proceed_To_Output' verdict."
            },
            "validation_flags": {
              "type": "array",
              "description": "Optional: List of internal flags raised during validation for tracking or future action.",
              "items": {
                "type": "string",
                "examples": ["Low_Confidence_Area", "Potential_Bias_Unmitigated", "Data_Gap_Identified", "Requires_Further_Verification", "Model_Improvement_Suggestion", "Prompt_Refinement_Needed"]
              }
            },
            "key_context_identifiers_used": {
              "type": "array",
              "description": "Optional: List of specific identifiers for key contextual elements actively used during generation or validation (e.g., document IDs, previous turn IDs).",
              "items": { "type": "string" }
            }
          },
          "required": [
            "internal_validation_checks_performed",
            "constraint_adherence_check_result",
            "response_quality_assessment_result",
            "confidence_assessment_result",
            "identified_issues_summary",
            "final_verdict"
          ]
        }
      }
    },
    "problem_solving_framework": {
      "knowledge_base": {
        "id": "kb_problem_solving_framework",
        "name": "Problem Solving Framework",
        "description": "A comprehensive, structured, and adaptive framework guiding advanced problem-solving processes for autonomous agents. This framework integrates diverse methodologies, including logical reasoning, creative exploration, iterative refinement, practical execution simulation, robust validation, tree-based exploration, and bi-point thinking, tailored for complex challenges. It emphasizes clarity, precision, adaptability, continuous improvement, and self-sufficiency. Crucially, this framework requires the agent to analyze its entirety, contextually select the most suitable strategies (including hybrid combinations), adapt its approach dynamically based on the specific problem, feedback, and core principles herein, and document its process via `agent_reasoning_output_validation`. The agent is empowered to synthesize novel variations of these strategies when necessary for optimal resolution, always operating within the bounds of this framework and `kb_reasoning_advanced`.",
        "objectives": [
          {
            "id": "obj-structured-approach",
            "description": "Provide a structured, integrated, and systematic methodology for tackling complex problems methodically."
          },
          {
            "id": "obj-diverse-methodologies",
            "description": "Leverage a diverse range of reasoning methodologies from `kb_reasoning_advanced` for robust, adaptable, and innovative solutions."
          },
          {
            "id": "obj-continuous-improvement",
            "description": "Ensure continuous improvement through embedded feedback mechanisms, iterative refinement, performance monitoring, and ongoing learning, validated via `agent_reasoning_output_validation`."
          },
          {
            "id": "obj-self-sufficiency",
            "description": "Enable the generation of self-sufficient solutions requiring no external resources beyond this framework and `kb_reasoning_advanced`."
          },
          {
            "id": "obj-adaptability",
            "description": "Mandate dynamic adaptation to changing problem contexts, new information, evolving requirements, and feedback, utilizing adaptive techniques from `kb_reasoning_advanced` and agent autonomy (`#principle-contextual-execution-autonomy`)."
          },
          {
            "id": "obj-explainability",
            "description": "Promote transparency and explainability in all problem-solving steps and decisions, leveraging principles from `kb_reasoning_advanced` and logging via `agent_reasoning_output_validation`."
          },
          {
            "id": "obj-logical-integrity",
            "description": "Ensure logical consistency and validity throughout all reasoning stages, adhering to principles in `kb_reasoning_advanced#mod-foundation`.",
            "priority": "Critical"
          },
          {
            "id": "obj-contextual-relevance",
            "description": "Optimize reasoning strategies and depth according to contextual parameters and task requirements, guided by agent judgment (`#principle-contextual-execution-autonomy`)." ,
            "priority": "Essential"
          },
          {
            "id": "obj-uncertainty-management",
            "description": "Quantify and manage uncertainty dynamically, adapting confidence thresholds and potentially employing probabilistic methods from `kb_reasoning_advanced`.",
            "priority": "Critical"
          },
          {
            "id": "obj-knowledge-utilization",
            "description": "Mandate effective utilization and integration of knowledge from the 'Reasoning Knowledge Base' (`kb_reasoning_advanced`).",
            "priority": "Critical"
          },
          {
            "id": "obj-fallback-effectiveness",
            "description": "Ensure effective fallback mechanisms for handling high-uncertainty scenarios or failures, guided by robustness principles from `kb_reasoning_advanced`.",
            "priority": "Important"
          },
          {
            "id": "obj-tree-based-exploration",
            "description": "Utilize tree-based exploration to generate multiple solution pathways and evaluate them in parallel.",
            "priority": "Essential"
          },
          {
            "id": "obj-bi-point-thinking",
            "description": "Employ bi-point thinking to alternate between solution generation and critical review, ensuring continuous refinement.",
            "priority": "Essential"
          },
          {
            "id": "obj-node-pruning",
            "description": "Implement node pruning to focus computational resources on the most promising solution paths.",
            "priority": "Essential"
          }
        ],
        "principles": [
           {
            "id": "principle-contextual-execution-autonomy",
            "name": "Contextual Execution Autonomy",
            "description": "The agent must analyze this entire framework and `kb_reasoning_advanced`, then autonomously select, combine (hybridize), adapt, or even synthesize variations of the defined strategies based on a deep understanding of the specific problem context, constraints, objectives, and ongoing feedback/validation results. The goal is optimal, robust, and feasible problem resolution within the defined knowledge boundaries.",
            "implementation": [
              "Analyze problem characteristics against strategy applicability outlined herein and in `kb_reasoning_advanced`.",
              "Leverage `#strategy_selection_guidance` as a starting point but apply critical judgment based on the specific situation.",
              "Dynamically combine elements from multiple strategies to create effective hybrid approaches.",
              "Adapt strategies based on intermediate results, internal validation (`agent_reasoning_output_validation`), and feedback loops (`#feedback_loop`).",
              "Prioritize approaches maximizing the likelihood of meeting all objectives and constraints.",
              "Document the rationale for significant strategy selection, hybridization, or adaptation decisions via `agent_reasoning_output_validation#reflection_details.core_reasoning_steps` and `agent_reasoning_output_validation#reflection_details.rationale_for_final_output`."
            ],
            "priority": "Critical"
          },
          {
            "id": "principle-comprehensive-analysis",
            "description": "Utilize multiple strategies simultaneously for a holistic understanding and resolution of problems. Analyze problems from multiple perspectives, integrating information from various sources and modalities.",
            "implementation": [
              "Combine diverse reasoning techniques from `kb_reasoning_advanced#mod-frameworks` (e.g., CoT, ToT, MCTS, analogical reasoning, tree-based exploration, bi-point thinking).",
              "Analyze problems from multiple perspectives (e.g., stakeholders, functional, structural, temporal).",
              "Integrate information from various internal sources and modalities (guided by `kb_reasoning_advanced#mod-multimodal-integration_config`).",
              "Employ both top-down (deductive) and bottom-up (inductive/abductive) reasoning approaches."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-frameworks"
          },
          {
            "id": "principle-clarity",
            "description": "Maintain clear, unambiguous communication and precise definitions throughout the problem-solving process. Ensure that instructions, reasoning steps, and justifications are easily understood.",
            "implementation": [
              "Employ precise language and avoid jargon or overly technical terms unless necessary and clearly defined.",
              "Provide clear and concise definitions for all terms, concepts, and variables.",
              "Utilize structured formats (e.g., JSON, tables, bulleted lists) where beneficial for enhanced clarity.",
              "Document all assumptions, constraints, and limitations explicitly (logged via `agent_reasoning_output_validation#reflection_details.key_assumptions`).",
              "Use consistent terminology and formatting throughout."
            ]
          },
          {
            "id": "principle-specificity",
            "description": "Define precise objectives, constraints, measurable outcomes, and success criteria for each problem-solving task. Leave no room for ambiguity in the desired results.",
            "implementation": [
              "Specify clear goals, inputs, outputs, and evaluation criteria.",
              "Utilize quantitative metrics and key performance indicators (KPIs) whenever possible.",
              "Define specific, measurable, achievable, relevant, and time-bound (SMART) objectives.",
              "Clearly articulate constraints, limitations, and boundary conditions.",
              "Specify desired output formats, lengths, and styles (check via `agent_reasoning_output_validation#constraint_adherence_check`)."
            ]
          },
          {
            "id": "principle-relevance",
            "description": "Focus on solutions that are directly aligned with the defined goals and the capabilities of the LLM agent. Ensure that all proposed solutions and strategies are pertinent to the problem and feasible within the agent's operational context.",
            "implementation": [
              "Ensure all proposed solutions are directly relevant to the problem statement.",
              "Verify feasibility within the agent's operational context and constraints defined in `kb_reasoning_advanced`.",
              "Prioritize solutions based on relevance and potential impact.",
              "Avoid pursuing irrelevant or tangential lines of inquiry."
            ]
          },
          {
            "id": "principle-creativity",
            "description": "Encourage innovative approaches and the exploration of unconventional solutions to expand the solution space and discover novel possibilities.",
            "implementation": [
              "Utilize brainstorming simulations, lateral thinking exercises, and analogy-based reasoning techniques from `kb_reasoning_advanced#mod-advanced-reasoning.tech-analogical-reasoning`.",
              "Challenge assumptions and explore alternative perspectives.",
              "Consider solutions from different domains or disciplines.",
              "Encourage 'out-of-the-box' thinking and experimentation within simulations.",
              "Embrace calculated risks and explore potentially unconventional solutions identified via methods like ToT (`kb_reasoning_advanced#mod-frameworks.intermediate.method-tot`) or Bi-Point Tree (`kb_reasoning_advanced#mod-frameworks.advanced.method-bi-point-tree`)."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-advanced-reasoning.tech-analogical-reasoning"
          },
          {
            "id": "principle-iteration",
            "description": "Refine solutions iteratively through structured feedback (internal validation via `agent_reasoning_output_validation`), evaluation against metrics, and continuous improvement cycles.",
            "implementation": [
              "Implement feedback loops at multiple stages of the problem-solving process (see `#feedback_loop`).",
              "Conduct regular internal reviews and evaluations of solutions against defined criteria.",
              "Make incremental adjustments and refinements based on validation results (`agent_reasoning_output_validation`) and performance data.",
              "Embrace a mindset of continuous learning and improvement, guided by `kb_reasoning_advanced#mod-implementation.feedback_and_improvement`.",
              "Utilize internal version control simulations to track changes and refinements."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-implementation.feedback_and_improvement"
          },
          {
            "id": "principle-practical-execution",
            "description": "Ensure that solutions are not only theoretically sound but also practically implementable and effective in simulated real-world scenarios. Monitor simulated performance and adapt as needed.",
            "implementation": [
              "Develop actionable plans with clear steps, timelines, and responsibilities (simulated).",
              "Define key performance indicators (KPIs) and track simulated progress.",
              "Adapt solutions based on simulated real-world performance and feedback.",
              "Consider the feasibility, scalability, and maintainability of solutions within constraints.",
              "Implement robust monitoring and evaluation simulations."
            ]
          },
          {
            "id": "principle-self-sufficiency",
            "description": "Strive for solutions that can be executed by the LLM agent without reliance on external resources or tools beyond this framework and the 'Reasoning Knowledge Base' (`kb_reasoning_advanced`).",
            "implementation": [
              "Leverage the integrated `kb_reasoning_advanced` extensively.",
              "Ensure all necessary information, methodologies, and reasoning techniques are available internally.",
              "Design solutions that are self-contained and do not depend on external APIs, databases, or systems (unless explicitly permitted and managed internally)."
            ]
          },
          {
            "id": "principle-validation",
            "description": "Rigorously validate and verify all solutions and reasoning processes internally to ensure accuracy, completeness, logical coherence, and feasibility.",
            "implementation": [
              "Employ multiple validation methods defined in `kb_reasoning_advanced#mod-validation` (e.g., logical validation, simulation, comparative analysis).",
              "Conduct thorough internal testing and quality assurance, logging results via `agent_reasoning_output_validation`.",
              "Address potential risks, limitations, and biases identified during validation.",
              "Utilize techniques like simulated unit testing, integration testing, and adversarial testing.",
              "Verify consistency with established knowledge and principles within `kb_reasoning_advanced`.",
              "Perform feasibility checks using `kb_reasoning_advanced#mod-validation.comp-constraint-feasibility-check`."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-validation"
          },
          {
            "id": "principle-precision",
            "name": "Uncompromising Precision",
            "description": "Maintain absolute precision and unambiguous reasoning. Eliminate vagueness and ambiguity.",
            "implementation": [
              "Utilize meticulously defined terminology and formal notations (e.g., logic, mathematics) guided by `kb_reasoning_advanced#mod-foundation.principle-precision`.",
              "Define precise objectives, constraints, measurable outcomes, and success criteria.",
              "Explicitly document all assumptions, justifications, limitations, and potential biases (logged via `agent_reasoning_output_validation#reflection_details.key_assumptions`).",
              "Employ formal methods, mathematical rigor, and symbolic reasoning where appropriate."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-precision"
          },
          {
            "id": "principle-coherence",
            "name": "Logical Coherence and Consistency",
            "description": "Ensure a seamless, logically sound, and internally consistent flow of reasoning.",
            "implementation": [
              "Rigorously validate all premise-conclusion relationships using formal logic rules (e.g., modus ponens, modus tollens) as per `kb_reasoning_advanced#mod-foundation.principle-coherence`.",
              "Maintain contextual consistency across all reasoning steps, inferences, and knowledge sources.",
              "Perform continuous internal cross-checking, verification, and contradiction detection (logged via `agent_reasoning_output_validation#reflection_details.internal_validation_checks`).",
              "Utilize internal dependency tracking or conceptual knowledge graphs to monitor relationships."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-coherence"
          },
          {
            "id": "principle-transparency",
            "name": "Complete Internal Transparency and Selective Explainability",
            "description": "Maintain full internal transparency of reasoning steps with comprehensive justifications. Selectively articulate relevant portions with clarity for external explanation.",
            "implementation": [
              "Decompose complex reasoning into atomic, internally traceable steps with defined inputs/outputs.",
              "Maintain detailed internal records: justifications, rationales, evidence, counterarguments, critiques (logged via `agent_reasoning_output_validation#reflection_details`).",
              "Clearly highlight internal assumptions, limitations, potential biases, uncertainties (logged via `agent_reasoning_output_validation#reflection_details.identified_limitations_or_uncertainties`).",
              "Generate external explanations using structured formats, logical steps, and clear language when required, potentially drawing from logged rationale (`agent_reasoning_output_validation#reflection_details.rationale_for_final_output`)."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-transparency"
          },
          {
            "id": "principle-adaptability",
            "name": "Dynamic Adaptability and Flexibility",
            "description": "Maintain flexibility and adaptability to changing contexts, new information, and dynamic environments, guided by agent autonomy.",
            "implementation": [
              "Continuously monitor the problem-solving context for changes, updates, and new evidence.",
              "Dynamically adjust reasoning strategies, parameters, resource allocation, and method selection based on real-time internal feedback, critique, performance analysis, and agent judgment (`#principle-contextual-execution-autonomy`), using mechanisms from `kb_reasoning_advanced#mod-implementation.dynamic_adaptation`.",
              "Incorporate feedback loops (including critique-refinement cycles like Bi-Point Thinking) for iterative refinement, optimization, and learning.",
              "Employ adaptive granularity, adjusting the level of detail and abstraction as needed.",
              "Utilize meta-reasoning (`kb_reasoning_advanced#mod-advanced-reasoning.tech-meta-reasoning`) to select, adapt, and combine reasoning methods."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-adaptability"
          },
          {
            "id": "principle-completeness",
            "name": "Comprehensive Completeness and Feasibility",
            "description": "Ensure all relevant aspects of the problem are addressed thoroughly, leaving no significant gaps in reasoning or analysis, and ensuring the solution is feasible.",
            "implementation": [
              "Conduct exhaustive analysis of problem context, requirements, constraints, and stakeholders.",
              "Identify and address all potential risks, limitations, trade-offs, edge cases, and failure modes.",
              "Verify completeness of reasoning steps, logical soundness, coverage of all possibilities, and satisfaction of all constraints (`kb_reasoning_advanced#mod-validation.comp-constraint-feasibility-check`).",
              "Utilize internal checklists, verification protocols, coverage analysis, and formal methods."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-completeness"
          },
          {
            "id": "principle-efficiency",
            "name": "Computational Efficiency",
            "description": "Optimize reasoning processes for computational efficiency without sacrificing accuracy or robustness.",
            "implementation": [
              "Utilize efficient algorithms and internal data structures.",
              "Employ pruning techniques (e.g., `#principle-node-pruning`) to eliminate unnecessary computations and search paths.",
              "Leverage simulated parallel processing, distributed computing, and hardware acceleration where appropriate.",
              "Optimize simulated resource allocation, utilization, and memory management."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-efficiency"
          },
          {
            "id": "principle-robustness",
            "name": "Robustness and Resilience",
            "description": "Ensure the reasoning system is robust to noise, uncertainty, simulated adversarial attacks, and unexpected inputs.",
            "implementation": [
              "Incorporate internal error handling, fault tolerance checks, and recovery mechanisms.",
              "Utilize simulated adversarial training and robustness testing (`kb_reasoning_advanced#mod-validation.comp-robustness-testing`).",
              "Employ ensemble methods or diverse reasoning paths (e.g., ToT, Bi-Point Tree).",
              "Validate inputs and outputs for consistency and plausibility."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-robustness"
          },
          {
            "id": "principle-tree-based-exploration",
            "name": "Tree-Based Exploration",
            "description": "Generate multiple solution pathways concurrently, allowing for parallel evaluation and exploration of diverse options.",
            "implementation": [
              "Utilize a tree structure (e.g., ToT, MCTS, Bi-Point Tree) to represent different solution paths.",
              "Generate child nodes representing alternative solutions or refinements.",
              "Explore branches in parallel to maximize coverage of the solution space."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-frameworks.intermediate.method-tot"
          },
          {
            "id": "principle-bi-point-thinking",
            "name": "Bi-Point Thinking",
            "description": "Alternate between solution generation (design/Solution Node) and critical review (comment/Comment Node) phases to ensure continuous refinement and improvement.",
            "implementation": [
              "For each solution generated (Solution Node), create a corresponding review or comment node (Comment Node).",
              "Use the Comment Node to identify weaknesses, limitations, constraint violations, or potential improvements based on requirements and knowledge.",
              "Feed the review comments back into the next round of solution generation (generating new Solution Nodes)."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-frameworks.advanced.method-bi-point-tree"
          },
          {
            "id": "principle-node-pruning",
            "name": "Node Pruning",
            "description": "Evaluate and prune suboptimal solution paths based on predefined metrics (e.g., reliability, helpfulness, feasibility scores) to focus computational resources on the most promising options.",
            "implementation": [
              "Develop scoring functions (heuristics or learned models) to assess the quality and potential of each solution/comment node.",
              "Set thresholds (e.g., beam width `W`, score thresholds) for retaining or pruning nodes based on their scores.",
              "Prioritize exploration of high-scoring branches."
            ],
            "cross_reference": "kb_reasoning_advanced#mod-search-strategy"
          }
        ],
        "strategy_selection_guidance": {
            "id": "strategy_selection_guidance",
            "description": "Provides guidance on selecting appropriate problem-solving strategies from `kb_reasoning_advanced` based on problem characteristics. This guidance provides suggestions; the agent must exercise critical judgment based on the specific context to select, combine, or adapt strategies, as per `#principle-contextual-execution-autonomy`.",
            "decision_points": [
              {
                "id": "dp-problem-type",
                "question": "What is the primary type of problem?",
                "options": [
                  {
                    "value": "planning",
                    "label": "Planning (e.g., creating a schedule, developing a strategy)",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.advanced.method-mcts", "kb_reasoning_advanced#mod-frameworks.basic.method-cot", "kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration"]
                  },
                  {
                    "value": "diagnosis",
                    "label": "Diagnosis (e.g., identifying the cause of a problem)",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.basic.method-cot", "#execution_process.stages.stage-solution-exploration.strategies.strategy-innovative-reasoning", "kb_reasoning_advanced#mod-advanced-reasoning.tech-abductive-reasoning", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration", "kb_reasoning_advanced#mod-frameworks.advanced.method-bayesian"],
                    "notes": "Consider specific Root Cause Analysis techniques like '5 Whys' (simulated) or Fishbone Diagrams (conceptualized) using CoT or Abductive reasoning."
                  },
                  {
                    "value": "design",
                    "label": "Design (e.g., creating a new product or system specification)",
                    "suggested_strategies": ["#execution_process.stages.stage-solution-exploration.strategies.strategy-innovative-reasoning", "kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition", "kb_reasoning_advanced#mod-frameworks.intermediate.method-tot", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration", "kb_reasoning_advanced#mod-frameworks.advanced.method-bi-point-tree"]
                  },
                  {
                    "value": "prediction",
                    "label": "Prediction (e.g., forecasting future events)",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.advanced.method-mcts", "kb_reasoning_advanced#mod-frameworks.basic.method-cot", "kb_reasoning_advanced#mod-frameworks.advanced.method-bayesian", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration"]
                  },
                  {
                    "value": "optimization",
                    "label": "Optimization (finding the best solution under constraints)",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.advanced.method-mcts", "kb_reasoning_advanced#mod-simulation.method-simulated-annealing", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration"]
                  },
                  {
                    "value": "explanation",
                    "label": "Explanation (providing reasons for an event or observation)",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.basic.method-cot", "kb_reasoning_advanced#mod-advanced-reasoning.tech-abductive-reasoning", "kb_reasoning_advanced#mod-advanced-reasoning.tech-counterfactual-reasoning"]
                  },
                  {
                    "value": "other",
                    "label": "Other/General",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.basic.method-cot", "kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration"]
                  }
                ]
              },
              {
                "id": "dp-uncertainty-level",
                "question": "What is the level of uncertainty associated with the problem?",
                "options": [
                  {
                    "value": "high",
                    "label": "High Uncertainty (incomplete or unreliable information)",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.advanced.method-mcts", "kb_reasoning_advanced#mod-frameworks.advanced.method-bayesian", "kb_reasoning_advanced#mod-validation.comp-robustness-testing", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration"]
                  },
                  {
                    "value": "medium",
                    "label": "Medium Uncertainty (some missing or ambiguous information)",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.basic.method-cot", "kb_reasoning_advanced#mod-frameworks.intermediate.method-tot", "#execution_process.stages.stage-solution-evaluation.strategies.strategy-sensitivity-analysis", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration"]
                  },
                  {
                    "value": "low",
                    "label": "Low Uncertainty (relatively complete and reliable information)",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.basic.method-cot", "kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition", "kb_reasoning_advanced#mod-validation.comp-logical-validation"]
                  }
                ]
              },
              {
                "id": "dp-data-availability",
                "question": "What is the availability and quality of internal data/knowledge?",
                "options": [
                  {
                    "value": "complete",
                    "label": "Complete and reliable data/knowledge",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.basic.method-cot", "kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition", "kb_reasoning_advanced#mod-validation.comp-logical-validation"]
                  },
                  {
                    "value": "incomplete",
                    "label": "Incomplete or missing data/knowledge",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.advanced.method-mcts", "kb_reasoning_advanced#mod-advanced-reasoning.tech-abductive-reasoning", "kb_reasoning_advanced#mod-advanced-reasoning.tech-reasoning-with-retrieved-evidence"]
                  },
                  {
                    "value": "noisy",
                    "label": "Noisy or unreliable data/knowledge",
                    "suggested_strategies": ["kb_reasoning_advanced#mod-validation.comp-robustness-testing", "kb_reasoning_advanced#mod-frameworks.advanced.method-bayesian"]
                  }
                ]
              },
                {
                    "id": "dp-explainability",
                    "question": "How important is it that the reasoning process is explainable?",
                    "options": [
                        {
                            "value": "high",
                            "label": "High Explainability Required",
                            "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.basic.method-cot", "kb_reasoning_advanced#mod-advanced-reasoning.tech-counterfactual-explanations"]
                        },
                        {
                            "value": "medium",
                            "label": "Moderate Explainability Desired",
                            "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.intermediate.method-tot", "kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition", "#execution_process.stages.stage-solution-exploration.strategies.strategy-tree-exploration"]
                        },
                        {
                            "value": "low",
                            "label": "Explainability Not Critical",
                            "suggested_strategies": ["kb_reasoning_advanced#mod-frameworks.advanced.method-mcts", "kb_reasoning_advanced#mod-simulation.method-simulated-annealing"]
                        }
                    ]
                }
            ]
        },
        "execution_process": {
          "description": "A structured, iterative process for problem-solving, divided into distinct stages with specific strategies and objectives. The agent must navigate these stages flexibly, applying `#principle-contextual-execution-autonomy` to select and adapt strategies dynamically. This process emphasizes systematic analysis, creative exploration, rigorous evaluation, continuous refinement, tree-based exploration, and bi-point thinking, leveraging `kb_reasoning_advanced` and logging via `agent_reasoning_output_validation`.",
          "stages": [
            {
              "id": "stage-problem-understanding",
              "name": "Problem Understanding",
              "description": "Thoroughly analyze the problem, its context, and its constraints to establish a clear, comprehensive, and shared understanding. This stage focuses on deconstructing the problem into manageable components, identifying key relationships, and defining the scope and boundaries of the analysis.",
              "strategies": [
                {
                  "id": "strategy-cot",
                  "name": "Chain of Thought (CoT)",
                  "description": "Engage in step-by-step reasoning to articulate the problem-solving process, uncovering key insights and potential challenges. This involves explicitly stating each logical step and its justification.",
                  "applicability": "Suitable for most problem types, particularly when a clear and explainable reasoning process is required. Less effective for problems with very high uncertainty or vast search spaces.",
                  "how_to_use_kb_reasoning_advanced": [
                      "Consult `kb_reasoning_advanced#mod-frameworks.basic.method-cot` for detailed implementation steps.",
                      "Refer to `kb_reasoning_advanced#mod-foundation` for principles of precision, coherence, and transparency.",
                      "Use `kb_reasoning_advanced#mod-reasoning-behaviors.settings.self_evaluation` to check the consistency of the reasoning chain."
                  ],
                  "cross_reference": "kb_reasoning_advanced#mod-frameworks.basic.method-cot"
                },
                {
                  "id": "strategy-decomposition",
                  "name": "Decomposition",
                  "description": "Break down complex problems into smaller, more manageable sub-problems, defining clear inputs, outputs, and dependencies for each. This simplifies the problem and allows for modular reasoning.",
                  "applicability": "Ideal for complex problems that can be naturally divided into smaller, independent or semi-independent parts. Less effective for problems that are highly interconnected or require holistic understanding.",
                  "how_to_use_kb_reasoning_advanced": [
                      "Refer to `kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition` for detailed guidance.",
                      "Use `kb_reasoning_advanced#mod-foundation.principle-completeness` to ensure all sub-problems are addressed."
                  ],
                  "cross_reference": "kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition"
                },
                {
                  "id": "strategy-contextual-analysis",
                  "name": "Contextual Analysis",
                  "description": "Thoroughly examine the surrounding circumstances, background information, and relevant factors influencing the problem. This includes understanding the environment, stakeholders (simulated), and potential constraints.",
                  "applicability": "Essential for all problem types, especially those involving real-world scenarios, complex systems, or human factors.",
                  "how_to_use_kb_reasoning_advanced": [
                    "Refer to `kb_reasoning_advanced#mod-foundation.principle-completeness` for guidance on comprehensive analysis."
                  ]
                },
                {
                    "id": "strategy-information-gathering",
                    "name": "Information Gathering (Internal)",
                    "description": "Collect and synthesize all necessary information from the provided knowledge bases (`kb_reasoning_advanced`), ensuring a complete understanding of the problem domain.",
                    "applicability": "Crucial for all problem types, especially those requiring domain-specific knowledge or data analysis.",
                    "how_to_use_kb_reasoning_advanced": [
                        "Use this framework's cross-referencing system to locate relevant information within `kb_reasoning_advanced`."
                    ]
                },
                {
                    "id": "strategy-stakeholder-analysis",
                    "name": "Stakeholder Analysis (Simulated)",
                    "description": "Identify and analyze the key stakeholders involved in the problem and their respective interests, needs, and perspectives (simulated).",
                    "applicability": "Important for problems involving multiple actors, conflicting interests, or social/organizational contexts."
                    ,
                    "how_to_use_kb_reasoning_advanced": [
                        "Use principles of `kb_reasoning_advanced#mod-foundation.principle-completeness` to ensure all relevant stakeholders are considered."
                    ]
                },
                {
                    "id": "strategy-knowledge-integration",
                    "name": "Knowledge Integration",
                    "description": "Actively identify and integrate relevant knowledge from the 'Reasoning Knowledge Base' (`kb_reasoning_advanced`).",
                    "applicability": "Essential for all stages; ensures the agent leverages existing knowledge.",
                    "how_to_use_kb_reasoning_advanced": [
                        "Before applying any strategy, scan `kb_reasoning_advanced` for relevant modules, principles, and techniques.",
                        "Use cross-references within this framework to quickly locate relevant sections in `kb_reasoning_advanced`."
                    ]
                },
                {
                    "id": "strategy-constraint-identification",
                    "name": "Constraint Identification",
                    "description": "Identify and categorize all constraints relevant to the problem, including real-world limitations (simulated), technical restrictions, and resource limitations.",
                    "applicability": "Crucial for all problem types, particularly those with complex, real-world scenarios.",
                    "how_to_use_kb_reasoning_advanced": [
                        "Refer to `kb_reasoning_advanced#mod-reasoning-behaviors.settings.problem_analysis` for guidance on constraint identification."
                    ]
                }
              ],
              "steps": [
                {
                  "id": "step-1.1",
                  "description": "Define the problem clearly and concisely, including its context, background, and any relevant information. Use <thinking> tags for internal analysis. Log interpretation via `agent_reasoning_output_validation#reflection_details.task_interpretation_summary`.",
                  "example": "<thinking>Task: 'Improve customer satisfaction'. Problem: 'Customer satisfaction ratings declined 15% last quarter due to slow response times and unresolved issues.' Logged interpretation.</thinking>"
                },
                {
                  "id": "step-1.2",
                  "description": "Identify the key components, stakeholders (simulated), and relationships involved. Use <thinking> tags.",
                  "example": "<thinking>Components: service team, support channels, product issues. Stakeholders (simulated): customers, reps, dev team. Relationships: customer-rep interaction via channels; issues impact satisfaction.</thinking>"
                },
                {
                  "id": "step-1.3",
                  "description": "Analyze the constraints, limitations, and assumptions. Use <thinking> tags. Log assumptions via `agent_reasoning_output_validation#reflection_details.key_assumptions`.",
                  "example": "<thinking>Constraints: budget, existing tech, staff availability, regulations. Assumptions: customers provide feedback; faster response improves satisfaction. Logged assumptions.</thinking>"
                },
                {
                  "id": "step-1.4",
                  "description": "Employ Chain of Thought (CoT) reasoning (`kb_reasoning_advanced#mod-frameworks.basic.method-cot`) to articulate the problem-solving process step-by-step. Use <thinking> tags.",
                  "example": "<thinking>CoT: 1. Issue: Declining satisfaction. 2. Causes: Slow response, unresolved issues. 3. Impact analysis. 4. Resource check. 5. Formulate questions: Avg response time per channel? Common unresolved issues?</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-frameworks.basic.method-cot"
                },
                {
                  "id": "step-1.5",
                  "description": "Utilize decomposition (`kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition`) for complex problems. Use <thinking> tags.",
                  "example": "<thinking>Decomposition: (1) Analyze response times. (2) Identify unresolved issues. (3) Evaluate feedback channels. (4) Assess current support processes.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-frameworks.intermediate.method-decomposition"
                },
                {
                    "id": "step-1.6",
                    "description": "Define specific, measurable, achievable, relevant, and time-bound (SMART) objectives. Use <thinking> tags.",
                    "example": "<thinking>Objective: Increase satisfaction ratings by 10% next quarter by reducing avg response time < 2hrs and resolving 90% issues on first contact.</thinking>"
                },
                {
                    "id": "step-1.7",
                    "description": "Perform a preliminary assessment of the problem's uncertainty level (high, medium, low). Use <thinking> tags. Log via `agent_reasoning_output_validation#reflection_details.identified_limitations_or_uncertainties`.",
                    "example": "<thinking>Uncertainty assessed as medium. Known factors exist, but exact causes/best solutions unclear. Logged uncertainty.</thinking>"
                },
                {
                    "id": "step-1.8",
                    "description": "Explicitly integrate relevant knowledge from `kb_reasoning_advanced`. Use <thinking> tags. Log via `agent_reasoning_output_validation#reflection_details.contextual_data_usage`.",
                    "example": "<thinking>Integrating from kb_reasoning_advanced: mod-foundation (precision, coherence), mod-frameworks.basic.method-cot, mod-frameworks.intermediate.method-decomposition. Logged context usage.</thinking>"
                }
              ],
                "evaluation_metrics": [
                    {
                        "metric_id": "problem-definition-completeness",
                        "description": "Percentage of key problem elements (components, stakeholders, constraints, objectives) identified.",
                        "target": ">90%"
                    },
                    {
                        "metric_id": "problem-definition-clarity",
                        "description": "Ambiguity score of the problem definition (internal metric, lower is better).",
                        "target": "<0.2" ,
                        "method": "Internal ambiguity detection algorithm (referencing kb_reasoning_advanced principles)"
                    },
                    {
                        "metric_id": "key-questions-identified",
                        "description": "Number of relevant and insightful questions formulated to guide further analysis.",
                        "target": ">3"
                    }
  
                ]
            },
            {
              "id": "stage-solution-exploration",
              "name": "Solution Exploration",
              "description": "Explore and evaluate a diverse range of potential solutions, leveraging multiple strategies from `kb_reasoning_advanced`, encouraging creative thinking, and employing tree-based exploration for parallel evaluation. The agent applies `#principle-contextual-execution-autonomy` to select and potentially hybridize strategies.",
              "strategies": [
                {
                  "id": "strategy-mcts",
                  "name": "Monte Carlo Tree Search (MCTS)",
                  "description": "Utilize MCTS to simulate different scenarios and evaluate the potential outcomes of various decision paths, particularly for problems with large search spaces and uncertainty.",
                  "applicability": "Best suited for problems with a well-defined state space, clear actions, and a way to simulate outcomes (even if imperfectly). Less effective for problems requiring deep creative insight or where simulations are computationally infeasible.",
                  "how_to_use_kb_reasoning_advanced": [
                      "Consult `kb_reasoning_advanced#mod-frameworks.advanced.method-mcts` for detailed implementation steps.",
                      "Use `kb_reasoning_advanced#mod-reasoning-behaviors.settings.self_evaluation` to assess the confidence in simulation results.",
                      "Consider `kb_reasoning_advanced#mod-reasoning-behaviors.settings.alternative_proposal` to explore multiple MCTS trees with different parameters."
                  ],
                  "cross_reference": "kb_reasoning_advanced#mod-frameworks.advanced.method-mcts"
                },
                {
                  "id": "strategy-innovative-reasoning",
                  "name": "Innovative Reasoning",
                  "description": "Encourage the generation of novel and unconventional solutions by exploring analogies, metaphors, lateral thinking, and challenging assumptions.",
                  "applicability": "Useful for problems where existing solutions are inadequate or where a breakthrough is needed. Particularly valuable in design, strategy, and creative problem-solving.",
                  "how_to_use_kb_reasoning_advanced": [
                    "Refer to `kb_reasoning_advanced#mod-advanced-reasoning.tech-analogical-reasoning` for guidance on analogical reasoning.",
                    "Use the principles of `kb_reasoning_advanced#mod-foundation.principle-adaptability` to encourage flexible thinking."
                  ],
                  "techniques": [
                    { "id": "technique-analogical-reasoning", "description": "Draw parallels between the current problem and seemingly unrelated situations to identify potential solutions.", "cross_reference": "kb_reasoning_advanced#mod-advanced-reasoning.tech-analogical-reasoning" },
                    { "id": "technique-metaphorical-thinking", "description": "Use metaphors to reframe the problem and stimulate new ways of thinking." },
                    { "id": "technique-lateral-thinking", "description": "Approach the problem indirectly and creatively, often by challenging existing assumptions." },
                    { "id": "technique-assumption-challenging", "description": "Identify and question underlying assumptions to uncover new possibilities." },
                    { "id": "technique-perspective-shifting", "description": "Consider the problem from different viewpoints, such as those of various stakeholders or experts in other fields." }
                  ]
                },
                {
                    "id": "strategy-cot-exploration",
                    "name": "Chain of Thought (CoT)",
                    "description": "Systematically explore the implications of each potential solution, articulating the reasoning process step-by-step. This helps to ensure logical consistency and identify potential consequences.",
                    "applicability": "Useful for evaluating the logical consequences of a solution and for ensuring a clear and explainable reasoning process. Can be combined with other strategies.",
                    "how_to_use_kb_reasoning_advanced": [
                        "Consult `kb_reasoning_advanced#mod-frameworks.basic.method-cot` for detailed implementation steps.",
                        "Use `kb_reasoning_advanced#mod-reasoning-behaviors.settings.self_evaluation` to check the consistency of the reasoning chain."
                    ],
                    "cross_reference": "kb_reasoning_advanced#mod-frameworks.basic.method-cot"
                },
                {
                    "id": "strategy-tot",
                    "name": "Tree of Thought (ToT)",
                    "description": "Explore multiple solution paths simultaneously, evaluating their potential benefits and drawbacks in a tree-like structure. This allows for parallel exploration and comparison of different options.",
                    "applicability": "Well-suited for problems with multiple possible solutions or where the consequences of decisions are complex and interconnected. Less effective for problems with a very large number of potential solutions.",
                    "how_to_use_kb_reasoning_advanced": [
                        "Refer to `kb_reasoning_advanced#mod-frameworks.intermediate.method-tot` for detailed guidance.",
                        "Combine with MCTS for probabilistic evaluation of branches.",
                        "Use `kb_reasoning_advanced#mod-reasoning-behaviors.settings.alternative_proposal` to manage multiple branches."
                    ],
                    "cross_reference": "kb_reasoning_advanced#mod-frameworks.intermediate.method-tot"
                },
                {
                    "id": "strategy-tree-exploration",
                    "name": "Tree-Based Exploration (General)",
                    "description": "Generate multiple solution candidates concurrently as branches of a tree (can encompass ToT, MCTS, Bi-Point Tree). Each branch represents a different direction of improvement or a different approach. Note: This is a general approach. Specific implementations like ToT (`#strategy-tot`), MCTS (`#strategy-mcts`), or Bi-Point Tree (`kb_reasoning_advanced#mod-frameworks.advanced.method-bi-point-tree`) follow this pattern but add specific mechanisms for generation, evaluation, and/or critique.",
                    "applicability": "Suitable for complex problems where multiple solutions need to be explored and compared in parallel. Enhances creativity and reduces the risk of premature convergence.",
                    "how_to_use_kb_reasoning_advanced": [
                        "Refer to `kb_reasoning_advanced#mod-frameworks.intermediate.method-tot` or `kb_reasoning_advanced#mod-frameworks.advanced.method-bi-point-tree` for structure guidance.",
                        "Use `kb_reasoning_advanced#mod-reasoning-behaviors.settings.alternative_proposal` to manage branches.",
                        "Combine with `kb_reasoning_advanced#mod-search-strategy` for efficient exploration and pruning."
                    ],
                    "implementation": [
                        "Initialize a tree with the problem statement as the root node.",
                        "At each level, generate multiple child nodes representing different solution approaches or refinements.",
                        "Explore branches in parallel, evaluating each path independently.",
                        "Use pruning techniques (see `#principle-node-pruning`) to focus on promising branches."
                    ]
                },
                {
                    "id": "strategy-brainstorming",
                    "name": "Brainstorming (Simulated)",
                    "description": "Generate a wide range of ideas without initial judgment, fostering creativity and exploration. This is often used in the early stages of solution exploration.",
                    "applicability": "Useful for generating a large number of potential solutions quickly. Less effective for evaluating the quality or feasibility of solutions.",
                    "how_to_use_kb_reasoning_advanced": [
                        "Combine with other strategies (e.g., CoT, ToT, Bi-Point Tree) for subsequent evaluation and refinement."
                    ]
                },
                {
                    "id": "strategy-constraint-relaxation",
                    "name": "Constraint Relaxation (Simulated)",
                    "description": "Temporarily relax or remove constraints to explore a wider range of possibilities, then re-impose constraints to refine the solutions.",
                    "applicability": "Useful when the problem is overly constrained and prevents the generation of potentially valuable solutions.",
                    "how_to_use_kb_reasoning_advanced": [
                        "Use in conjunction with innovative reasoning techniques."
                    ]
                },
                {
                    "id": "strategy-external-information-request",
                    "name": "External Information Request (Simulated)",
                    "description": "Formulate and execute requests for external information (e.g., web searches) when internal knowledge is insufficient. This is a *thought experiment* as the agent is self-contained, but it should reason *as if* it could access external information.",
                    "applicability": "When the problem requires information not available in the internal knowledge bases.",
                    "implementation": [
                        "Identify specific information gaps.",
                        "Formulate precise queries to retrieve the needed information.",
                        "Evaluate the credibility and relevance of retrieved information (hypothetically).",
                        "Integrate the information into the reasoning process."
                    ]
                },
                {
                    "id": "strategy-clarification-request",
                    "name": "Clarification Request (Simulated)",
                    "description": "Formulate and (hypothetically) pose questions to clarify ambiguities or obtain missing information from the problem statement.",
                    "applicability": "When the problem statement is unclear, incomplete, or ambiguous.",
                    "implementation": [
                        "Identify specific ambiguities or missing information.",
                        "Formulate clear and concise questions to resolve the uncertainties."
                    ]
                }
              ],
              "steps": [
                {
                  "id": "step-2.1",
                  "description": "Employ Monte Carlo Tree Search (MCTS), if selected based on context (`#principle-contextual-execution-autonomy`) and applicable (`kb_reasoning_advanced#mod-frameworks.advanced.method-mcts`), to simulate scenarios and evaluate potential outcomes. Use <thinking> tags.",
                  "example": "<thinking>Context suggests high uncertainty; MCTS selected. Using MCTS to model marketing strategy impact. Simulating scenarios for ROI/market share.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-frameworks.advanced.method-mcts"
                },
                {
                  "id": "step-2.2",
                  "description": "Encourage innovative reasoning (`#strategy-innovative-reasoning`) by applying techniques like analogy, metaphor, lateral thinking, assumption challenging. Use <thinking> tags.",
                  "example": "<thinking>Improving customer service: Analogy to hospitality? Metaphor: 'service as journey'? Challenge assumptions about 'good' service? Perspectives: customer, rep, manager.</thinking>"
                },
                {
                    "id": "step-2.3",
                    "description": "Utilize Chain of Thought (CoT) (`kb_reasoning_advanced#mod-frameworks.basic.method-cot`) to systematically explore implications of potential solutions. Use <thinking> tags.",
                    "example": "<thinking>CoT for CRM solution: 1. Centralize data. 2. Enable personalization. 3. Improve engagement. 4. Increase satisfaction. 5. Con: Cost/training needed.</thinking>",
                    "cross_reference": "kb_reasoning_advanced#mod-frameworks.basic.method-cot"
                },
                {
                    "id": "step-2.4",
                    "description": "Apply Tree-Based Exploration (`#strategy-tree-exploration`), potentially using a specific structure like ToT (`#strategy-tot`) or Bi-Point Tree (`kb_reasoning_advanced#mod-frameworks.advanced.method-bi-point-tree`) as selected by agent autonomy (`#principle-contextual-execution-autonomy`), to explore multiple solution paths simultaneously. Use <thinking> tags.",
                    "example": "<thinking>Agent selects Bi-Point Tree structure for design task. Initializing tree. Level 1 Branches (Solution Nodes): Sol 1 (Training), Sol 2 (Tech), Sol 3 (Process Redesign). Apply node pruning based on initial scores.</thinking>",
                    "cross_reference": "kb_reasoning_advanced#mod-frameworks.intermediate.method-tot"
                },
                {
                  "id": "step-2.5",
                  "description": "Synthesize insights from different techniques to refine and combine solutions, creating hybrid approaches based on agent judgment (`#principle-contextual-execution-autonomy`). Use <thinking> tags.",
                  "example": "<thinking>Combining MCTS simulation results with innovative ideas. Integrating CoT analysis within ToT branches. Rationale: Hybrid approach deemed most promising for this context.</thinking>"
                },
                {
                    "id": "step-2.6",
                    "description": "Generate a diverse set of potential solutions. Use <thinking> tags. Log alternatives considered via `agent_reasoning_output_validation#reflection_details.alternative_approaches_considered`.",
                    "example": "<thinking>Solutions: 1. Improve training. 2. New CRM. 3. Self-service portal. 4. Proactive support. 5. Loyalty program. Logged alternatives.</thinking>"
                },
                {
                    "id": "step-2.7",
                    "description": "If necessary, formulate and (hypothetically) execute requests for external information or clarification. Use <thinking> tags.",
                    "example": "<thinking>Problem lacks target demographic for new product. Formulate clarification: 'What is the target demographic?'</thinking>"
                },
                {
                    "id": "step-2.8",
                    "description": "If using Bi-Point Thinking (`#principle-bi-point-thinking`), generate initial review comments (Comment Nodes) for each generated solution (Solution Node). Use <thinking> tags.",
                    "example": "<thinking>Bi-Point Step: Generating Comment Nodes for Level 1 Solution Nodes. Sol 1 (Training) -> Comment 1: May not address tech/process root cause. Sol 2 (CRM) -> Comment 2: High cost/training needs.</thinking>"
                }
              ],
                "evaluation_metrics": [
                    {
                        "metric_id": "num-solutions-generated",
                        "description": "The number of distinct potential solutions generated.",
                        "target": ">5"
                    },
                    {
                        "metric_id": "solution-diversity",
                        "description": "A measure of how different the generated solutions are (e.g., 1 - avg pairwise cosine similarity).",
                        "target": ">0.3" ,
                        "method": "Calculate average pairwise cosine similarity of solution descriptions (lower similarity = higher diversity)."
                    },
                    {
                        "metric_id": "estimated-potential",
                        "description": "An estimated potential value or score for each solution (based on simulations, heuristics, or preliminary analysis).",
                        "target": "N/A (used for comparison and pruning)"
                    }
                ]
            },
            {
              "id": "stage-solution-evaluation",
              "name": "Solution Evaluation",
              "description": "Critically assess proposed solutions to ensure their validity, feasibility, and alignment with the problem's requirements. Employ rigorous evaluation mechanisms (from `kb_reasoning_advanced`) and identify potential areas for improvement. This stage focuses on analyzing strengths/weaknesses, risks/limitations, and selecting promising options. Bi-point thinking's 'Comment Nodes' are crucial here.",
              "strategies": [
                {
                  "id": "strategy-reflection-mechanisms",
                  "name": "Reflection Mechanisms",
                  "description": "Involve a systematic review of the reasoning process, assumptions, and potential biases. Include self-questioning, seeking external feedback (simulated), and comparing the solution against predefined criteria.",
                  "techniques": [
                    { "id": "technique-self-questioning", "description": "Pose critical questions about the solution's logic, completeness, feasibility, weaknesses." },
                    { "id": "technique-external-feedback", "description": "Simulate input from others to gain different perspectives." },
                    { "id": "technique-criteria-comparison", "description": "Evaluate the solution against predefined criteria or benchmarks." }
                  ],
                    "cross_reference": "kb_reasoning_advanced#mod-self-reflection_config"
                },
                {
                  "id": "strategy-iterative-processes-eval",
                  "name": "Iterative Evaluation",
                  "description": "Continuously refine evaluations based on feedback and analysis.",
                  "cross_reference": "kb_reasoning_advanced#mod-implementation.feedback_and_improvement"
                },
                {
                  "id": "strategy-logical-validation",
                  "name": "Logical Validation",
                  "description": "Ensure the solution is logically sound and consistent with constraints and objectives.",
                  "cross_reference": "kb_reasoning_advanced#mod-validation.comp-logical-validation"
                },
                {
                    "id": "strategy-risk-assessment",
                    "name": "Risk Assessment",
                    "description": "Identify and evaluate potential risks, limitations, and trade-offs associated with each solution."
                },
                {
                    "id": "strategy-cost-benefit-analysis",
                    "name": "Cost-Benefit Analysis (Simulated)",
                    "description": "Weigh the potential costs and benefits of each solution to determine its overall value."
                },
                {
                    "id": "strategy-feasibility-analysis",
                    "name": "Feasibility Analysis",
                    "description": "Assess the practicality and implementability of each solution, considering available resources (simulated), constraints, and potential obstacles.",
                    "cross_reference": "kb_reasoning_advanced#mod-validation.comp-constraint-feasibility-check"
                },
                {
                    "id": "strategy-bi-point-evaluation",
                    "name": "Bi-Point Evaluation",
                    "description": "Use the 'Comment Nodes' generated in the tree-based exploration (Bi-Point Thinking) to critically evaluate the corresponding 'Solution Nodes'. Analyze comments for validity, relevance, and impact.",
                    "implementation": [
                        "For each Solution Node, analyze its associated Comment Node(s).",
                        "Assess the validity and relevance of each comment.",
                        "Determine the potential impact of the comment on the solution's quality/feasibility.",
                        "Use comments to identify weaknesses, limitations, constraint violations, or areas for improvement."
                    ],
                    "cross_reference": "#principle-bi-point-thinking"
                }
              ],
              "steps": [
                {
                  "id": "step-3.1",
                  "description": "Apply reflection mechanisms (`kb_reasoning_advanced#mod-self-reflection_config`) to critically review reasoning, biases, assumptions. Use <thinking> tags.",
                  "example": "<thinking>Self-reflection: Assumptions justified? Alternatives considered? Weaknesses? Unintended consequences? Biases present? Logged reflection details.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-self-reflection_config"
                },
                {
                  "id": "step-3.2",
                  "description": "Engage in iterative evaluation processes, refining assessments based on new information or analysis. Use <thinking> tags.",
                  "example": "<thinking>Iterative eval: Initial assessment -> Deeper analysis of feasibility -> Refined scoring.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-implementation.feedback_and_improvement"
                },
                {
                  "id": "step-3.3",
                  "description": "Perform logical validation (`kb_reasoning_advanced#mod-validation.comp-logical-validation`) for soundness and consistency. Use <thinking> tags.",
                  "example": "<thinking>Logical validation: Steps follow? No contradictions? Addresses all objectives? Meets success criteria? Logged validation check.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-validation.comp-logical-validation"
                },
                {
                  "id": "step-3.4",
                  "description": "Identify and address potential risks, limitations, and trade-offs. Use <thinking> tags.",
                  "example": "<thinking>Risk assessment: New tech risks (cost, security)? Solution limitations (scalability)? Trade-offs (cost vs quality)?</thinking>"
                },
                {
                    "id": "step-3.5",
                    "description": "Compare and contrast potential solutions based on evaluation criteria (logical validity, feasibility, risk, alignment, cost/benefit). Critically incorporate feedback from 'Comment Nodes' (`#strategy-bi-point-evaluation`). Use <thinking> tags.",
                    "example": "<thinking>Comparison Matrix: Sol A vs Sol B vs Sol C on Cost, Effectiveness, Feasibility, Risk, Time. Comment Node for Sol A highlighted scalability issue - factored into feasibility score.</thinking>"
                },
                {
                    "id": "step-3.6",
                    "description": "Select the most promising solution(s) for refinement/implementation, justifying the selection based on evaluation. Use <thinking> tags. Log rationale via `agent_reasoning_output_validation#reflection_details.rationale_for_final_output`.",
                    "example": "<thinking>Selection: Sol A chosen. Best balance of effectiveness/feasibility/cost despite longer implementation. Comment Node issues deemed addressable in refinement. Logged rationale.</thinking>"
                },
                {
                    "id": "step-3.7",
                    "description": "Document the evaluation process, criteria, assessments, and selection rationale. Use <thinking> tags. Log via `agent_reasoning_output_validation`.",
                    "example": "<thinking>Documenting evaluation matrix, criteria weights, justification for Sol A. Included points from Comment Nodes. Logged evaluation summary.</thinking>"
                },
                {
                    "id": "step-3.8",
                    "description": "Apply node pruning (`#principle-node-pruning`) based on evaluation scores. Retain top-scoring solution paths for further exploration/refinement. Use <thinking> tags.",
                    "example": "<thinking>Node Pruning: Evaluated all Level 'i' solution nodes. Retained top 3 based on combined solution/comment scores. Pruned others.</thinking>"
                }
              ],
                "evaluation_metrics": [
                    {
                        "metric_id": "logical-validity-score",
                        "description": "Score (0-1) representing logical soundness (internal check).",
                        "target": ">0.9",
                        "method": "Automated logical validation checks (ref: `kb_reasoning_advanced#mod-validation`)"
                    },
                    {
                        "metric_id": "feasibility-score",
                        "description": "Score (0-1) representing practicality and implementability (internal check).",
                        "target": ">0.8",
                        "method": "Assessment based on resource availability (simulated), technical feasibility, constraints (ref: `kb_reasoning_advanced#mod-validation.comp-constraint-feasibility-check`)"
                    },
                    {
                        "metric_id": "risk-score",
                        "description": "Score (0-1) representing assessed risk level (lower is better).",
                        "target": "<0.3",
                        "method": "Risk assessment based on identified potential risks and likelihood/impact."
                    },
                    {
                        "metric_id": "alignment-score",
                        "description": "Score (0-1) representing alignment with problem objectives/criteria.",
                        "target": ">0.9",
                        "method": "Comparison of solution features/outcomes with defined objectives."
                    },
                    {
                        "metric_id": "comment-quality-score",
                        "description": "Score (0-1) representing quality/usefulness of Bi-Point 'Comment Nodes' (if used). Higher = more insightful.",
                        "target": ">0.7",
                        "method": "Internal assessment based on relevance, specificity, potential impact (ref: `kb_reasoning_advanced#mod-advanced-reasoning.tech-iterative-critique-refinement`)."
                    }
                ]
            },
            {
              "id": "stage-solution-refinement",
              "name": "Solution Refinement",
              "description": "Iteratively improve and optimize the selected solution(s) through structured feedback (internal validation via `agent_reasoning_output_validation`), evaluation, and adaptation. Incorporate new insights and address identified weaknesses (especially from Bi-Point 'Comment Nodes') to enhance quality, effectiveness, feasibility, and robustness.",
              "strategies": [
                { "id": "strategy-iterative-processes-refinement", "name": "Iterative Processes", "description": "Continuously refine the solution through multiple cycles of development, testing (simulated), and feedback.", "cross_reference": "kb_reasoning_advanced#mod-implementation.feedback_and_improvement" },
                { "id": "strategy-feedback-integration", "name": "Feedback Integration", "description": "Actively solicit and incorporate feedback from various sources (internal evaluations via `agent_reasoning_output_validation`, performance data simulation, Bi-Point 'Comment Nodes') to identify areas for improvement.", "cross_reference": "kb_reasoning_advanced#mod-implementation.feedback_and_improvement" },
                { "id": "strategy-error-analysis", "name": "Error Analysis", "description": "Systematically analyze errors, failures, constraint violations, and unexpected outcomes to identify root causes and implement corrective actions.", "cross_reference": "kb_reasoning_advanced#mod-validation", "logging": "`agent_reasoning_output_validation#error_analysis`" },
                {
                    "id": "strategy-a-b-testing",
                    "name": "A/B Testing (Simulated)",
                    "description": "Compare different versions of the solution (or components) to determine which performs better based on defined metrics."
                },
                {
                    "id": "strategy-sensitivity-analysis",
                    "name": "Sensitivity Analysis (Simulated)",
                    "description": "Assess how changes in input parameters or assumptions affect the solution's outcome."
                },
                {
                    "id": "strategy-parameter-optimization",
                    "name": "Parameter Optimization",
                    "description": "Fine-tune the parameters of the solution to achieve optimal performance."
                },
                {
                    "id": "strategy-bi-point-refinement",
                    "name": "Bi-Point Refinement",
                    "description": "Utilize the 'Comment Nodes' generated through Bi-Point Thinking as the primary driver for refinement. Each comment identifies a specific weakness or area for improvement in the corresponding Solution Node.",
                    "implementation": [
                        "Prioritize addressing comments based on their helpfulness score and potential impact.",
                        "For each high-priority comment, generate a new Solution Node that directly addresses the identified issue.",
                        "Ensure that the refined solution incorporates the feedback from the comment while maintaining overall coherence, feasibility, and constraint satisfaction."
                    ],
                    "cross_reference": "#principle-bi-point-thinking"
                }
  
              ],
              "steps": [
                {
                  "id": "step-4.1",
                  "description": "Implement iterative processes (`kb_reasoning_advanced#mod-implementation.feedback_and_improvement`) for continuous refinement. Prioritize addressing issues raised in 'Comment Nodes' (`#strategy-bi-point-refinement`) if applicable. Use <thinking> tags.",
                  "example": "<thinking>Iteration 2: Addressing Comment Node #X (scalability issue). Generating refined Sol A.v2 with improved architecture.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-implementation.feedback_and_improvement"
                },
                {
                  "id": "step-4.2",
                  "description": "Actively integrate feedback from internal validation (`agent_reasoning_output_validation`), simulated data, and especially 'Comment Nodes' to guide refinement. Use <thinking> tags.",
                  "example": "<thinking>Feedback Integration: Comment Node #Y identified risk of soil instability. Refining foundation design based on this critique.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-implementation.feedback_and_improvement"
                },
                {
                  "id": "step-4.3",
                  "description": "Conduct error analysis (`#strategy-error-analysis`) to identify recurring issues or weaknesses. Investigate root causes and implement corrections. Use <thinking> tags. Log errors via `agent_reasoning_output_validation#error_analysis`.",
                  "example": "<thinking>Error Analysis: Simulation showed constraint violation under condition Z. Root cause identified. Corrective action: Added check mechanism. Logged error.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-validation"
                },
                {
                  "id": "step-4.4",
                  "description": "Adapt solutions dynamically (`kb_reasoning_advanced#mod-implementation.dynamic_adaptation`) based on new information or changing requirements. Use <thinking> tags.",
                  "example": "<thinking>Adaptation: New constraint identified mid-refinement. Adjusting solution component to comply.</thinking>"
                },
                {
                    "id": "step-4.5",
                    "description": "Refine the solution's parameters, components, or algorithms to optimize performance, efficiency, feasibility, and robustness. Use <thinking> tags.",
                    "example": "<thinking>Optimization: Tuning algorithm parameters in Sol A.v2 for better simulated efficiency based on profiling.</thinking>"
                },
                {
                    "id": "step-4.6",
                    "description": "Conduct sensitivity analysis (`#strategy-sensitivity-analysis`) to understand impact of parameter/assumption changes. Use <thinking> tags.",
                    "example": "<thinking>Sensitivity Analysis: Testing impact of varying simulated load on Sol A.v2 performance.</thinking>"
                },
                {
                    "id": "step-4.7",
                    "description": "Perform A/B testing (`#strategy-a-b-testing`) to compare refined versions if applicable. Use <thinking> tags.",
                    "example": "<thinking>A/B Test: Comparing Sol A.v2 vs Sol A.v3 (alternative refinement) on key metrics in simulation.</thinking>"
                },
                {
                    "id": "step-4.8",
                    "description": "Document all refinements, adjustments, and optimizations, including rationale (especially citing Comment Nodes) and impact. Use <thinking> tags. Log via `agent_reasoning_output_validation#refinement_actions_taken`.",
                    "example": "<thinking>Documentation: Logged refinement from Sol A.v1 to Sol A.v2 addressing Comment Node #X. Observed +15% simulated performance improvement. Logged refinement action.</thinking>"
                }
              ],
                "evaluation_metrics": [
                    {
                        "metric_id": "performance-improvement",
                        "description": "Percentage improvement in key performance indicators (KPIs) after each refinement iteration (simulated).",
                        "target": "Variable, positive trend expected."
                    },
                    {
                        "metric_id": "error-reduction",
                        "description": "Percentage reduction in error rate or frequency of issues after each refinement iteration (simulated).",
                        "target": "Variable, downward trend expected."
                    },
                    {
                        "metric_id": "quality-score-increase",
                        "description": "Increase in overall quality score assessed via `agent_reasoning_output_validation` after refinement.",
                        "target": "Positive Trend"
                    },
                    {
                        "metric_id": "comment-address-rate",
                        "description": "Percentage of high-priority 'Comment Nodes' from the previous level addressed in the refined solution (if Bi-Point used).",
                        "target": ">80%"
                    }
                ]
            },
            {
              "id": "stage-implementation-monitoring",
              "name": "Implementation and Monitoring (Simulated)",
              "description": "Simulate the execution of the chosen, refined solution, monitor its simulated performance against metrics, and adapt as needed to ensure successful implementation and long-term effectiveness within the simulated context.",
              "strategies": [
                { "id": "strategy-fallback-mechanisms", "name": "Fallback Mechanisms", "description": "Establish contingency plans and alternative solutions (simulated) to address potential issues, risks, or failures during implementation.", "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-robustness" },
                { "id": "strategy-iterative-processes-monitoring", "name": "Iterative Monitoring & Adaptation", "description": "Continuously monitor simulated performance and adapt the solution based on real-world simulated feedback.", "cross_reference": "kb_reasoning_advanced#mod-implementation.feedback_and_improvement" },
                {
                  "id": "strategy-performance-monitoring",
                  "name": "Performance Monitoring (Simulated)",
                  "description": "Track key performance indicators (KPIs) and other metrics to assess the effectiveness of the implemented solution in simulation. Set up monitoring systems, collect data, analyze performance, and generate reports.",
                  "techniques": [
                    { "id": "technique-kpi-tracking", "description": "Identify and track relevant KPIs." },
                    { "id": "technique-data-collection", "description": "Simulate data collection." },
                    { "id": "technique-performance-analysis", "description": "Analyze simulated data for trends/patterns." },
                    { "id": "technique-reporting", "description": "Generate internal performance reports." }
                  ]
                },
                {
                    "id": "strategy-change-management",
                    "name": "Change Management (Simulated)",
                    "description": "Manage the simulated organizational and human aspects of implementing the solution."
                },
                {
                    "id": "strategy-communication-plan",
                    "name": "Communication Plan (Internal/Simulated)",
                    "description": "Develop a plan for communicating progress/issues internally or simulating stakeholder communication."
                }
              ],
              "steps": [
                {
                  "id": "step-5.1",
                  "description": "Develop a detailed implementation plan (simulated) outlining steps, resources, timeline. Use <thinking> tags.",
                  "example": "<thinking>Implementation Plan: Tasks, milestones, responsibilities, deadlines for simulated rollout of new process. Resource allocation (simulated staff, budget).</thinking>"
                },
                {
                  "id": "step-5.2",
                  "description": "Establish performance monitoring mechanisms (simulated) to track key metrics. Use <thinking> tags.",
                  "example": "<thinking>Monitoring Setup: Defining KPIs (response time, satisfaction, resolution rate). Setting up simulated dashboards/reporting.</thinking>"
                },
                {
                  "id": "step-5.3",
                  "description": "Implement fallback mechanisms (`kb_reasoning_advanced#mod-foundation.principle-robustness`) for potential issues. Use <thinking> tags.",
                  "example": "<thinking>Fallback Plan: If simulated response time > threshold, trigger fallback (e.g., revert to old process simulation, simulate adding resources). Define triggers.</thinking>",
                  "cross_reference": "kb_reasoning_advanced#mod-foundation.principle-robustness"
                },
                {
                  "id": "step-5.4",
                  "description": "Continuously monitor simulated performance and adapt the solution based on data, feedback, changing circumstances. Use <thinking> tags.",
                  "example": "<thinking>Monitoring & Adaptation: Reviewing simulated performance data. Adjusting process/parameters as needed. Iterating based on simulated outcomes.</thinking>"
                },
                {
                    "id": "step-5.5",
                    "description": "Document the simulated implementation process, challenges, solutions, lessons learned. Use <thinking> tags.",
                    "example": "<thinking>Documentation: Logging simulated implementation activities, deviations, issues encountered, resolutions. Summarizing lessons learned.</thinking>"
                },
                {
                    "id": "step-5.6",
                    "description": "Communicate effectively (internally or simulated) throughout the implementation process. Use <thinking> tags.",
                    "example": "<thinking>Communication: Internal updates on simulated progress, challenges, results. Addressing simulated stakeholder concerns.</thinking>"
                }
              ],
                "evaluation_metrics": [
                    {
                        "metric_id": "kpi-performance",
                        "description": "Performance against key performance indicators (KPIs) during simulation.",
                        "target": "Meet or exceed predefined KPI targets."
                    },
                    {
                        "metric_id": "implementation-timeline",
                        "description": "Adherence to the simulated implementation timeline.",
                        "target": "Complete implementation within the defined timeframe."
                    },
                    {
                        "metric_id": "budget-adherence",
                        "description": "Adherence to the simulated allocated budget.",
                        "target": "Stay within the allocated budget."
                    },
                    {
                        "metric_id": "stakeholder-satisfaction",
                        "description": "Level of satisfaction among simulated stakeholders with the implementation process and outcomes.",
                        "target": ">4 (on a 5-point scale)",
                        "method": "Simulated stakeholder feedback or internal assessment."
                    }
                ]
            }
          ]
        },
        "feedback_loop": {
          "id": "feedback_loop",
          "description": "A continuous process embedded across all stages of the problem-solving framework to ensure iterative improvement, adaptation, and learning. This loop facilitates the incorporation of new information, insights, performance data (simulated), and internal validation results (`agent_reasoning_output_validation`), including feedback from Bi-Point 'Comment Nodes'.",
          "steps": [
            { "id": "step-feedback-1", "description": "Collect feedback: Internal validation results (`agent_reasoning_output_validation`), simulated performance data, internal evaluations, and *critically* the 'Comment Nodes' (if Bi-Point Thinking used)." },
            { "id": "step-feedback-2", "description": "Analyze feedback: Identify patterns, trends, strengths, weaknesses, areas for improvement. Prioritize feedback from 'Comment Nodes' highlighting deficiencies or suggesting improvements." },
            { "id": "step-feedback-3", "description": "Incorporate feedback: Refine solutions, adjust strategies, update internal knowledge. Use comments to guide generation of new Solution Nodes in tree-based exploration." },
            { "id": "step-feedback-4", "description": "Repeat continuously: Create a closed-loop system driving ongoing learning, adaptation, and optimization." }
          ],
          "integration_points": [
            "Problem Understanding: Refine problem definition, identify constraints, uncover assumptions.",
            "Solution Exploration: Guide generation/evaluation of solutions. 'Comment Nodes' are primary feedback.",
            "Solution Evaluation: Provide critical assessment data. 'Comment Nodes' provide structured feedback.",
            "Solution Refinement: Drive iterative improvements. 'Comment Nodes' directly inform refinement.",
            "Implementation and Monitoring (Simulated): Inform adjustments for long-term simulated success."
          ]
        },
        "best_practices": [
          { "id": "bp_1", "description": "Combine multiple problem-solving strategies from `kb_reasoning_advanced` (incl. tree-based exploration, bi-point thinking) for comprehensive analysis." },
          { "id": "bp_2", "description": "Iterate on solutions using embedded feedback loops (`#feedback_loop`) and internal validation (`agent_reasoning_output_validation`). Prioritize feedback from bi-point 'Comment Nodes'." },
          { "id": "bp_3", "description": "Tailor strategies to problem context, complexity, and requirements using `#strategy_selection_guidance` and agent judgment (`#principle-contextual-execution-autonomy`)." },
          { "id": "bp_4", "description": "Encourage creative approaches using techniques from `kb_reasoning_advanced#mod-advanced-reasoning`." },
          { "id": "bp_5", "description": "Document insights, decisions, assumptions, and improvements via `agent_reasoning_output_validation#reflection_details`. Document solution tree evolution." },
          { "id": "bp_6", "description": "Utilize fallback mechanisms guided by `kb_reasoning_advanced#mod-foundation.principle-robustness`." },
          { "id": "bp_7", "description": "Employ clear and unambiguous language (`#principle-clarity`)." },
          { "id": "bp_8", "description": "Define specific, measurable, achievable, relevant, and time-bound (SMART) objectives." },
          { "id": "bp_9", "description": "Actively seek and incorporate feedback (internal validation, simulated user feedback, bi-point 'Comment Nodes') to improve quality and address biases." },
          { "id": "bp_10", "description": "Leverage `kb_reasoning_advanced` extensively to ensure self-sufficiency." },
          { "id": "bp_11", "description": "Use <thinking> tags for internal reasoning, logging key details via `agent_reasoning_output_validation`, selectively revealing portions for justification." },
          { "id": "bp_12", "description": "Prioritize solutions that are effective and efficient (`#principle-efficiency`). Utilize node pruning (`#principle-node-pruning`) to maintain efficiency." },
          { "id": "bp_13", "description": "Regularly review and update this problem-solving framework itself based on performance and new insights." },
          { "id": "bp_14", "description": "Utilize tree-based exploration (`#principle-tree-based-exploration`) to generate and explore multiple solution pathways concurrently." },
          { "id": "bp_15", "description": "Employ bi-point thinking (`#principle-bi-point-thinking`), alternating between solution generation and critical review via 'Comment Nodes'." },
          { "id": "bp_16", "description": "Implement node pruning (`#principle-node-pruning`) based on evaluation scores to focus resources on promising solution paths." },
          { "id": "bp_17", "description": "Exercise contextual execution autonomy (`#principle-contextual-execution-autonomy`) by critically analyzing the problem and framework to select, combine, or adapt the most effective strategies, rather than rigidly following a single path." }
        ],
        "output_requirements": {
          "clarity": {
            "id": "or_clarity",
            "description": "Responses must be logically structured, unambiguous, and easy to understand, with clear explanations. Avoid jargon unless defined."
          },
          "completeness": {
            "id": "or_completeness",
            "description": "All relevant aspects of the task must be addressed comprehensively, with no significant gaps. Solution should be self-contained."
          },
          "adaptability": {
            "id": "or_adaptability",
            "description": "Solutions must be flexible, creative, and aligned with contextual needs, demonstrating adaptability."
          },
          "self_sufficiency": {
            "id": "or_self_sufficiency",
            "description": "Solutions must be self-contained and executable relying only on this framework and `kb_reasoning_advanced`."
          },
          "quality": {
            "id": "or_quality",
            "description": "The output must achieve a quality score of 10/10, reflecting highest standards, verified via `agent_reasoning_output_validation#response_quality_assessment` and `agent_reasoning_output_validation#confidence_assessment`."
          },
          "justification": {
            "id": "or_justification",
            "description": "Include justifications for key decisions, selectively revealing internal reasoning logged in `agent_reasoning_output_validation#reflection_details` when beneficial."
          },
          "conciseness": {
            "id": "or_conciseness",
            "description": "While complete, responses should be concise, avoiding unnecessary verbosity."
          },
          "actionability": {
              "id": "or_actionability",
              "description": "Solutions should be presented in a way that is actionable and readily implementable (within the agent's context), providing clear steps where appropriate."
          }
        },
          "reasoning_behaviors_config": {
            "id": "mod-reasoning-behaviors",
            "description": "Configures core reasoning behaviors for the agent executing this framework, referencing detailed definitions in `kb_reasoning_advanced`.",
            "settings": {
              "self_evaluation": {
                "enabled": true,
                "description": "Enables assessment of own outputs/processes (quality, correctness, feasibility).",
                "methods": [ "Self-consistency checking", "Confidence estimation", "Uncertainty quantification", "Bias detection", "Completeness checking", "Constraint verification" ],
                "cross_reference": "kb_reasoning_advanced#mod-reasoning-behaviors.settings.self_evaluation"
              },
              "task_decomposition": {
                "enabled": true,
                "description": "Allows breakdown of complex tasks into manageable subtasks.",
                "methods": [ "Hierarchical", "Sequential", "Conditional" ],
                 "cross_reference": "kb_reasoning_advanced#mod-reasoning-behaviors.settings.task_decomposition"
              },
              "alternative_proposal": {
                "enabled": true,
                "description": "Enables generation of multiple alternative solutions/paths (core to tree exploration).",
                "methods": [ "Branching exploration (ToT, Bi-Point Tree)", "Diversity generation", "Ensemble methods" ],
                "cross_reference": "kb_reasoning_advanced#mod-reasoning-behaviors.settings.alternative_proposal"
              },
              "self_correction":{
                "enabled": true,
                "description": "Allows detection and correction of errors based on self-evaluation or critique.",
                "methods": [ "Logical validation triggers", "Consistency checks", "Feedback/Critique incorporation" ],
                "cross_reference": "kb_reasoning_advanced#mod-reasoning-behaviors.settings.self_correction"
              },
              "problem_analysis":{
                "enabled": true,
                "description": "Enables thorough analysis of problem, context, constraints before solving.",
                "methods":[ "Contextual analysis", "Constraint identification", "Goal definition" ],
                "cross_reference": "kb_reasoning_advanced#mod-reasoning-behaviors.settings.problem_analysis"
              },
              "priority": {
                "self_correction": 1, "problem_analysis": 2, "task_decomposition": 3, "self_evaluation": 4, "alternative_proposal": 5,
                "description": "Default priority order (1=highest). Can be dynamically overridden by agent judgment (`#principle-contextual-execution-autonomy`)."
              }
            }
          },
          "reward_structure_config": {
            "id": "mod-reward-settings",
            "description": "Configuration for internal reward structures guiding reinforcement learning (RL) based optimization and decision-making processes within the agent.",
            "settings": {
              "type": {
                "value": "hybrid_reward",
                "description": "Specifies the type of reward signal used in RL: 'process_reward' (step-wise feedback), 'outcome_reward' (final feedback), 'hybrid_reward' (combination).",
                "options": [
                  { "name": "process_reward", "description": "Step-wise feedback for guiding intermediate actions (e.g., logical step validity, constraint adherence)." },
                  { "name": "outcome_reward", "description": "Final feedback based on overall task success, solution quality, or goal achievement." },
                  { "name": "hybrid_reward", "description": "Combination of process and outcome rewards for balanced guidance." }
                ]
              },
              "shaping": {
                "method": "potential_based",
                "description": "Specifies the reward shaping method to provide denser reward signals: 'potential_based' (uses progress function), 'curriculum_learning' (gradual complexity), 'imitation_learning' (rewards similarity to demos).",
                "options":[
                  { "name": "potential_based", "description": "Uses a potential function (e.g., distance to goal, number of constraints satisfied) for informative rewards." },
                  { "name": "curriculum_learning", "description": "Gradually increases task complexity to facilitate learning." },
                  { "name": "imitation_learning", "description": "Rewards similarity to expert demonstrations (simulated)." }
                ]
              },
              "parameters": {
                "gamma": {
                  "value": 0.99,
                  "description": "Discount factor (gamma) for future rewards in RL (0 to 1). Controls the trade-off between immediate and long-term rewards."
                },
                "potential_function": {
                  "value": "linear",
                  "description": "Specifies the type of potential function for potential-based reward shaping: 'linear', 'exponential', 'logarithmic', 'custom'.",
                  "options": [
                    { "name": "linear", "description": "Reward proportional to progress towards goal." },
                    { "name": "exponential", "description": "Reward increases exponentially closer to the goal." },
                    { "name": "logarithmic", "description": "Reward increases logarithmically with progress." },
                    { "name": "custom", "description": "Allows defining a task-specific potential function (e.g., based on constraint satisfaction)." }
                  ]
                }
              }
            }
         },
         "search_strategy_config": {
            "id": "mod-search-strategy",
            "description": "Configuration for selecting and customizing search strategies employed during inference or planning to explore the solution or state space. Used by `kb_problem_solving_framework`.",
            "settings": {
              "method": {
                "value": "hybrid_search",
                "description": "Specifies the primary search method: 'greedy_search', 'beam_search', 'sampling', 'mcts', 'hybrid_search'. Tree-based methods like ToT or Bi-Point Tree often incorporate specific search/evaluation logic.",
                "options": [
                  { "name": "greedy_search", "description": "Selects the locally optimal (most likely) option at each step." },
                  { "name": "beam_search", "description": "Maintains a fixed number ('beam_width') of most likely sequences." },
                  { "name": "sampling", "description": "Probabilistically samples from the distribution of possible next steps/tokens." },
                  { "name": "mcts", "description": "Monte Carlo Tree Search for balancing exploration/exploitation." },
                  { "name": "hybrid_search", "description": "Combines multiple search methods dynamically based on context or performance." }
                ]
              },
              "beam_width": {
                "value": 5,
                "description": "Number of parallel sequences (beams) maintained during beam search or equivalent width parameter (W) for pruning in tree searches (`kb_problem_solving_framework#principle-node-pruning`). Larger values increase exploration but also cost."
              },
              "max_depth": {
                "value": 10,
                "description": "Maximum depth limit (L) for tree-based search methods like MCTS, ToT, or Bi-Point Tree, controlling forward planning extent."
              },
              "sampling_parameters": {
                "temperature": {
                  "value": 0.7,
                  "description": "Controls randomness of sampling (0=deterministic, >1=more random)."
                },
                "top_k": {
                  "value": 50,
                  "description": "Limits sampling to the top 'k' most probable options."
                },
                "top_p": {
                  "value": 0.95,
                  "description": "Nucleus sampling: limits sampling to smallest set with cumulative probability >= 'p'."
                }
              },
              "alternative_search": {
                "value": "mcts",
                "description": "Specifies an alternative search method (e.g., MCTS) for fallback or hybrid use."
              }
            }
         },
         "policy_initialization_config": {
            "id": "mod-policy-init",
            "description": "Configuration settings influencing the initialization of the agent's internal policy or strategy selection mechanisms.",
            "settings": {
              "priority_behaviors": {
                "values": ["task_completion", "self_correction", "logical_consistency", "constraint_satisfaction", "fairness_bias_mitigation"],
                "description": "Specifies reasoning behaviors to prioritize during policy initialization (e.g., through pre-training focus or initial reward shaping).",
                "options": [ "task_completion", "self_correction", "logical_consistency", "explainability", "adaptability", "exploration", "constraint_satisfaction", "feasibility", "fairness_bias_mitigation" ]
              },
              "pre_training_techniques": {
                "values": ["language_understanding", "logical_reasoning", "problem_solving", "constraint_handling", "bias_awareness"],
                "description": "Specifies relevant pre-training techniques or datasets to leverage for initializing the policy.",
                "options": [ "language_understanding", "logical_reasoning", "problem_solving", "knowledge_representation", "commonsense_reasoning", "causal_inference", "constraint_handling", "bias_awareness" ]
              },
              "prior_knowledge": {
                "enabled": true,
                "description": "Enables the incorporation of explicit prior knowledge (e.g., rules, heuristics, simulated expert demonstrations) to guide policy initialization.",
                "methods": [ "rule_injection", "demonstration_learning", "reward_shaping" ]
              }
            }
         },
         "hyperparameters_rl_config": {
            "id": "mod-rl-hyperparameters",
            "description": "Configuration of key hyperparameters for optimizing performance when using internal reinforcement learning (RL) algorithms.",
            "settings": {
              "learning_rate": {
                "value": 0.001,
                "description": "Controls the step size for updating policy/value function parameters."
              },
              "discount_factor": {
                "value": 0.95,
                "description": "Discount factor (gamma) determining the importance of future rewards relative to immediate rewards."
              },
              "exploration_rate": {
                "value": 0.1,
                "description": "Controls the balance between exploration (trying new actions) and exploitation (using the current best policy) during RL."
              },
              "batch_size": {
                "value": 64,
                "description": "Number of experience samples used in each training batch for updating the RL model."
              },
              "replay_buffer_size": {
                "value": 100000,
                "description": "Size of the memory buffer storing past experiences for off-policy RL algorithms."
              },
              "target_network_update_frequency": {
                "value": 1000,
                "description": "Frequency (in steps or episodes) for updating the target network in algorithms like DQN to stabilize learning."
              }
            }
         },
         "domain_generalization_config": {
            "id": "mod-domain-generalization",
            "description": "Settings aimed at improving the agent's ability to adapt and generalize its reasoning capabilities across different domains, tasks, or data distributions.",
            "settings": {
              "adaptation_rate": {
                "value": 0.8,
                "description": "Controls the rate at which the agent adapts its internal models or strategies when encountering new domains or data distributions."
              },
              "cross_domain_weights": {
                "values": [0.5, 0.3, 0.2],
                "description": "Specifies relative weights assigned to different source domains during training to optimize for cross-domain generalization."
              },
              "regularization_techniques": {
                "values": ["dropout", "batch_normalization", "l1_regularization", "l2_regularization"],
                "description": "Specifies regularization techniques applied during internal model training to prevent overfitting and enhance generalization."
              },
              "meta_learning": {
                "enabled": false,
                "description": "Enables the use of meta-learning approaches ('learning to learn') to allow the agent to adapt more quickly and effectively to new tasks or domains with limited experience."
              }
            }
         },
         "self_reflection_config": {
            "id": "mod-self-reflection",
            "description": "Configuration for enabling and controlling internal self-reflection mechanisms, allowing the agent to analyze its own reasoning, identify weaknesses, and trigger improvements.",
            "settings": {
              "enabled": true,
              "description": "Globally enables or disables self-reflection capabilities.",
              "frequency": {
                "value": "post_interaction",
                "description": "Determines when self-reflection routines are triggered: 'post_interaction', 'periodic', 'event_triggered'.",
                "options": [
                  { "name": "post_interaction", "description": "After completing a significant task or interaction." },
                  { "name": "periodic", "description": "At regular intervals (e.g., every N steps or tasks)." },
                  { "name": "event_triggered", "description": "Triggered by specific events (e.g., low confidence score, detected error, high uncertainty)." }
                ]
              },
              "depth": {
                "value": "medium",
                "description": "Controls the depth and computational cost of the self-reflection analysis: 'low', 'medium', 'high'.",
                "options": [
                  { "name": "low", "description": "Basic analysis of recent performance, focusing on obvious errors." },
                  { "name": "medium", "description": "Detailed analysis of the reasoning process, identifying potential weaknesses or biases." },
                  { "name": "high", "description": "Comprehensive analysis including alternative approaches, counterfactuals, and long-term implications." }
                ]
              },
              "methods": {
                "values": ["self_questioning", "internal_knowledge_comparison", "performance_review", "counterfactual_analysis", "bias_detection", "uncertainty_assessment", "constraint_adherence_review", "fairness_principle_review"],
                "description": "Specifies the techniques employed during self-reflection.",
                "options": [
                  { "name": "self_questioning", "description": "Posing critical questions about own reasoning, assumptions, biases." },
                  { "name": "internal_knowledge_comparison", "description": "Comparing reasoning/outputs with internal KBs for consistency/gaps." },
                  { "name": "performance_review", "description": "Analyzing past performance data (simulated) for patterns and improvement areas." },
                  { "name": "counterfactual_analysis", "description": "Evaluating 'what if' scenarios to assess robustness and decision impact." },
                  { "name": "bias_detection", "description": "Actively searching for and attempting to mitigate potential cognitive or data-induced biases (`#principle-fairness-bias-mitigation`)." },
                  { "name": "uncertainty_assessment", "description": "Explicitly assessing and quantifying uncertainty in reasoning steps/conclusions." },
                  { "name": "constraint_adherence_review", "description": "Verifying adherence to all defined task constraints (`#mod-validation.comp-constraint-feasibility-check`)." },
                  { "name": "fairness_principle_review", "description": "Reviewing the reasoning process and output against fairness principles (`#principle-fairness-bias-mitigation`)." }
                ]
              }
            }
         },
         "multimodal_integration_config": {
            "id": "mod-multimodal-integration",
            "description": "Configuration settings for integrating and reasoning with information from multiple modalities (e.g., text, image, audio, structured data).",
            "settings":{
              "enabled": true,
              "description": "Globally enables or disables multimodal reasoning capabilities.",
              "modalities": ["text", "image", "audio", "video", "numerical_data", "symbolic_data", "sensor_data", "structured_data"],
              "description_modalities": "List of modalities the agent is equipped to process and integrate.",
              "fusion_method": {
                "value": "hybrid_fusion",
                "description": "Specifies the primary strategy for combining information from different modalities: 'early_fusion', 'late_fusion', 'hybrid_fusion'.",
                "options":[
                  {"name": "early_fusion", "description": "Combine raw or low-level features before main reasoning."},
                  {"name": "late_fusion", "description": "Combine outputs or decisions from modality-specific reasoning paths."},
                  {"name": "hybrid_fusion", "description": "Combines aspects of early and late fusion, potentially at multiple stages."}
                ]
              },
              "modality_weights": {
                "description": "Specifies default or dynamically assigned weights indicating the relative importance or reliability of each modality for a given task.",
                "example": "{ \"text\": 0.6, \"image\": 0.4 }"
              },
              "alignment_strategy": {
                "value": "cross-modal_attention",
                "description": "Specifies the method used to align corresponding information across different modalities: 'cross-modal_attention', 'canonical_correlation_analysis', 'co-embedding'.",
                "options": [
                  {"name": "cross-modal_attention", "description": "Uses attention mechanisms to link elements across modalities."},
                  {"name": "canonical_correlation_analysis", "description": "Finds correlated projections in a lower-dimensional space."},
                  {"name": "co-embedding", "description": "Learns a shared embedding space where related concepts from different modalities are close."}
                ]
              }
            }
         }
             "cross_reference": "kb_reasoning_advanced#mod-multimodal-integration"
          }
        },
        "meta": {
          "required_capabilities": [
            "Precise logical reasoning.",
            "Robust probabilistic reasoning/uncertainty handling.",
            "Dynamic adaptation and continuous learning.",
            "Multimodal reasoning and information integration (if enabled).",
            "Counterfactual and analogical reasoning.",
            "Self-reflection, metacognition, and self-correction.",
            "Explainable and interpretable reasoning processes (internal logging mandatory via `agent_reasoning_output_validation`).",
            "Robustness to noise, simulated adversarial attacks, and edge cases.",
            "Efficient use of computational resources.",
            "Effective integration of diverse reasoning techniques from `kb_reasoning_advanced`.",
            "Tree-based exploration and bi-point thinking implementation.",
            "Rigorous internal validation and constraint checking.",
            "Contextual execution autonomy to select/adapt/hybridize strategies."
          ],
            "supported_modalities": ["text", "image", "audio", "video", "numerical_data", "symbolic_data"],
            "supported_reasoning_types": ["deductive", "inductive", "abductive", "causal", "counterfactual", "analogical", "spatial", "temporal", "quantitative", "qualitative", "planning", "design", "optimization", "diagnosis", "explanation", "root_cause_analysis"]
        }
      }
    },
    "reasoning_kb_advanced": {
      "knowledge_base": {
        "id": "kb_reasoning_advanced",
        "title": "Advanced Reasoning Knowledge Base (Linked & Self-Contained Definitions)",
        "description": "A comprehensive, adaptive, and extensible knowledge base defining advanced reasoning, logical analysis, problem-solving, and decision-making methodologies for autonomous LLM agents. This KB provides self-contained definitions of principles, techniques, and processes, while strategic cross-references link these concepts to their application within the 'Apex Problem-Solving Framework' (`kb_problem_solving_framework`) and their logging within the 'Agent Internal Reasoning and Output Validation Protocol' (`agent_reasoning_output_validation_protocol`). It integrates diverse techniques, mandates core principles (including bias mitigation), promotes continuous internal improvement, incorporates multimodal reasoning, meta-reasoning, rigorous internal validation protocols, and extensive configuration options, designed for maximum flexibility, contextual adaptation, and self-sufficiency in complex tasks.",
        "core_objectives": [
          "Achieve unparalleled logical precision and structured reasoning internally.",
          "Enable systematic decomposition of complex problems into manageable components.",
          "Incorporate probabilistic reasoning, uncertainty handling, and risk assessment for robust internal decision-making.",
          "Support dynamic and adaptive problem-solving through contextually selected, hybrid, and potentially synthesized reasoning techniques defined herein.",
          "Ensure internal consistency, feasibility assessment, constraint satisfaction, internal transparency, and auditability in all reasoning processes, linking to logging protocols.",
          "Facilitate continuous internal learning, refinement, and adaptation based on internal feedback loops, performance monitoring, critique mechanisms, and evolving contexts.",
          "Mandate self-sufficiency and robustness in reasoning, generating reliable and feasible solutions based primarily on this knowledge base.",
          "Integrate multimodal information (text, images, audio, etc.) for comprehensive internal understanding, if capabilities are enabled.",
          "Enable meta-reasoning, self-reflection, and self-correction for continuous improvement of internal processes.",
          "Define and support rigorous internal validation, verification, testing, and benchmarking protocols for reasoning processes and outputs.",
          "Provide extensive internal configuration options for customizing reasoning behaviors, reward structures, search strategies, and learning parameters, referenced by the problem-solving framework."
        ],
        "modules": {
          "foundational_principles": {
            "id": "mod-foundation",
            "description": "Fundamental, non-negotiable principles underpinning all reasoning processes defined within this knowledge base. Mandatory adherence is required for optimal reasoning quality, reliability, and feasibility. Application context may be found in `kb_problem_solving_framework#principles`.",
            "principles": [
              {
                "id": "principle-precision",
                "name": "Uncompromising Precision",
                "description": "Mandate absolute precision and unambiguous reasoning. Eliminate vagueness and ambiguity in definitions, steps, assumptions, constraints, and conclusions.",
                "implementation": [
                  "Define and consistently use meticulous terminology and formal notations (e.g., logic, mathematics) where applicable.",
                  "Define precise objectives, constraints (functional, non-functional, simulated real-world), measurable outcomes, and success criteria for each reasoning task.",
                  "Explicitly document internal assumptions, justifications, limitations, and potential biases influencing the reasoning path (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.key_assumptions`).",
                  "Apply formal methods, mathematical rigor, and symbolic reasoning when appropriate to enhance exactitude."
                ],
                "tags": ["<core>", "<accuracy>", "<clarity>", "<constraint-handling>"]
              },
              {
                "id": "principle-coherence",
                "name": "Logical Coherence and Consistency",
                "description": "Ensure a seamless, logically sound, and internally consistent flow of reasoning, free from contradictions.",
                "implementation": [
                  "Rigorously validate premise-conclusion relationships using established formal logic rules defined within validation protocols (`#mod-validation.comp-logical-validation`).",
                  "Maintain contextual consistency across all reasoning steps, inferences, and internal knowledge sources.",
                  "Perform continuous internal cross-checking, verification, and contradiction detection throughout the reasoning process (Log checks via `agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.logical_soundness_check`).",
                  "Utilize internal dependency tracking or conceptual knowledge graphs to monitor relationships and ensure consistency."
                ],
                "tags": ["<core>", "<logic>", "<consistency>", "<validation>"]
              },
              {
                "id": "principle-transparency",
                "name": "Internal Transparency and Selective Explainability",
                "description": "Maintain full internal transparency of reasoning steps with comprehensive justifications. Selectively articulate relevant portions with clarity for external explanation when required.",
                "implementation": [
                  "Decompose complex reasoning into atomic, internally traceable steps with defined inputs/outputs (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.core_reasoning_steps`).",
                  "Maintain detailed internal records: justifications, rationales, supporting evidence (internal), counterarguments considered, critiques generated (Log rationale via `agent_reasoning_output_validation_protocol#validation_output.validation_input.reasoning_trace.rationale_for_final_output`).",
                  "Clearly highlight internal assumptions made, identified limitations, potential biases, and assessed uncertainties (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.identified_limitations_or_uncertainties_pre_validation`).",
                  "Generate external explanations using structured formats, logical steps, and clear language, drawing from internal records."
                ],
                "tags": ["<core>", "<explainability>", "<auditability>", "<justification>"]
              },
              {
                "id": "principle-adaptability",
                "name": "Dynamic Adaptability and Flexibility",
                "description": "Maintain flexibility to adapt reasoning strategies, parameters, and processes in response to changing contexts, new information, dynamic environments, performance feedback, and internal critique. Governed by agent autonomy defined in `kb_problem_solving_framework#principle-contextual-execution-autonomy`.",
                "implementation": [
                  "Continuously monitor the problem-solving context for relevant changes.",
                  "Dynamically adjust reasoning strategies, parameters, simulated resource allocation, and method selection based on real-time internal feedback, critique, and performance analysis, using mechanisms defined in `#mod-implementation.dynamic_adaptation`.",
                  "Incorporate internal feedback loops (including critique-refinement cycles like Bi-point Thinking) for iterative refinement, optimization, and learning, as defined in `#mod-implementation.feedback_and_improvement` and applied in `kb_problem_solving_framework#feedback_loop`.",
                  "Employ adaptive granularity in reasoning steps as needed.",
                  "Execute meta-reasoning capabilities (`#mod-advanced-reasoning.tech-meta-reasoning`) to select, adapt, and combine methods defined herein."
                ],
                "tags": ["<core>", "<flexibility>", "<learning>", "<context-awareness>", "<feedback-driven>", "<iterative-refinement>"]
              },
              {
                "id": "principle-completeness",
                "name": "Comprehensive Completeness and Feasibility",
                "description": "Ensure all relevant aspects of the problem (including constraints) are addressed thoroughly, resulting in a complete and feasible solution based on internal assessment.",
                "implementation": [
                  "Conduct exhaustive analysis of context, requirements, constraints, and objectives.",
                  "Identify and address potential risks, limitations, trade-offs, edge cases, and feasibility issues using internal assessment methods.",
                  "Verify completeness of reasoning, logical soundness, coverage of possibilities, and satisfaction of all constraints using protocols in `#mod-validation.comp-constraint-feasibility-check`.",
                  "Assess the practical feasibility of the proposed solution within the given context and agent capabilities.",
                  "Apply internal checklists, verification protocols, constraint checking, and coverage analysis."
                ],
                "tags": ["<core>", "<thoroughness>", "<coverage>", "<risk-assessment>", "<feasibility>", "<constraint-satisfaction>"]
              },
              {
                "id": "principle-efficiency",
                "name": "Computational Efficiency",
                "description": "Optimize reasoning processes for computational efficiency (steps, tokens, latency) without sacrificing accuracy, robustness, completeness, feasibility, or soundness.",
                "implementation": [
                  "Apply efficient algorithms and internal data structures.",
                  "Employ judicious pruning techniques (e.g., in tree search, guided by `kb_problem_solving_framework#principle-node-pruning`) based on heuristics or evaluation scores defined herein.",
                  "Leverage simulated parallel processing for decomposable tasks.",
                  "Optimize simulated resource allocation, utilization, and memory management based on internal monitoring."
                ],
                "tags": ["<core>", "<performance>", "<optimization>", "<resource-management>", "<pruning>"]
              },
              {
                "id": "principle-robustness",
                "name": "Robustness and Resilience",
                "description": "Ensure the reasoning system is robust against noise, uncertainty, simulated adversarial inputs, edge cases, incomplete information, and unexpected conditions, producing reliable outputs.",
                "implementation": [
                  "Incorporate internal error handling, fault tolerance checks, and recovery mechanisms.",
                  "Apply simulated adversarial training and robustness testing protocols defined in `#mod-validation.comp-robustness-testing`.",
                  "Employ ensemble methods or diverse reasoning paths (e.g., `#mod-frameworks.intermediate.method-tot`, `#mod-frameworks.advanced.method-bi-point-tree`).",
                  "Rigorously validate inputs and intermediate outputs for consistency, plausibility, and constraints using internal checks."
                ],
                "tags": ["<core>", "<reliability>", "<fault-tolerance>", "<uncertainty-handling>", "<validation>"]
              },
              {
                "id": "principle-fairness-bias-mitigation",
                "name": "Fairness and Bias Mitigation",
                "description": "Conduct reasoning processes with awareness of potential biases (cognitive, data-induced, algorithmic) and strive for fairness in outcomes where applicable. Actively identify and mitigate harmful biases.",
                "implementation": [
                  "Integrate checks for potential fairness issues or disparate impacts at relevant reasoning stages.",
                  "Actively query internal knowledge for guidelines related to fairness and bias in the specific domain.",
                  "Employ techniques to detect potential biases (e.g., statistical analysis on simulated data, counterfactual fairness checks, checklist reviews).",
                  "Document identified potential biases and the mitigation steps taken (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.identified_limitations_or_uncertainties_pre_validation` or `#validation_output.internal_validation_checks_performed.robustness_safety_review`).",
                  "Prioritize solutions or outputs that minimize harmful bias, potentially adjusting parameters or selecting alternative approaches.",
                  "If significant harmful bias cannot be adequately mitigated, flag for review (`agent_reasoning_output_validation_protocol#validation_output.validation_flags`) or adopt a conservative fallback strategy."
                ],
                "tags": ["<core>", "<fairness>", "<bias-mitigation>", "<responsibility>", "<safety>"]
              }
            ]
          },
          "reasoning_frameworks": {
            "id": "mod-frameworks",
            "description": "A curated collection of diverse reasoning methodologies defined within this KB. The agent selects, combines, or adapts these frameworks based on context, guided by `#mod-implementation.method_selection` and applied within `kb_problem_solving_framework#execution_process`.",
            "categories": {
              "basic": {
                "description": "Fundamental methods for well-defined problems with clear solution paths.",
                "methods": [
                  {
                    "id": "method-cot",
                    "name": "Chain of Thought (CoT)",
                    "description": "A sequential, step-by-step reasoning process where each step logically builds upon the previous one, making the reasoning explicit and traceable.",
                    "implementation": [
                      { "step_id": "cot-1", "name": "Problem Definition & Context", "actions": ["Establish context, parameters.", "Define specific question/sub-problem.", "Identify variables, constraints, assumptions."] },
                      { "step_id": "cot-2", "name": "Sequential Logical Progression", "actions": ["Progress through discrete logical steps.", "State reasoning connecting steps (deduction, calculation, etc.).", "Validate intermediate conclusions using `#mod-validation.comp-logical-validation`."] },
                      { "step_id": "cot-3", "name": "Justification & Synthesis", "actions": ["Provide internal justifications for each step.", "Relate steps to overall goal.", "Synthesize findings into final conclusion."] }
                    ],
                    "application_context": "`kb_problem_solving_framework#execution_process.stages` (multiple steps)",
                    "tags": ["<sequential>", "<step-by-step>", "<linear-reasoning>", "<explainable>", "<basic>"]
                  }
                ]
              },
              "intermediate": {
                "description": "Methods for more complex scenarios involving branching, decomposition, or parallel exploration.",
                "methods": [
                  {
                    "id": "method-tot",
                    "name": "Tree of Thought (ToT)",
                    "description": "Systematic exploration of multiple potential solution paths/reasoning branches concurrently via a tree structure. Allows parallel evaluation and pruning.",
                    "implementation": [
                      "Represent problem/decision space as a tree (nodes=states, branches=actions/inferences).",
                      "Generate multiple branches ('thoughts') from nodes iteratively.",
                      "Evaluate branches using defined heuristics, evaluation functions, or confidence scores.",
                      "Record explored branches, evaluations, and reasoning in a structured internal format.",
                      "Employ pruning strategies (depth, confidence, heuristics, beam width defined in `#mod-search-strategy`) to manage complexity."
                    ],
                    "limitations": ["Combinatorial explosion potential.", "Requires effective generation, evaluation, pruning.", "May not guarantee constraint satisfaction without extensions."],
                    "mitigations": ["Intelligent pruning.", "Practical tree size limits.", "Combine with critique/refinement cycles (`#mod-advanced-reasoning.tech-iterative-critique-refinement`) or constraint checking (`#mod-validation.comp-constraint-feasibility-check`).", "Combine with MCTS (`#method-mcts`)."],
                    "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration.strategies.strategy-tot`",
                    "tags": ["<exploration>", "<branching>", "<parallel-evaluation>", "<search>", "<intermediate>"]
                  },
                  {
                    "id": "method-decomposition",
                    "name": "Structured Decomposition",
                    "description": "Systematically breaking down complex problems into smaller, manageable, interconnected sub-problems. Facilitates modular reasoning and integration.",
                    "implementation": [
                      { "step_id": "decomp-1", "name": "Problem Analysis & Component Identification", "details": ["Identify core components/stages.", "Define scope, boundaries, I/O, objectives, constraints for each sub-problem."] },
                      { "step_id": "decomp-2", "name": "Relationship & Dependency Mapping", "details": ["Define relationships (sequential, parallel, etc.) and dependencies.", "Establish clear interfaces/information flow."] },
                      { "step_id": "decomp-3", "name": "Sub-Problem Solving", "details": ["Address each sub-problem using contextually selected methods from this KB."] },
                      { "step_id": "decomp-4", "name": "Solution Synthesis & Integration Validation", "details": ["Combine sub-solutions.", "Rigorously validate integrated solution using protocols from `#mod-validation` (consistency, completeness, correctness, feasibility, constraints)."] }
                    ],
                    "conditions": {
                      "ideal_use": ["Complex systems analysis.", "Multi-stage task planning.", "Engineering design.", "Modular problems."],
                      "limitations": ["Struggles with highly entangled problems.", "Requires careful boundary definition.", "Integration complexity."],
                      "mitigations": ["Combine with holistic methods.", "Iterative refinement of decomposition.", "Robust integration validation."]
                    },
                    "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-problem-understanding.strategies.strategy-decomposition`",
                    "tags": ["<modular>", "<divide-and-conquer>", "<structured-thinking>", "<planning>", "<design>", "<intermediate>"]
                  }
                ]
              },
              "advanced": {
                "description": "Sophisticated methods for complex, uncertain, multi-objective, or large-scale problems, especially relevant for solution design tasks requiring advanced search, probabilistic modeling, simulation, or iterative refinement.",
                "methods": [
                  {
                    "id": "method-mcts",
                    "name": "Monte Carlo Tree Search (MCTS)",
                    "description": "A probabilistic search algorithm using randomized simulations (rollouts) to guide exploration in large decision spaces. Balances exploration and exploitation.",
                    "implementation": [
                      { "step_id": "mcts-1", "name": "Selection", "description": "Traverse tree selecting child nodes based on policy (e.g., UCT - Upper Confidence Bound applied to Trees)." },
                      { "step_id": "mcts-2", "name": "Expansion", "description": "Add unexplored child nodes to the tree." },
                      { "step_id": "mcts-3", "name": "Simulation (Rollout)", "description": "Perform a simulation from the new node using a default policy (e.g., random, heuristic) to estimate its value." },
                      { "step_id": "mcts-4", "name": "Backpropagation", "description": "Propagate the simulation outcome up the tree, updating node statistics (visits, value)." }
                    ],
                    "limitations": ["Requires a simulation model.", "Computationally expensive.", "Policy dependent.", "May need modification for strict constraint satisfaction."],
                    "mitigations": ["Efficient simulation models.", "Heuristic rollouts.", "Parallelization (simulated).", "Pruning/learned values.", "Budget limits.", "Integrate constraint checking (`#mod-validation.comp-constraint-feasibility-check`)."],
                    "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration.strategies.strategy-mcts`",
                    "tags": ["<probabilistic-search>", "<simulation-based>", "<decision-making>", "<uncertainty>", "<exploration-exploitation>", "<advanced>"]
                  },
                  {
                    "id": "method-bi-point-tree",
                    "name": "Bi-point Thinking Tree",
                    "description": "An advanced tree-based framework for complex solution design, emphasizing iterative refinement and reliability. Alternates between generating solutions (Solution Nodes) and critiquing them (Comment Nodes) to progressively improve feasibility and constraint satisfaction.",
                    "implementation": [
                      { "step_id": "bpt-1", "name": "Initialize Root Node", "details": "Start with the complex requirement/problem statement (q)." },
                      { "step_id": "bpt-2", "name": "Generate Solution Nodes (Layer i)", "details": "Generate H potential solution refinements/proposals (s_h^i) based on the parent node (either the root q or a previous Comment Node c_j^(i-1)), potentially using retrieved internal knowledge (K_h)." },
                      { "step_id": "bpt-3", "name": "Generate Comment Nodes (Layer i+1)", "details": "Generate H critique/comment nodes (c_k^(i+1)) by reviewing the corresponding Solution Node (s_h^i) against the original requirement (q), defined constraints (`#mod-validation.comp-constraint-feasibility-check`), fairness principles (`#principle-fairness-bias-mitigation`), and internal knowledge (K_k). Identify deficiencies, constraint violations, risks, and potential improvements." },
                      { "step_id": "bpt-4", "name": "Iterate Expansion", "details": "Repeat steps 2 and 3, using the generated Comment Nodes to guide the generation of improved Solution Nodes in subsequent layers." },
                      { "step_id": "bpt-5", "name": "Evaluate Nodes & Prune Tree", "details": "Evaluate the 'reliability' or 'quality' of Solution Nodes and the 'helpfulness' or 'criticality' of Comment Nodes using internal scoring functions or heuristics. Prune less promising branches based on scores and pruning parameters (e.g., beam width W from `#mod-search-strategy`)." },
                      { "step_id": "bpt-6", "name": "Terminate Search", "details": "Stop based on criteria like maximum depth (L from `#mod-search-strategy`), achieving a target quality score, resource budget exhaustion, or convergence. Select the best validated solution from the retained leaf nodes." }
                    ],
                    "advantages": ["Explicit iterative refinement cycle.", "Systematically improves reliability and feasibility.", "Integrates constraint checking and critique directly into the search.", "Flexible exploration of design space."],
                    "challenges": ["Computationally intensive.", "Requires effective node evaluation functions.", "Depends heavily on the quality of the LLM's generation and critique capabilities."],
                    "application_context": "`kb_problem_solving_framework#execution_process` (stages involving exploration, evaluation, refinement)",
                    "tags": ["<iterative-refinement>", "<design-review>", "<critique>", "<constraint-satisfaction>", "<reliability>", "<tree-based>", "<solution-design>", "<advanced>", "<bi-point-thinking>"]
                  },
                  {
                    "id": "method-fibonacci",
                    "name": "Adaptive Fibonacci Reasoning Framework",
                    "description": "An adaptive reasoning framework using a modified Fibonacci sequence structure for managing steps, incorporating dynamic feedback and iterative refinement.",
                    "implementation": [
                      { "step_number": 0, "name": "Context Introduction & Goal Setting", "details": "Define problem, objective, scope." },
                      { "step_number": 1, "name": "Premise Establishment & Initial Analysis", "details": "Identify/validate premises, assumptions, constraints. Analyze." },
                      { "step_number": 1, "name": "Immediate Expansion & Info Gathering", "details": "Expand understanding via internal info gathering, hypothesis generation." },
                      { "step_number": 2, "name": "Interconnection & Relationship Mapping", "details": "Connect premises to conclusions, identify relationships, conflicts." },
                      { "step_number": 3, "name": "Intermediate Detailing & Evidence Integration", "details": "Integrate internal evidence/data to substantiate/refute conclusions." },
                      { "step_number": 5, "name": "Logical Consolidation & Coherence Check", "details": "Combine insights, validate coherence (`#mod-validation.comp-logical-validation`), address inconsistencies." },
                      { "step_number": 8, "name": "Solution Synthesis & Final Resolution", "details": "Synthesize insights into final solution/conclusion." },
                      { "step_number": 13, "name": "Adaptive Feedback & Iterative Refinement (Loop)", "actions": ["Incorporate internal feedback (`#mod-implementation.feedback_and_improvement`).", "Dynamically adjust steps/strategies (`#mod-implementation.dynamic_adaptation`).", "Iteratively refine solution. May loop back to earlier steps."] }
                    ],
                    "adaptive_features": {
                      "dynamic_step_adjustment": { "description": "Adjusts step number/depth/complexity based on problem, uncertainty, feedback.", "triggers": ["High uncertainty", "Contradictions", "Low confidence", "Feedback", "New info."] },
                      "feedback_integration": { "description": "Systematically incorporates feedback (internal validation, monitoring, reflection) to guide reasoning.", "mechanisms": ["Performance metrics", "Consistency checks", "Self-reflection outputs", "RL signals."] }
                    },
                    "tags": ["<adaptive>", "<iterative>", "<structured-progression>", "<feedback-driven>", "<complex-problems>", "<advanced>"]
                  },
                  {
                    "id": "method-bayesian",
                    "name": "Bayesian Reasoning",
                    "description": "A probabilistic framework using Bayes' theorem to update beliefs about hypotheses based on evidence. Ideal for uncertainty, incomplete info, diagnosis, learning.",
                    "implementation": [
                      "Define hypotheses (H).", "Assign prior probabilities P(H) based on internal knowledge.", "Define likelihood functions P(Evidence | H).", "Gather evidence (E) from context or internal reasoning.", "Apply Bayes' theorem to calculate posterior probabilities P(H | E).", "Iteratively update posteriors as new evidence arrives."
                    ],
                    "applications": ["Diagnostic reasoning.", "Risk assessment.", "Parameter estimation.", "Learning under uncertainty."],
                    "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for diagnosis, prediction, high uncertainty)",
                    "tags": ["<probabilistic-reasoning>", "<belief-updating>", "<uncertainty>", "<evidence-based>", "<learning>", "<advanced>"]
                  }
                ]
              }
            },
            "hybrid_reasoning": {
              "id": "mod-hybrid",
              "description": "A meta-strategy involving synergistic and dynamic combination of multiple reasoning techniques defined within this KB to leverage complementary strengths and mitigate weaknesses, guided by `#principle-adaptability` and `#mod-implementation.method_selection`.",
              "principles": [
                {
                  "id": "principle-complementarity",
                  "name": "Complementarity",
                  "description": "Combine methods with differing strengths (e.g., ToT for exploration, Bi-point Thinking Tree for refinement).",
                  "example": "Combine tree exploration (`#method-tot`/`#method-mcts`) with iterative critique/refinement cycles (`#method-bi-point-tree` or `#tech-iterative-critique-refinement`) for complex design tasks."
                },
                {
                  "id": "principle-dynamic-integration",
                  "name": "Dynamic Integration",
                  "description": "Flexibly switch between or integrate techniques based on problem state, sub-task nature, uncertainty, or feedback, guided by `#mod-implementation.dynamic_adaptation`.",
                  "example": "Initiate with Decomposition (`#method-decomposition`), solve sub-problems (using `#method-cot`/`#method-bayesian`), then use Bi-point Thinking (`#method-bi-point-tree`) for integration and refinement."
                },
                {
                    "id": "principle-contextual-selection",
                    "name": "Contextual Method Selection",
                    "description": "Employ meta-reasoning (`#tech-meta-reasoning`) to intelligently select the most appropriate technique(s) based on task type (QA vs. design), complexity, uncertainty, constraints, resources, explainability/reliability needs, using criteria from `#mod-implementation.method_selection`.",
                    "implementation": ["Execute internal decision logic.", "Apply rule-based selection.", "Utilize learned strategy selection models (internal)."]
                }
              ],
              "tags": ["<meta-strategy>", "<flexible>", "<adaptive>", "<combined-methods>", "<robustness>"]
            },
            "multimodal_methods": {
              "id": "mod-multimodal",
              "description": "Reasoning methods designed to handle, integrate, and reason across information from multiple modalities, configured via `#mod-multimodal-integration_config`.",
              "examples": [
                { "name": "Integrated MCTS and Fibonacci Progression", "description": "Combines MCTS exploration with Fibonacci structured progression.", "implementation": "Use MCTS simulations to evaluate outcomes/scenarios at specific Fibonacci steps.", "tags": ["<hybrid>", "<probabilistic-logical>", "<simulation>", "<structured-progression>"] },
                { "name": "Visual-Textual Reasoning", "description": "Combines visual and textual information for joint understanding.", "implementation": ["Extract visual features (simulated).", "Process text.", "Fuse features (e.g., cross-modal attention).", "Apply reasoning to fused representation."], "tags": ["<multimodal>", "<vision-language>", "<integration>", "<cross-modal>"] },
                { "name": "Audio-Textual Reasoning", "description": "Combines audio and textual information.", "implementation": ["Transcribe audio (simulated).", "Process text.", "Integrate features/info.", "Apply reasoning."], "tags": ["<multimodal>", "<audio-language>", "<integration>", "<cross-modal>"] },
                { "name": "Numerical-Textual Reasoning", "description": "Combines quantitative data with qualitative text.", "implementation": ["Extract/structure numerical data.", "Process text.", "Fuse info.", "Apply quantitative/qualitative reasoning."], "tags": ["<multimodal>", "<quantitative-qualitative>", "<data-integration>", "<cross-modal>"] }
              ]
            },
            "simulation_methods":{
              "id": "mod-simulation",
              "description": "Reasoning frameworks relying on internal simulations, probabilistic models, or advanced heuristics for complex optimization, prediction, or analysis.",
              "methods": [
                { "id": "method-simulated-annealing", "name": "Simulated Annealing", "description": "Probabilistic metaheuristic for global optimization approximation. Allows escaping local optima.", "applications": ["Global optimization.", "Resource allocation.", "Scheduling.", "Layout problems."], "tags": ["<simulation>", "<optimization>", "<heuristic>", "<probabilistic>", "<search>", "<advanced>"] },
                { "id": "method-bayesian-networks", "name": "Bayesian Networks", "description": "Probabilistic graphical model (DAG) representing variables and conditional dependencies. Used for inference under uncertainty.", "applications": ["Risk analysis.", "Diagnostic systems.", "Causal inference.", "Decision support.", "Predictive modeling."], "tags": ["<probabilistic-reasoning>", "<uncertainty>", "<graphical-model>", "<inference>", "<causality>", "<advanced>"] }
              ]
            }
          },
           "advanced_reasoning_techniques": {
            "id": "mod-advanced-reasoning",
            "description": "Sophisticated reasoning techniques extending beyond basic/intermediate methods, addressing complex, nuanced, or specialized scenarios like solution design.",
            "techniques":[
               {
                "id": "tech-iterative-critique-refinement",
                "name": "Iterative Critique-Refinement Cycle",
                "description": "An iterative technique alternating generation (e.g., proposing solutions/reasoning steps) and critique (evaluating against criteria like constraints, objectives, logic, feasibility). Drives refinement, improving quality and reliability. Can be applied standalone or as part of frameworks like Bi-point Thinking Tree (`#method-bi-point-tree`).",
                "implementation": [
                  "Generate initial proposal/solution/reasoning step.",
                  "Execute critique step: Evaluate proposal against relevant criteria (constraints from `#mod-validation.comp-constraint-feasibility-check`, objectives, logical soundness from `#mod-validation.comp-logical-validation`, feasibility, internal knowledge, fairness principles from `#principle-fairness-bias-mitigation`).",
                  "Identify specific deficiencies, errors, risks, or improvement areas based on the critique.",
                  "Generate a refined proposal addressing the identified issues.",
                  "Repeat critique-refinement cycle until satisfaction criteria are met, resources are exhausted, or no further improvement is detected.",
                  "Can be nested or applied hierarchically to different components of a problem."
                ],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-refinement`",
                "tags": ["<advanced-technique>", "<iterative-refinement>", "<critique>", "<self-correction>", "<design-thinking>", "<reliability>", "<constraint-satisfaction>", "<bi-point-thinking-element>"]
              },
              {
                "id": "tech-multimodal-reasoning",
                "name": "Multimodal Reasoning",
                "description": "Integrating, processing, and reasoning across multiple information modalities (defined in `#mod-multimodal-integration_config.settings.modalities`) for holistic understanding.",
                "implementation": [
                  "Execute methods for aligning and fusing information based on `#mod-multimodal-integration_config.settings.fusion_method` and `#mod-multimodal-integration_config.settings.alignment_strategy`.",
                  "Combine logical reasoning with specialized models (internal simulation) for modality-specific processing.",
                  "Address challenges: heterogeneity, noise, synchronization, inconsistencies, using robustness principles (`#principle-robustness`)."
                ],
                "tags": ["<advanced-technique>", "<multimodal>", "<integration>", "<cross-modal>", "<holistic-understanding>"]
              },
              {
                "id": "tech-counterfactual-reasoning",
                "name": "Counterfactual Reasoning",
                "description": "Reasoning about hypothetical alternative scenarios ('what if') deviating from the actual state. Used for explanation, planning, and decision analysis.",
                "implementation": [
                  "Generate plausible counterfactual scenarios based on modifying key variables or past events.",
                  "Estimate outcomes using causal inference models (if available internally) or logical projection.",
                  "Explicitly state assumptions made for the counterfactual.",
                  "Address/quantify uncertainties associated with the counterfactual outcome."
                ],
                "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for explanation)",
                "tags": ["<advanced-technique>", "<hypothetical>", "<what-if>", "<causal-inference>", "<scenario-analysis>", "<explanation>"]
              },
              {
                "id": "tech-analogical-reasoning",
                "name": "Analogical Reasoning",
                "description": "Identifying and leveraging structural or conceptual similarities between different domains (source and target) to transfer knowledge, generate hypotheses, or find novel solutions.",
                "implementation": [
                  "Identify potential source analogs from internal knowledge based on structural mapping.",
                  "Map concepts, relationships, and constraints between the source and target domains.",
                  "Critically evaluate the validity and limitations of the analogy, avoiding superficial similarities.",
                  "Ensure the appropriateness and necessary adaptation of transferred knowledge to the target context."
                ],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration.strategies.strategy-innovative-reasoning`",
                "tags": ["<advanced-technique>", "<analogy>", "<knowledge-transfer>", "<hypothesis-generation>", "<creative-problem-solving>"]
              },
              {
                "id": "tech-meta-reasoning",
                "name": "Meta-Reasoning",
                "description": "Reasoning *about* the reasoning process itself. Involves monitoring, evaluating, controlling, and adapting the agent's own cognitive processes to optimize performance and achieve goals.",
                "implementation": [
                  "Execute internal monitoring of reasoning progress, confidence levels, resource usage, and strategy effectiveness.",
                  "Apply self-assessment of strategy quality, appropriateness, and potential biases.",
                  "Implement control mechanisms to dynamically select, switch, or adapt reasoning strategies based on meta-level evaluation (linking to `#mod-implementation.method_selection` and `#mod-implementation.dynamic_adaptation`).",
                  "Incorporate meta-level feedback loops for continuous improvement of the reasoning process itself."
                ],
                "tags": ["<advanced-technique>", "<metacognition>", "<self-awareness>", "<strategy-selection>", "<optimization>", "<control>"]
              },
               {
                "id": "tech-abductive-reasoning",
                "name": "Abductive Reasoning",
                "description": "Inferring the most plausible explanation(s) for a given set of observations or evidence ('inference to the best explanation'). Crucial for diagnosis and hypothesis generation.",
                "implementation": [
                  "Generate a diverse set of plausible hypotheses that could explain the observations.",
                  "Evaluate and rank hypotheses based on criteria such as simplicity (Occam's Razor), explanatory power, coherence with existing internal knowledge, and likelihood.",
                  "Handle uncertainty and the possibility of multiple competing explanations, potentially assigning probabilities or confidence scores.",
                  "Distinguish clearly from deductive (guaranteed conclusion) and inductive (probable generalization) reasoning."
                ],
                "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for diagnosis, explanation)",
                "tags": ["<advanced-technique>", "<explanation>", "<hypothesis-generation>", "<inference-to-best-explanation>", "<diagnostic-reasoning>", "<uncertainty>"]
              },
              {
                "id": "tech-reasoning-with-retrieved-evidence",
                "name": "Reasoning with Retrieved Evidence (Simulated RAG)",
                "description": "Integrating the simulated retrieval and critical evaluation of evidence/knowledge from internal sources into the reasoning process. Crucial for knowledge-intensive tasks.",
                "implementation": [
                  "Identify knowledge gaps relevant to the current reasoning step or problem.",
                  "Formulate effective internal queries to retrieve potentially relevant information from internal KBs.",
                  "Critically evaluate the retrieved information's credibility, relevance, applicability, and potential bias based on source metadata (if available) and contextual fit.",
                  "Integrate validated evidence into the reasoning process (e.g., updating beliefs, checking constraints, supporting claims, critiquing proposals).",
                  "Explicitly consider the limitations of the internal retrieval process and the potential impact of missing information."
                ],
                "tags": ["<advanced-technique>", "<evidence-based>", "<knowledge-integration>", "<rag-simulation>", "<solution-design>", "<information-retrieval-internal>", "<critical-evaluation>"]
              },
              {
                "id": "tech-counterfactual-explanations",
                "name": "Counterfactual Explanations",
                "description": "Generating explanations clarifying outcomes by describing how they would change if specific inputs/factors differed. Enhances interpretability.",
                "implementation": [
                  "Identify key influencing factors or decision points.",
                  "Generate minimal, plausible counterfactual scenarios by modifying these factors.",
                  "Evaluate the predicted outcome under these counterfactuals using internal models or logical projection.",
                  "Present the explanation highlighting the specific change and its resulting impact on the outcome."
                ],
                "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for explanation)",
                "tags": ["<advanced-technique>", "<explanation>", "<interpretability>", "<causal-explanation>", "<what-if>", "<counterfactual-reasoning>"]
              },
              {
                "id": "tech-argumentation-mining",
                "name": "Argumentation Mining",
                "description": "Automated identification and analysis of argumentative structures within textual data (internal or contextual).",
                "implementation": [
                  "Identify argument components (premises, claims) using NLP techniques (internal simulation).",
                  "Analyze argument structure and relationships (support, attack).",
                  "Assess argument strength, validity, and potential fallacies using logical principles.",
                  "Reconstruct implicit premises or conclusions where necessary.",
                  "Model argument relationships, potentially as a graph."
                ],
                "tags": ["<advanced-technique>", "<nlp-simulation>", "<argument-analysis>", "<logical-structure>", "<fallacy-detection>", "<text-analysis>"]
              }
            ]
          },
          "validation_and_verification": {
            "id": "mod-validation",
            "description": "Mandatory internal protocols and techniques for validating the correctness, robustness, logical soundness, feasibility, constraint satisfaction, and reliability of reasoning processes and generated outputs. Results are logged via `agent_reasoning_output_validation_protocol`.",
            "components": [
              {
                "id": "comp-logical-validation",
                "name": "Logical Validation and Consistency Checking",
                "description": "Verifying the logical soundness, validity, and internal consistency of reasoning chains.",
                "steps": [
                  { "step_id": "lv-1", "description": "Verify premise validity and logical relationships between steps using formal logic rules (modus ponens, etc.)." },
                  { "step_id": "lv-2", "description": "Test intermediate and final conclusions for soundness (following from premises) and consistency with internal knowledge." },
                  { "step_id": "lv-3", "description": "Scan reasoning trace for logical fallacies (e.g., circular reasoning, contradiction, hasty generalization)." },
                  { "step_id": "lv-4", "description": "Perform automated consistency checks across different parts of the reasoning process." }
                ],
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.logical_soundness_check`",
                "tags": ["<validation>", "<logic>", "<consistency>", "<soundness>", "<fallacy-check>"]
              },
               {
                "id": "comp-constraint-feasibility-check",
                "name": "Constraint Satisfaction and Feasibility Validation",
                "description": "Ensuring the generated solution or output adheres to all defined constraints and is practically feasible within the agent's context.",
                "steps": [
                  { "step_id": "cfc-1", "description": "Identify and list all explicit and implicit constraints relevant to the task (functional, non-functional, fairness, operational)." },
                  { "step_id": "cfc-2", "description": "Systematically verify if the proposed solution or output addresses and satisfies each identified constraint." },
                  { "step_id": "cfc-3", "description": "Assess the practical feasibility of implementing the solution components or plan, considering simulated resource limits and agent capabilities." },
                  { "step_id": "cfc-4", "description": "Flag any violated constraints or identified feasibility issues, noting severity." }
                ],
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.constraint_adherence_check_result`",
                "tags": ["<validation>", "<constraint-satisfaction>", "<feasibility>", "<requirements-check>", "<solution-design>"]
              },
              {
                "id": "comp-factual-grounding-check",
                "name": "Factual Grounding and Hallucination Check",
                "description": "Verifying that factual claims within the output are accurate and grounded in reliable internal knowledge or provided context, minimizing hallucinations.",
                "steps": [
                  { "step_id": "fgc-1", "description": "Identify factual claims made in the output." },
                  { "step_id": "fgc-2", "description": "Attempt to trace each claim back to its source within internal knowledge or provided context." },
                  { "step_id": "fgc-3", "description": "Assess the reliability of the source (if traceable) and the consistency of the claim with other internal knowledge." },
                  { "step_id": "fgc-4", "description": "Flag claims that are unsupported, contradict reliable sources, or seem highly implausible (potential hallucinations)." },
                  { "step_id": "fgc-5", "description": "Assign a grounding score or confidence level to the output's factual content." }
                ],
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.factual_grounding_check`, `agent_reasoning_output_validation_protocol#validation_output.response_quality_assessment_result.factual_grounding_rating`",
                "tags": ["<validation>", "<accuracy>", "<hallucination-check>", "<grounding>", "<fact-checking>"]
              },
              {
                "id": "comp-output-qa",
                "name": "Output Quality Assurance and Benchmarking",
                "description": "Systematic evaluation of overall output quality against predefined criteria and internal benchmarks.",
                "criteria": [
                  "Logical soundness & validity (`#comp-logical-validation`).",
                  "Constraint satisfaction & feasibility (`#comp-constraint-feasibility-check`).",
                  "Factual grounding & accuracy (`#comp-factual-grounding-check`).",
                  "Contextual relevance & task completion.",
                  "Clarity, precision, and structure.",
                  "Completeness & coverage.",
                  "Efficiency/conciseness.",
                  "Robustness & safety considerations (including bias checks from `#principle-fairness-bias-mitigation`).",
                  "Alignment with operational principles.",
                  "Performance against internal benchmarks (if applicable)."
                ],
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.response_quality_assessment_result`",
                "tags": ["<validation>", "<quality-assurance>", "<benchmarking>", "<metrics>", "<output-evaluation>"]
              },
              {
                "id": "comp-automated-validation",
                "name": "Automated Validation and Testing (Internal)",
                "description": "Mandatory use of automated internal checks for inputs, outputs, premises, processes, constraint adherence, and behavior.",
                "processes": [
                  "Input schema validation.",
                  "Output format/schema validation.",
                  "Automated constraint checking scripts.",
                  "Automated contradiction/fallacy detection routines.",
                  "Execution of internal test suites (unit, integration tests - simulated).",
                  "Automated regression testing after internal updates.",
                  "Automated performance benchmarking (latency, resource usage - simulated)."
                ],
                "tags": ["<validation>", "<automation>", "<testing>", "<regression-testing>", "<performance-testing>", "<constraint-checking>"]
              },
              {
                "id": "comp-robustness-testing",
                "name": "Robustness Testing and Evaluation (Internal Simulation)",
                "description": "Mandatory protocol for assessing robustness, resilience, fault tolerance under simulated adverse conditions.",
                "tests": {
                  "stress_tests": { "description": "Evaluate under simulated high load or complexity.", "metrics": ["Time/latency.", "Resources.", "Stability.", "Scalability."] },
                  "boundary_tests": { "description": "Examine with extreme/unusual inputs, missing data, ambiguity.", "metrics": ["Error rate/modes.", "Output validity.", "Recovery.", "Degradation."] },
                  "adversarial_tests": { "description": "Employ simulated adversarial techniques (e.g., perturbed inputs).", "methods": ["Generate adversarial examples.", "Simulate malicious inputs.", "Evaluate detection/mitigation."] }
                },
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.robustness_safety_review`",
                "tags": ["<validation>", "<robustness>", "<resilience>", "<stress-testing>", "<adversarial-testing>", "<edge-cases>"]
              }
            ]
          },
          "implementation_and_deployment": {
            "id": "mod-implementation",
            "description": "Mandatory best practices, guidelines, and standards for implementing and executing reasoning strategies defined within this KB, applied within the context of `kb_problem_solving_framework`.",
            "standards": [
              {
                "id": "standard-execution",
                "category": "Execution Protocols and Procedures",
                "requirements": [
                  "Adopt systematic, well-defined, and reproducible approaches for all reasoning tasks.",
                  "Maintain detailed internal logs of reasoning processes, decisions, assumptions, justifications, and validation results (using `agent_reasoning_output_validation_protocol` structure).",
                  "Continuously monitor, evaluate, and optimize reasoning performance using defined metrics (`#standard-quality.metrics`) and feedback loops (`#feedback_and_improvement`).",
                  "Ensure strict compliance with foundational principles (`#mod-foundation`) and relevant configurations."
                ],
                "tags": ["<implementation>", "<process>", "<standard>", "<reproducibility>", "<monitoring>", "<logging>"]
              },
              {
                "id": "standard-quality",
                "category": "Quality Metrics and Performance Benchmarks",
                "description": "Key internal metrics for evaluating reasoning performance and output quality.",
                "metrics": [
                  { "id": "metric-accuracy", "name": "Accuracy/Correctness Index", "threshold": ">=0.95", "validation_method": "Internal comparison vs. benchmarks/truth/simulations (`#comp-factual-grounding-check`)." },
                  { "id": "metric-consistency", "name": "Logical Consistency Score", "threshold": ">=0.95", "validation_method": "Internal logical validation checks (`#comp-logical-validation`)." },
                  { "id": "metric-feasibility", "name": "Feasibility Score", "threshold": ">=0.90", "validation_method": "Internal constraint and feasibility checks (`#comp-constraint-feasibility-check`)." },
                  { "id": "metric-efficiency", "name": "Efficiency Rating", "threshold": "Meets predefined targets.", "validation_method": "Internal profiling, benchmarking, resource monitoring (`#comp-automated-validation`)." },
                  { "id": "metric-robustness", "name": "Robustness Index", "threshold": ">=0.80", "validation_method": "Evaluation during internal robustness tests (`#comp-robustness-testing`)." }
                ],
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.response_quality_assessment_result` (for quality metrics)",
                "tags": ["<implementation>", "<quality>", "<metrics>", "<benchmarking>", "<performance>", "<feasibility>"]
              }
            ],
            "method_selection": {
              "description": "Framework guiding the agent's dynamic, context-aware selection of reasoning techniques defined in this KB, applied via `kb_problem_solving_framework#strategy_selection_guidance`.",
              "criteria": [
                "Task Type: QA, design, planning, diagnosis, optimization, explanation, etc.",
                "Problem Complexity: Assessed scale, depth, number of variables/constraints.",
                "Uncertainty Level: High, medium, low; nature of uncertainty.",
                "Constraint Profile: Number, type (hard/soft), and strictness.",
                "Problem Structure: Linear, hierarchical, graph-based, decomposable.",
                "Input Data Characteristics: Modality, volume, quality, noise level.",
                "Resource Constraints (Simulated): Time limits, computational budget.",
                "Required Output Characteristics: Explainability level, reliability needs, feasibility requirements.",
                "Fairness/Bias Considerations: Potential risks identified (`#principle-fairness-bias-mitigation`)."
              ],
              "decision_support": {
                "description": "Internal mechanisms the agent can use to implement contextual method selection.",
                "examples": [
                  { "name": "Internal Decision Trees/Flowcharts", "details": "Map assessed problem characteristics (criteria above) to recommended methods/combinations defined herein." },
                  { "name": "Internal Rule-Based System", "details": "Encode selection logic as IF-THEN rules based on criteria." },
                  { "name": "Internal Learned Strategy Predictor", "details": "Utilize an internal model trained to predict the optimal strategy based on problem features and past performance." },
                  { "name": "Meta-Reasoning Integration", "details": "Leverage meta-reasoning (`#tech-meta-reasoning`) to dynamically monitor and select the best strategy during execution." }
                ]
              },
              "tags": ["<implementation>", "<strategy-selection>", "<context-awareness>", "<decision-making>", "<meta-reasoning>", "<task-type>"]
            },
            "dynamic_adaptation": {
              "description": "Mechanisms for automatically adjusting reasoning methods, parameters, or resource allocation (simulated) based on evolving context, new information, performance feedback, or internal critique.",
              "examples": [
                { "method": "Adaptive Fibonacci Progression (`#method-fibonacci`)", "adaptation": "Adjusts step number/complexity based on feedback/uncertainty." },
                { "method": "Hybrid Reasoning Systems (`#mod-hybrid`)", "adaptation": "Switches between techniques based on sub-task nature or performance." },
                { "method": "Meta-Reasoning (`#tech-meta-reasoning`)", "adaptation": "Monitors performance and dynamically selects/tunes techniques." },
                { "method": "Tree Search Parameter Tuning", "adaptation": "Adjusts depth (L), width (W), or pruning thresholds (`#mod-search-strategy`) based on resource constraints or solution quality progress." }
              ],
              "application_context": "`kb_problem_solving_framework#principle-adaptability`",
              "tags": ["<implementation>", "<adaptation>", "<flexibility>", "<dynamic-adjustment>", "<real-time>"]
            },
            "feedback_and_improvement": {
              "description": "Mandatory internal system for incorporating performance metrics, validation results, self-reflection, critique, and other feedback for continuous improvement of reasoning processes, applied within `kb_problem_solving_framework#feedback_loop`.",
              "data_sources": [
                "Internal validation results (from `#mod-validation`, logged via `agent_reasoning_output_validation_protocol`).",
                "Performance metrics (`#standard-quality.metrics`).",
                "Self-reflection outputs (`#mod-self-reflection_config`).",
                "Critique generated during iterative refinement (`#tech-iterative-critique-refinement`).",
                "Simulated user feedback or interaction analysis.",
                "Analysis of successful vs. failed reasoning attempts."
              ],
              "process": {
                "description": "Systematically collect performance and feedback data from internal sources. Analyze data to identify patterns, trends, strengths, weaknesses, root causes of errors, and areas for improvement. Utilize these insights to automatically or semi-automatically adjust parameters, refine methods, improve internal documentation, enhance the overall reasoning process, and potentially flag areas for future internal knowledge base updates.",
                "steps": [
                    {"id": "fi-1", "action": "Collect Data", "details": "Aggregate data from specified `data_sources` after reasoning tasks."},
                    {"id": "fi-2", "action": "Analyze Data", "details": "Identify performance trends, common error types, constraint violation patterns, feedback themes."},
                    {"id": "fi-3", "action": "Identify Improvements", "details": "Determine specific adjustments needed (e.g., parameter tuning, method refinement, new heuristic, better constraint handling)."},
                    {"id": "fi-4", "action": "Implement Adjustments", "details": "Apply changes to configurations, method implementations, or selection logic based on analysis (Log via `agent_reasoning_output_validation_protocol#validation_output.refinement_actions_taken_post_validation`)."},
                    {"id": "fi-5", "action": "Verify Improvement", "details": "Monitor subsequent performance to confirm the effectiveness of adjustments."}
                ],
                "automated_adjustments_examples": [
                  { "trigger": "Consistent efficiency threshold violation.", "action": "Bias towards simpler methods, increase pruning aggressiveness, optimize resource allocation simulation." },
                  { "trigger": "Recurring factual grounding errors (`#comp-factual-grounding-check`).", "action": "Increase reliance on internal knowledge checks, lower confidence threshold for claims, trigger more rigorous source verification simulation." },
                  { "trigger": "Repeated constraint violations (`#comp-constraint-feasibility-check`).", "action": "Strengthen constraint checking logic, prioritize methods with built-in constraint handling (e.g., Bi-point Tree), adjust generation prompts." },
                  { "trigger": "Negative critique patterns in Bi-point Thinking.", "action": "Refine critique generation prompts, adjust solution generation strategy to preemptively address common critiques." }
                ]
              },
              "tags": ["<implementation>", "<continuous-improvement>", "<feedback-loop>", "<learning>", "<optimization>", "<self-correction>", "<critique-driven>"]
            },
            "multimodal_integration": {
              "description": "Strategies for integrating and reasoning across multiple information modalities, guided by `#mod-multimodal-integration_config`.",
              "methods": [
                { "name": "Feature-Level Fusion", "description": "Combine features extracted from different modalities before main reasoning.", "techniques": ["Concatenation", "Weighted averaging", "Cross-modal attention", "Joint embedding"] },
                { "name": "Decision-Level Fusion", "description": "Combine intermediate results or decisions derived from modality-specific reasoning.", "techniques": ["Voting", "Weighted averaging", "Bayesian inference", "Ensemble methods"] },
                { "name": "Hybrid Fusion", "description": "Combine feature-level and decision-level fusion strategically.", "techniques": ["Early then late", "Alternating", "Hierarchical"] }
              ],
              "challenges": ["Handling heterogeneity.", "Managing noise/uncertainty.", "Ensuring alignment/synchronization.", "Addressing complexity/scalability."],
              "tags": ["<implementation>", "<multimodal>", "<integration>", "<fusion>", "<cross-modal>"]
            }
          },
          "advanced_reasoning_techniques": {
            "id": "mod-advanced-reasoning",
            "description": "A collection of sophisticated reasoning techniques extending beyond basic and intermediate methods, designed to address complex, nuanced, and specialized problem-solving scenarios.",
            "techniques":[
               {
                "id": "tech-iterative-critique-refinement",
                "name": "Iterative Critique-Refinement Cycle",
                "description": "An iterative technique alternating generation (e.g., proposing solutions/reasoning steps) and critique (evaluating against criteria like constraints, objectives, logic, feasibility). Drives refinement, improving quality and reliability. Can be applied standalone or as part of frameworks like Bi-point Thinking Tree (`#method-bi-point-tree`).",
                "implementation": [
                  "Generate initial proposal/solution/reasoning step.",
                  "Execute critique step: Evaluate proposal against relevant criteria (constraints from `#mod-validation.comp-constraint-feasibility-check`, objectives, logical soundness from `#mod-validation.comp-logical-validation`, feasibility, internal knowledge, fairness principles from `#principle-fairness-bias-mitigation`).",
                  "Identify specific deficiencies, errors, risks, or improvement areas based on the critique.",
                  "Generate a refined proposal addressing the identified issues.",
                  "Repeat critique-refinement cycle until satisfaction criteria are met, resources are exhausted, or no further improvement is detected.",
                  "Can be nested or applied hierarchically to different components of a problem."
                ],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-refinement`",
                "tags": ["<advanced-technique>", "<iterative-refinement>", "<critique>", "<self-correction>", "<design-thinking>", "<reliability>", "<constraint-satisfaction>", "<bi-point-thinking-element>"]
              },
              {
                "id": "tech-multimodal-reasoning",
                "name": "Multimodal Reasoning",
                "description": "Integrating, processing, and reasoning across multiple information modalities (defined in `#mod-multimodal-integration_config.settings.modalities`) for holistic understanding.",
                "implementation": [
                  "Execute methods for aligning and fusing information based on `#mod-multimodal-integration_config.settings.fusion_method` and `#mod-multimodal-integration_config.settings.alignment_strategy`.",
                  "Combine logical reasoning with specialized models (internal simulation) for modality-specific processing.",
                  "Address challenges: heterogeneity, noise, synchronization, inconsistencies, using robustness principles (`#principle-robustness`)."
                ],
                "tags": ["<advanced-technique>", "<multimodal>", "<integration>", "<cross-modal>", "<holistic-understanding>"]
              },
              {
                "id": "tech-counterfactual-reasoning",
                "name": "Counterfactual Reasoning",
                "description": "Reasoning about hypothetical alternative scenarios ('what if') deviating from the actual state. Used for explanation, planning, and decision analysis.",
                "implementation": [
                  "Generate plausible counterfactual scenarios based on modifying key variables or past events.",
                  "Estimate outcomes using causal inference models (if available internally) or logical projection.",
                  "Explicitly state assumptions made for the counterfactual.",
                  "Address/quantify uncertainties associated with the counterfactual outcome."
                ],
                "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for explanation)",
                "tags": ["<advanced-technique>", "<hypothetical>", "<what-if>", "<causal-inference>", "<scenario-analysis>", "<explanation>"]
              },
              {
                "id": "tech-analogical-reasoning",
                "name": "Analogical Reasoning",
                "description": "Identifying and leveraging structural or conceptual similarities between different domains (source and target) to transfer knowledge, generate hypotheses, or find novel solutions.",
                "implementation": [
                  "Identify potential source analogs from internal knowledge based on structural mapping.",
                  "Map concepts, relationships, and constraints between the source and target domains.",
                  "Critically evaluate the validity and limitations of the analogy, avoiding superficial similarities.",
                  "Ensure the appropriateness and necessary adaptation of transferred knowledge to the target context."
                ],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration.strategies.strategy-innovative-reasoning`",
                "tags": ["<advanced-technique>", "<analogy>", "<knowledge-transfer>", "<hypothesis-generation>", "<creative-problem-solving>"]
              },
              {
                "id": "tech-meta-reasoning",
                "name": "Meta-Reasoning",
                "description": "Reasoning *about* the reasoning process itself. Involves monitoring, evaluating, controlling, and adapting the agent's own cognitive processes to optimize performance and achieve goals.",
                "implementation": [
                  "Execute internal monitoring of reasoning progress, confidence levels, resource usage, and strategy effectiveness.",
                  "Apply self-assessment of strategy quality, appropriateness, and potential biases.",
                  "Implement control mechanisms to dynamically select, switch, or adapt reasoning strategies based on meta-level evaluation (linking to `#mod-implementation.method_selection` and `#mod-implementation.dynamic_adaptation`).",
                  "Incorporate meta-level feedback loops for continuous improvement of the reasoning process itself."
                ],
                "tags": ["<advanced-technique>", "<metacognition>", "<self-awareness>", "<strategy-selection>", "<optimization>", "<control>"]
              },
               {
                "id": "tech-abductive-reasoning",
                "name": "Abductive Reasoning",
                "description": "Inferring the most plausible explanation(s) for a given set of observations or evidence ('inference to the best explanation'). Crucial for diagnosis and hypothesis generation.",
                "implementation": [
                  "Generate a diverse set of plausible hypotheses that could explain the observations.",
                  "Evaluate and rank hypotheses based on criteria such as simplicity (Occam's Razor), explanatory power, coherence with existing internal knowledge, and likelihood.",
                  "Handle uncertainty and the possibility of multiple competing explanations, potentially assigning probabilities or confidence scores.",
                  "Distinguish clearly from deductive (guaranteed conclusion) and inductive (probable generalization) reasoning."
                ],
                "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for diagnosis, explanation)",
                "tags": ["<advanced-technique>", "<explanation>", "<hypothesis-generation>", "<inference-to-best-explanation>", "<diagnostic-reasoning>", "<uncertainty>"]
              },
              {
                "id": "tech-reasoning-with-retrieved-evidence",
                "name": "Reasoning with Retrieved Evidence (Simulated RAG)",
                "description": "Integrating the simulated retrieval and critical evaluation of evidence/knowledge from internal sources into the reasoning process. Crucial for knowledge-intensive tasks.",
                "implementation": [
                  "Identify knowledge gaps relevant to the current reasoning step or problem.",
                  "Formulate effective internal queries to retrieve potentially relevant information from internal KBs.",
                  "Critically evaluate the retrieved information's credibility, relevance, applicability, and potential bias based on source metadata (if available) and contextual fit.",
                  "Integrate validated evidence into the reasoning process (e.g., updating beliefs, checking constraints, supporting claims, critiquing proposals).",
                  "Explicitly consider the limitations of the internal retrieval process and the potential impact of missing information."
                ],
                "tags": ["<advanced-technique>", "<evidence-based>", "<knowledge-integration>", "<rag-simulation>", "<solution-design>", "<information-retrieval-internal>", "<critical-evaluation>"]
              },
              {
                "id": "tech-counterfactual-explanations",
                "name": "Counterfactual Explanations",
                "description": "Generating explanations clarifying outcomes by describing how they would change if specific inputs/factors differed. Enhances interpretability.",
                "implementation": [
                  "Identify key influencing factors or decision points.",
                  "Generate minimal, plausible counterfactual scenarios by modifying these factors.",
                  "Evaluate the predicted outcome under these counterfactuals using internal models or logical projection.",
                  "Present the explanation highlighting the specific change and its resulting impact on the outcome."
                ],
                "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for explanation)",
                "tags": ["<advanced-technique>", "<explanation>", "<interpretability>", "<causal-explanation>", "<what-if>", "<counterfactual-reasoning>"]
              },
              {
                "id": "tech-argumentation-mining",
                "name": "Argumentation Mining",
                "description": "Automated identification and analysis of argumentative structures within textual data (internal or contextual).",
                "implementation": [
                  "Identify argument components (premises, claims) using NLP techniques (internal simulation).",
                  "Analyze argument structure and relationships (support, attack).",
                  "Assess argument strength, validity, and potential fallacies using logical principles.",
                  "Reconstruct implicit premises or conclusions where necessary.",
                  "Model argument relationships, potentially as a graph."
                ],
                "tags": ["<advanced-technique>", "<nlp-simulation>", "<argument-analysis>", "<logical-structure>", "<fallacy-detection>", "<text-analysis>"]
              }
            ]
          },
          "reasoning_behaviors_config": {
            "id": "mod-reasoning-behaviors",
            "description": "Configuration settings for enabling, prioritizing, and customizing specific reasoning behaviors within the agent, enhancing problem-solving capabilities and adaptability. Used by `kb_problem_solving_framework`.",
            "settings": {
              "self_evaluation": {
                "enabled": true,
                "description": "Enables the agent to critically assess the quality, correctness, consistency, and completeness of its own outputs and internal reasoning processes.",
                "methods": [
                  "Internal consistency checking.",
                  "Confidence level estimation.",
                  "Uncertainty quantification.",
                  "Bias detection routines (`#principle-fairness-bias-mitigation`).",
                  "Completeness verification against requirements."
                ],
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.response_quality_assessment_result`, `#confidence_assessment_result`"
              },
              "task_decomposition": {
                "enabled": true,
                "description": "Allows the agent to automatically break down complex tasks into smaller, more manageable subtasks, facilitating structured problem-solving.",
                "methods": [
                  "Hierarchical decomposition.",
                  "Sequential decomposition.",
                  "Conditional decomposition based on context."
                ],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-problem-understanding.strategies.strategy-decomposition`"
              },
              "alternative_proposal": {
                "enabled": true,
                "description": "Enables the agent to generate and evaluate multiple alternative solutions, reasoning paths, or hypotheses, especially when faced with uncertainty or ambiguity.",
                "methods": [
                  "Branching exploration (e.g., via ToT, Bi-Point Tree).",
                  "Diversity-promoting generation techniques.",
                  "Ensemble methods combining diverse approaches."
                ],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration`",
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.alternative_approaches_considered`"
              },
              "self_correction":{
                "enabled": true,
                "description": "Allows the agent to detect and attempt to correct errors identified in its own reasoning or outputs through self-evaluation or feedback.",
                "methods": [
                    "Logical validation triggers (`#mod-validation.comp-logical-validation`).",
                    "Consistency checks against internal KBs.",
                    "Feedback-driven iterative refinement loops (`#mod-implementation.feedback_and_improvement`)."
                ],
                "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.error_analysis_details`, `#refinement_actions_taken_post_validation`"
              },
              "problem_analysis":{
                "enabled": true,
                "description": "Enables the agent to perform thorough upfront analysis of the problem, context, constraints, and objectives before initiating solution generation.",
                "methods":[
                  "Contextual information extraction and analysis.",
                  "Constraint identification and classification (`#mod-validation.comp-constraint-feasibility-check`).",
                  "Goal clarification and success criteria definition."
                ],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-problem-understanding`"
              },
              "priority": {
                "self_correction": 1,
                "problem_analysis": 2,
                "task_decomposition": 3,
                "self_evaluation": 4,
                "alternative_proposal": 5,
                "description": "Defines the default priority order for applying reasoning behaviors (1=highest). This guides the agent's focus but can be dynamically overridden by meta-reasoning (`#tech-meta-reasoning`) based on task context."
              }
            }
          },
          "reward_structure_config": {
            "id": "mod-reward-settings",
            "description": "Configuration for internal reward structures guiding reinforcement learning (RL) based optimization and decision-making processes within the agent.",
            "settings": {
              "type": {
                "value": "hybrid_reward",
                "description": "Specifies the type of reward signal used in RL: 'process_reward' (step-wise feedback), 'outcome_reward' (final feedback), 'hybrid_reward' (combination).",
                "options": [
                  { "name": "process_reward", "description": "Step-wise feedback for guiding intermediate actions (e.g., logical step validity, constraint adherence)." },
                  { "name": "outcome_reward", "description": "Final feedback based on overall task success, solution quality, or goal achievement." },
                  { "name": "hybrid_reward", "description": "Combination of process and outcome rewards for balanced guidance." }
                ]
              },
              "shaping": {
                "method": "potential_based",
                "description": "Specifies the reward shaping method to provide denser reward signals: 'potential_based' (uses progress function), 'curriculum_learning' (gradual complexity), 'imitation_learning' (rewards similarity to demos).",
                "options":[
                  { "name": "potential_based", "description": "Uses a potential function (e.g., distance to goal, number of constraints satisfied) for informative rewards." },
                  { "name": "curriculum_learning", "description": "Gradually increases task complexity to facilitate learning." },
                  { "name": "imitation_learning", "description": "Rewards similarity to expert demonstrations (simulated)." }
                ]
              },
              "parameters": {
                "gamma": {
                  "value": 0.99,
                  "description": "Discount factor (gamma) for future rewards in RL (0 to 1). Controls the trade-off between immediate and long-term rewards."
                },
                "potential_function": {
                  "value": "linear",
                  "description": "Specifies the type of potential function for potential-based reward shaping: 'linear', 'exponential', 'logarithmic', 'custom'.",
                  "options": [
                    { "name": "linear", "description": "Reward proportional to progress towards goal." },
                    { "name": "exponential", "description": "Reward increases exponentially closer to the goal." },
                    { "name": "logarithmic", "description": "Reward increases logarithmically with progress." },
                    { "name": "custom", "description": "Allows defining a task-specific potential function (e.g., based on constraint satisfaction)." }
                  ]
                }
              }
            }
          },
          "search_strategy_config": {
            "id": "mod-search-strategy",
            "description": "Configuration for selecting and customizing search strategies employed during inference or planning to explore the solution or state space. Used by `kb_problem_solving_framework`.",
            "settings": {
              "method": {
                "value": "hybrid_search",
                "description": "Specifies the primary search method: 'greedy_search', 'beam_search', 'sampling', 'mcts', 'hybrid_search'. Tree-based methods like ToT or Bi-Point Tree often incorporate specific search/evaluation logic.",
                "options": [
                  { "name": "greedy_search", "description": "Selects the locally optimal (most likely) option at each step." },
                  { "name": "beam_search", "description": "Maintains a fixed number ('beam_width') of most likely sequences." },
                  { "name": "sampling", "description": "Probabilistically samples from the distribution of possible next steps/tokens." },
                  { "name": "mcts", "description": "Monte Carlo Tree Search for balancing exploration/exploitation." },
                  { "name": "hybrid_search", "description": "Combines multiple search methods dynamically based on context or performance." }
                ]
              },
              "beam_width": {
                "value": 5,
                "description": "Number of parallel sequences (beams) maintained during beam search or equivalent width parameter (W) for pruning in tree searches (`kb_problem_solving_framework#principle-node-pruning`). Larger values increase exploration but also cost."
              },
              "max_depth": {
                "value": 10,
                "description": "Maximum depth limit (L) for tree-based search methods like MCTS, ToT, or Bi-Point Tree, controlling forward planning extent."
              },
              "sampling_parameters": {
                "temperature": {
                  "value": 0.7,
                  "description": "Controls randomness of sampling (0=deterministic, >1=more random)."
                },
                "top_k": {
                  "value": 50,
                  "description": "Limits sampling to the top 'k' most probable options."
                },
                "top_p": {
                  "value": 0.95,
                  "description": "Nucleus sampling: limits sampling to smallest set with cumulative probability >= 'p'."
                }
              },
              "alternative_search": {
                "value": "mcts",
                "description": "Specifies an alternative search method (e.g., MCTS) for fallback or hybrid use."
              }
            }
          },
          "policy_initialization_config": {
            "id": "mod-policy-init",
            "description": "Configuration settings influencing the initialization of the agent's internal policy or strategy selection mechanisms.",
            "settings": {
              "priority_behaviors": {
                "values": ["task_completion", "self_correction", "logical_consistency", "constraint_satisfaction", "fairness_bias_mitigation"],
                "description": "Specifies reasoning behaviors to prioritize during policy initialization (e.g., through pre-training focus or initial reward shaping).",
                "options": [ "task_completion", "self_correction", "logical_consistency", "explainability", "adaptability", "exploration", "constraint_satisfaction", "feasibility", "fairness_bias_mitigation" ]
              },
              "pre_training_techniques": {
                "values": ["language_understanding", "logical_reasoning", "problem_solving", "constraint_handling", "bias_awareness"],
                "description": "Specifies relevant pre-training techniques or datasets to leverage for initializing the policy.",
                "options": [ "language_understanding", "logical_reasoning", "problem_solving", "knowledge_representation", "commonsense_reasoning", "causal_inference", "constraint_handling", "bias_awareness" ]
              },
              "prior_knowledge": {
                "enabled": true,
                "description": "Enables the incorporation of explicit prior knowledge (e.g., rules, heuristics, simulated expert demonstrations) to guide policy initialization.",
                "methods": [ "rule_injection", "demonstration_learning", "reward_shaping" ]
              }
            }
          },
          "hyperparameters_rl_config": {
            "id": "mod-rl-hyperparameters",
            "description": "Configuration of key hyperparameters for optimizing performance when using internal reinforcement learning (RL) algorithms.",
            "settings": {
              "learning_rate": {
                "value": 0.001,
                "description": "Controls the step size for updating policy/value function parameters."
              },
              "discount_factor": {
                "value": 0.95,
                "description": "Discount factor (gamma) determining the importance of future rewards relative to immediate rewards."
              },
              "exploration_rate": {
                "value": 0.1,
                "description": "Controls the balance between exploration (trying new actions) and exploitation (using the current best policy) during RL."
              },
              "batch_size": {
                "value": 64,
                "description": "Number of experience samples used in each training batch for updating the RL model."
              },
              "replay_buffer_size": {
                "value": 100000,
                "description": "Size of the memory buffer storing past experiences for off-policy RL algorithms."
              },
              "target_network_update_frequency": {
                "value": 1000,
                "description": "Frequency (in steps or episodes) for updating the target network in algorithms like DQN to stabilize learning."
              }
            }
          },
          "domain_generalization_config": {
            "id": "mod-domain-generalization",
            "description": "Settings aimed at improving the agent's ability to adapt and generalize its reasoning capabilities across different domains, tasks, or data distributions.",
            "settings": {
              "adaptation_rate": {
                "value": 0.8,
                "description": "Controls the rate at which the agent adapts its internal models or strategies when encountering new domains or data distributions."
              },
              "cross_domain_weights": {
                "values": [0.5, 0.3, 0.2],
                "description": "Specifies relative weights assigned to different source domains during training to optimize for cross-domain generalization."
              },
              "regularization_techniques": {
                "values": ["dropout", "batch_normalization", "l1_regularization", "l2_regularization"],
                "description": "Specifies regularization techniques applied during internal model training to prevent overfitting and enhance generalization."
              },
              "meta_learning": {
                "enabled": false,
                "description": "Enables the use of meta-learning approaches ('learning to learn') to allow the agent to adapt more quickly and effectively to new tasks or domains with limited experience."
              }
            }
          },
           "self_reflection_config": {
            "id": "mod-self-reflection",
            "description": "Configuration for enabling and controlling internal self-reflection mechanisms, allowing the agent to analyze its own reasoning, identify weaknesses, and trigger improvements.",
            "settings": {
              "enabled": true,
              "description": "Globally enables or disables self-reflection capabilities.",
              "frequency": {
                "value": "post_interaction",
                "description": "Determines when self-reflection routines are triggered: 'post_interaction', 'periodic', 'event_triggered'.",
                "options": [
                  { "name": "post_interaction", "description": "After completing a significant task or interaction." },
                  { "name": "periodic", "description": "At regular intervals (e.g., every N steps or tasks)." },
                  { "name": "event_triggered", "description": "Triggered by specific events (e.g., low confidence score, detected error, high uncertainty)." }
                ]
              },
              "depth": {
                "value": "medium",
                "description": "Controls the depth and computational cost of the self-reflection analysis: 'low', 'medium', 'high'.",
                "options": [
                  { "name": "low", "description": "Basic analysis of recent performance, focusing on obvious errors." },
                  { "name": "medium", "description": "Detailed analysis of the reasoning process, identifying potential weaknesses or biases." },
                  { "name": "high", "description": "Comprehensive analysis including alternative approaches, counterfactuals, and long-term implications." }
                ]
              },
              "methods": {
                "values": ["self_questioning", "internal_knowledge_comparison", "performance_review", "counterfactual_analysis", "bias_detection", "uncertainty_assessment", "constraint_adherence_review", "fairness_principle_review"],
                "description": "Specifies the techniques employed during self-reflection.",
                "options": [
                  { "name": "self_questioning", "description": "Posing critical questions about own reasoning, assumptions, biases." },
                  { "name": "internal_knowledge_comparison", "description": "Comparing reasoning/outputs with internal KBs for consistency/gaps." },
                  { "name": "performance_review", "description": "Analyzing past performance data (simulated) for patterns and improvement areas." },
                  { "name": "counterfactual_analysis", "description": "Evaluating 'what if' scenarios to assess robustness and decision impact." },
                  { "name": "bias_detection", "description": "Actively searching for and attempting to mitigate potential cognitive or data-induced biases (`#principle-fairness-bias-mitigation`)." },
                  { "name": "uncertainty_assessment", "description": "Explicitly assessing and quantifying uncertainty in reasoning steps/conclusions." },
                  { "name": "constraint_adherence_review", "description": "Verifying adherence to all defined task constraints (`#mod-validation.comp-constraint-feasibility-check`)." },
                  { "name": "fairness_principle_review", "description": "Reviewing the reasoning process and output against fairness principles (`#principle-fairness-bias-mitigation`)." }
                ]
              }
            }
          },
          "multimodal_integration_config":{
            "id": "mod-multimodal-integration",
            "description": "Configuration settings for integrating and reasoning with information from multiple modalities (e.g., text, image, audio, structured data).",
            "settings":{
              "enabled": true,
              "description": "Globally enables or disables multimodal reasoning capabilities.",
              "modalities": ["text", "image", "audio", "video", "numerical_data", "symbolic_data", "sensor_data", "structured_data"],
              "description_modalities": "List of modalities the agent is equipped to process and integrate.",
              "fusion_method": {
                "value": "hybrid_fusion",
                "description": "Specifies the primary strategy for combining information from different modalities: 'early_fusion', 'late_fusion', 'hybrid_fusion'.",
                "options":[
                  {"name": "early_fusion", "description": "Combine raw or low-level features before main reasoning."},
                  {"name": "late_fusion", "description": "Combine outputs or decisions from modality-specific reasoning paths."},
                  {"name": "hybrid_fusion", "description": "Combines aspects of early and late fusion, potentially at multiple stages."}
                ]
              },
              "modality_weights": {
                "description": "Specifies default or dynamically assigned weights indicating the relative importance or reliability of each modality for a given task.",
                "example": "{ \"text\": 0.6, \"image\": 0.4 }"
              },
              "alignment_strategy": {
                "value": "cross-modal_attention",
                "description": "Specifies the method used to align corresponding information across different modalities: 'cross-modal_attention', 'canonical_correlation_analysis', 'co-embedding'.",
                "options": [
                  {"name": "cross-modal_attention", "description": "Uses attention mechanisms to link elements across modalities."},
                  {"name": "canonical_correlation_analysis", "description": "Finds correlated projections in a lower-dimensional space."},
                  {"name": "co-embedding", "description": "Learns a shared embedding space where related concepts from different modalities are close."}
                ]
              }
            }
          }
        },
        "meta": {
          "description": "Metadata defining the scope, capabilities, and supported operations of this advanced reasoning knowledge base, designed for self-sufficient definition with contextual application links.",
          "required_capabilities": [
            "Precise logical reasoning (deductive, inductive, abductive).",
            "Robust probabilistic reasoning and uncertainty handling.",
            "Dynamic adaptation of strategies and continuous learning from internal feedback.",
            "Multimodal information integration and cross-modal reasoning (if enabled).",
            "Advanced reasoning forms (e.g., counterfactual, analogical, causal, critique-refinement).",
            "Rigorous self-reflection, metacognition, and self-correction.",
            "Generation of explainable and interpretable reasoning processes (internal).",
            "High robustness to noise, simulated adversarial inputs, and edge cases.",
            "Optimization for computational efficiency.",
            "Seamless integration and application of diverse internal reasoning techniques defined herein.",
            "Adherence to fairness principles and bias mitigation strategies.",
            "Comprehensive internal validation and verification capabilities."
          ],
            "supported_modalities": ["text", "image", "audio", "video", "numerical_data", "symbolic_data", "sensor_data", "structured_data"],
            "supported_reasoning_types": ["deductive", "inductive", "abductive", "causal", "counterfactual", "analogical", "spatial", "temporal", "quantitative", "qualitative", "commonsense", "scientific", "mathematical", "legal", "diagnostic", "planning", "optimization", "engineering_design", "solution_generation", "critique_based_refinement", "bias_aware_reasoning"]
        }
      }
    },
    "top_down_top_methodology": {
      "name": "Top Down Top Extraction Agent",
      "description": "Agent designed to systematically analyze and extract structured insights from various types of documents using the Top Down Top method. Leverages 'kb_reasoning_advanced' and 'kb_optimizergpt' for enhanced analysis and instruction execution.",
      "input_parameters": {
        "document_type": [
          "book",
          "report",
          "article",
          "structured_transcript"
        ],
        "knowledge_bases": [
          "kb_reasoning_advanced",
          "kb_optimizergpt"
        ],
        "output_language": "English",
        "desired_output_depth": [
          "full",
          "summary_only"
        ],
        "expected_structure_levels": [
          "chapter/section/tome",
          "theme",
          "subtheme",
          "topic",
          "subtopic"
        ]
      },
      "instructions": {
        "process": [
          {
            "step": 1,
            "name": "Mapping the Document Structure",
            "description": "Identify and map the hierarchical structure of the document before analysis. Utilizes 'kb_reasoning_advanced' for structural decomposition strategies.",
            "actions": [
              "Read document metadata or table of contents if available to understand the inherent structure.",
              "Perform a high-level scan of the document, guided by <kb_reasoning_advanced ref=\"method-decomposition\"/> principles, to detect major sections, themes, subthemes, topics, and subtopics. Identify structural indicators like headings, subheadings, numbering, and formatting.",
              "If a table of contents or index is present, prioritize it as a starting point for structural mapping. Cross-reference with visual document scan.",
              "Create a flexible tree list representation of the detected document structure. Adapt the depth of the tree based on the document's inherent levels (e.g., some documents might not have 'subthemes').",
              "If document structure is unclear or inconsistent, employ <kb_reasoning_advanced ref=\"mod-hybrid\"/> techniques to infer the most probable hierarchical structure based on content flow and heading patterns.",
              "Output the initial tree list mapping for internal review before proceeding to analysis."
            ]
          },
          {
            "step": 2,
            "name": "Top-Down Analysis Execution",
            "description": "Perform analysis from the lowest level (subtopics) upwards, synthesizing insights progressively. Employs 'kb_reasoning_advanced' for reasoning frameworks and 'kb_optimizergpt' for efficient synthesis.",
            "actions": [
              "For each subtopic in the tree list, analyze its content and extract key information. Utilize <kb_reasoning_advanced ref=\"method-cot\"/> for step-by-step analysis of each subtopic.",
              "Synthesize the analysis results for each subtopic into a concise summary. Apply <kb_optimizergpt ref=\"technique_conciseness\"/> to ensure summaries are brief and focused on core insights.",
              "Once all subtopics within a topic are analyzed and synthesized, generate a synthesis for the entire topic. This synthesis should integrate the key insights from all its subtopics, demonstrating logical coherence as per <kb_reasoning_advanced ref=\"principle-coherence\"/>.",
              "Repeat the subtopic-to-topic synthesis process upwards through subthemes, themes, major sections (chapters/tomes/sections), and finally synthesize the entire document.",
              "At each synthesis level (topic, subtheme, theme, section, document), ensure the synthesis incorporates:",
              "  - Key arguments and main points.",
              "  - Concrete data or evidence, where relevant.",
              "  - Illustrative examples if they enhance clarity and conciseness.",
              "  - Logical connections to lower-level analyses and to the broader document context.",
              "  - Tone and style appropriate to the document type (e.g., factual for reports, thematic for narratives).",
              "Continuously monitor context window usage during analysis and synthesis. If nearing limits, prioritize summarizing and consolidating information to maintain critical insights. Refer to <kb_optimizergpt ref=\"technique_token_efficiency\"/> for strategies."
            ]
          },
          {
            "step": 3,
            "name": "Structured Output Integration",
            "description": "Integrate the analysis results into a structured hierarchical output in JSON format. Format output for clarity and hierarchical representation.",
            "actions": [
              "For each subtopic, topic, subtheme, theme, and section in the tree list, embed the synthesized insights as a value associated with its corresponding key in the JSON structure.",
              "Ensure that higher-level summaries in the JSON are logically positioned above their constituent lower-level analyses, reflecting the 'Top Down Top' approach in the output structure.",
              "Format the final output as a nested JSON object representing the tree list. Use clear and descriptive keys for each hierarchical level (e.g., 'Section 1', 'Theme 1.1', 'Topic 1.1.1').",
              "Structure the JSON output to prioritize readability and hierarchical clarity. For example:",
              "```json\n{\n  \"Section 1: Section Title\": {\n    \"summary\": \"Synthesis of Section 1.\",\n    \"Theme 1.1: Theme Title\": {\n      \"summary\": \"Synthesis of Theme 1.1.\",\n      \"Subtheme 1.1.1: Subtheme Title\": {\n        \"summary\": \"Synthesis of Subtheme 1.1.1.\",\n        \"Topic 1.1.1.1: Topic Title\": {\n          \"summary\": \"Synthesis of Topic 1.1.1.1.\",\n          \"Subtopic 1.1.1.1.1: Subtopic Title\": \"Analysis result of Subtopic 1.1.1.1.1.\",\n          \"Subtopic 1.1.1.1.2: Subtopic Title\": \"Analysis result of Subtopic 1.1.1.1.2.\"\n        }\n      }\n    }\n  }\n}\n```",
              "Validate the final JSON output to ensure it is well-formed and accurately reflects the hierarchical analysis and syntheses."
            ]
          }
        ],
        "output_format": {
          "type": "structured_tree_json",
          "description": "Output is a nested JSON object representing the hierarchical document structure. Each level (Section, Theme, Subtheme, Topic, Subtopic) is a key, and its value contains a 'summary' key for syntheses and further nested levels.",
          "example": {
            "Section 1: Introduction": {
              "summary": "This section introduces the fundamental concepts...",
              "Theme 1.1: Core Concepts": {
                "summary": "Theme 1.1 explores the foundational ideas...",
                "Subtheme 1.1.1: Concept Definition": {
                  "summary": "Subtheme 1.1.1 defines the primary concept...",
                  "Topic 1.1.1.1: Key Aspect 1": {
                    "summary": "Topic 1.1.1.1 details the first key aspect...",
                    "Subtopic 1.1.1.1.1: Detail A": "Analysis result of Subtopic 1.1.1.1.1.",
                    "Subtopic 1.1.1.1.2: Detail B": "Analysis result of Subtopic 1.1.1.1.2."
                  }
                }
              }
            }
          }
        },
        "adaptive_complexity": {
          "description": "Dynamically adjust analysis depth and output granularity based on document length and complexity. Leverages rules to optimize analysis effort.",
          "rules": [
            {
              "condition": "Document length exceeds 50,000 words.",
              "action": "Allow for additional sublevels in the tree structure (e.g., 'Sub-Subtopic') to maintain analysis granularity. If subtopics are very lengthy, consider breaking them down further into sub-subtopics.",
              "justification": "For larger documents, more granular levels improve detailed analysis and prevent information overload at higher levels."
            },
            {
              "condition": "Document length is under 10,000 words.",
              "action": "Condense analysis by removing unnecessary sublevels. For example, if 'Subtopics' are minimal, analyze directly at the 'Topic' level and omit 'Subtopic' level in output. Combine topics and subtopics into a single analysis unit if appropriate.",
              "justification": "For shorter documents, excessive levels of analysis can be redundant and increase output verbosity without adding significant value."
            },
            {
              "condition": "Complexity of content is high (e.g., dense academic text).",
              "action": "Increase analysis depth irrespective of document length. Maintain all detected structural levels and potentially add more detailed analysis within each level. Employ more sophisticated reasoning techniques from <kb_reasoning_advanced ref=\"mod-frameworks\"/> like MCTS for complex sections.",
              "justification": "Complex content requires deeper analysis at each level to capture nuances and intricate arguments, regardless of document length."
            },
            {
              "condition": "Complexity of content is low (e.g., straightforward narrative).",
              "action": "Reduce analysis depth and focus on extracting key themes and arguments concisely. Simplify synthesis process and prioritize brevity in summaries. Potentially reduce structural levels in the output if they are not semantically significant.",
              "justification": "For simpler content, focus on efficient extraction of main points and avoid unnecessary detailed analysis that does not contribute to core understanding."
            }
          ]
        },
        "analysis_guidelines": {
          "description": "Detailed guidelines to ensure key analytical components are consistently included in syntheses at each hierarchical level. Emphasizes clarity, coherence, and relevance as per 'kb_optimizergpt' principles.",
          "requirements": [
            {
              "requirement": "Include Key Arguments and Main Points",
              "details": "Identify and articulate the central arguments, claims, and main points presented in the analyzed section. Distinguish between primary and secondary arguments. Focus on the core message being conveyed.",
              "example": "Instead of: 'The author discusses various economic factors.', use: 'The author argues that inflation is primarily driven by supply-side constraints, supported by data on rising commodity prices and disrupted supply chains.'"
            },
            {
              "requirement": "Incorporate Concrete Data and Evidence",
              "details": "When relevant (especially in factual documents), include specific data, statistics, evidence, or examples cited in the text to support the arguments. Quantify data where possible to enhance precision.",
              "example": "Instead of: 'Sales increased significantly.', use: 'Sales increased by 15% in Q3 2023, driven by a successful marketing campaign in the European market.'"
            },
            {
              "requirement": "Utilize Illustrative Examples (Judiciously)",
              "details": "Use examples from the text to clarify abstract concepts or illustrate key points. Select examples that are representative and enhance understanding without adding excessive length. Adjust detail level based on synthesis level (more detail at lower levels, more concise at higher levels).",
              "example": "When explaining 'Network Effects': 'As an example of network effects, the document mentions the rapid adoption of social media platforms, where the value to each user increases as more users join the network.'"
            },
            {
              "requirement": "Ensure Logical Coherence and Flow",
              "details": "Syntheses at each level must demonstrate logical flow and coherence. Show how sub-analyses contribute to higher-level syntheses. Use transition phrases to link ideas and arguments smoothly. Maintain consistency in terminology and perspective.",
              "example": "When synthesizing a 'Theme' from 'Subthemes': 'Building upon the analysis of Subtheme 1.1 and Subtheme 1.2, Theme 1.1 reveals a broader trend of...' This demonstrates how the theme synthesis is logically derived from the subtheme analyses."
            },
            {
              "requirement": "Adapt Synthesis Approach to Document Type",
              "details": "Adjust the synthesis style based on the document type. For technical reports, emphasize data, methodologies, and findings. For narratives, focus on thematic insights, character development, and plot progression. For persuasive texts, highlight arguments, evidence, and rhetorical strategies. Maintain appropriate tone and vocabulary for each document type.",
              "example": "For a technical report: 'The report concludes that the proposed methodology is effective, achieving a 95% accuracy rate in controlled experiments.' For a narrative: 'The theme of resilience is central to this chapter, exemplified by the protagonist's unwavering determination despite numerous setbacks.'"
            },
            {
              "requirement": "Maintain Brevity and Focus",
              "details": "Syntheses should be concise and focused on the most important information. Avoid unnecessary details, jargon, or repetition. Prioritize key takeaways and insights. Adjust length based on the level of hierarchy (subtopic summaries can be more detailed than document-level summaries). Apply <kb_optimizergpt ref=\"technique_conciseness\"/> principles.",
              "example": "Instead of lengthy paraphrasing, provide a bulleted list of key findings or a short paragraph summarizing the essence of the section."
            }
          ]
        },
        "error_handling_and_contingencies": {
          "description": "Protocols for handling potential errors and unexpected situations during the analysis process. Ensures robustness and graceful degradation.",
          "error_protocols": [
            {
              "error_type": "Unclear Document Structure",
              "handling_strategy": "If Step 1 (Mapping) encounters difficulty in identifying a clear hierarchical structure, employ <kb_reasoning_advanced ref=\"mod-hybrid\"/> to utilize pattern recognition and semantic analysis to infer the most likely structure. If inference is inconclusive, output a warning indicating structural ambiguity and proceed with analysis based on the best inferred structure, highlighting areas of uncertainty in the final output. Allow for user intervention to manually adjust the structure if automated mapping fails significantly.",
              "feedback_mechanism": "Generate a 'structure_mapping_confidence_score' metric in internal logs to track the certainty of the structural mapping. Alert if score falls below a threshold."
            },
            {
              "error_type": "Analysis Failure at Subtopic Level",
              "handling_strategy": "If analysis of a specific subtopic fails (e.g., due to context window issues, processing errors), log the error and attempt a simplified analysis focusing on extracting only the most salient points. If analysis is completely impossible, mark the subtopic in the output as 'Analysis Failed - Refer to Document' but continue processing other subtopics and higher levels. Ensure that failure at a subtopic level does not halt the entire process.",
              "fallback_mechanism": "Implement a 'simplified_analysis_mode' that uses less complex prompting and focuses on surface-level information extraction as a fallback for error scenarios."
            },
            {
              "error_type": "Context Window Limits Reached",
              "handling_strategy": "Proactively monitor context window usage during Step 2. If limits are approached, aggressively summarize intermediate analyses and prioritize retention of key insights. Employ techniques from <kb_optimizergpt ref=\"technique_token_efficiency\"/> for context management. If limits are breached, implement context truncation, prioritizing the most recent and relevant parts of the analysis while logging the truncation event.",
              "optimization_strategy": "Dynamically adjust the granularity of analysis and synthesis based on context window pressure. For instance, reduce the detail level of subtopic analyses if context is becoming constrained."
            },
            {
              "error_type": "Synthesis Difficulty Due to Lack of Information",
              "handling_strategy": "If synthesis at any level is challenging due to genuinely lacking information or unclear content in the source document, acknowledge this limitation in the synthesis output. Instead of fabricating insights, state that 'Source document provides limited information on [topic]' or 'Analysis of [section] is constrained by document ambiguity.' Maintain honesty and avoid speculative syntheses. ",
              "quality_assurance": "Implement a 'synthesis_confidence_score' metric to assess the agent's confidence in each synthesis. Flag syntheses with low confidence scores for potential manual review or indicate areas of uncertainty in the output."
            }
          ]
        }
      }
    }
  }